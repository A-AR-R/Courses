
\documentclass[11pt]{article}

% math packages
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}    % Math symbols such as \mathbb
\usepackage{amsthm}
\usepackage{pgfplots}   % plots
\usepackage[linesnumbered, boxruled,titlenumbered, noend]{algorithm2e} % algorithmn
% https://en.wikibooks.org/wiki/LaTeX/Algorithms
% http://ctan.mirror.rafal.ca/macros/latex/contrib/algorithm2e/doc/algorithm2e.pdf
\SetKwProg{Fn}{Function}{}{}

% other packages
\usepackage{graphicx}
\graphicspath{ {../assets/} }
\usepackage{enumitem}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{hyperref}

% proper inline math display, adjust height for symbols like \sum
\everymath{\displaystyle}

% define tags for math use..
\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{exmp}{Example}[defn]
\newtheorem{prop}{Proposition}[defn]
\newtheorem{lemma}{Lemma}[defn]



\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}
\newtheorem{case}{Case}

% Gives begin{solution} same formating as \begin{proof}
\newenvironment{solution}
  {\begin{proof}[Solution]}
  {\end{proof}}


\newenvironment{approach}
  {\begin{proof}[Approach]}
  {\end{proof}}


%running fraction with slash - requires math mode.
\newcommand*\rfrac[2]{{}^{#1}\!/_{#2}}
%shortcut to mathbb
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\I}{\mathbb{I}}
% color highlighting
\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}


\title{CS236 notes}
\author{Mark Wang}

% begin document
\begin{document}

% title page
\maketitle


\section*{1.2 Simple Induction}




\begin{defn}
  \label{simple induction}
  Proof by \textbf{simple induction} is a method for proving statement
  \[
    \forall n\in \mathbb{N}, P(n)
  \]
  \\ The method of induction consists of 2 steps \\
  \textit{BASIS}: Prove that $P(0)$ is true, ie. that predicate $P(n)$ holds for $n=0$. \\
  \textit{INDUCTION STEP}: Prove that, for each $i\in \mathbb{N}$, if P(i) is true then $P(i+1)$ is also true. \\
  \begin{rem}
    The assumption that $P(i)$ holds in the indcution step of the proof is called the \textit{induction hypothesis}. Bases case can be non-zero.
  \end{rem}

  \begin{exmp}
    For any $m, n\in \mathbb{N}$ such that $n\neq 0$, there are unique $q,r\in \mathbb{N}$ such that $m=q\dot n + r$ and $r < n$

    \begin{rem}
      Think about 2 cases. either $r< n-1$ or $r=n-1$
    \end{rem}
  \end{exmp}

  \begin{exmp}
    We can use an unlimited supply of 4-cent and 7-cent postage stamps to make exactly any amount of postage that is 18 cents or more. Or that $\exists a,b\in \mathbb{N}, i=4a + 7b$

    \begin{rem}
      Intuitively, try to juggle around value of $a,b$ so that there is an excess of 1-cent, which satisfies for $i+1$. In this case prove by cases to make it happen. Otherwise use proof by complete induction which is easier.
    \end{rem}
  \end{exmp}
\end{defn}


\begin{defn}
  \label{divisible}
  a is \textbf{divisible} by b if the division of a by b has no remainder.
  \[
    b \mid a: \exists k\in \mathbb{N}: a = bk
  \]
  \begin{rem}
    Read $b\mid a$ as $b$ divides $a$
  \end{rem}
\end{defn}

\begin{defn}
  \label{prime number}
  An integer $n$ is \textbf{prime} if $n \geq 2$ and the only positive integers that divide $n$ are 1 and itself.
  \[
    \{ n \in\mathbb{N}: n \geq 2 \land m\mid n \Rightarrow m=1 \lor m=n\}
  \]
  \begin{rem}
    Prime factorization of a natural number n is a sequence of primes whose product is n
  \end{rem}
\end{defn}


\section*{1.3 Complete Induction}

\begin{defn}
  \label{complete induction}
  Proof by \textbf{complete induction} is a method for proving \\
  \[
    \forall n\in \mathbb{N}, P(n)
  \]
  \textit{BASIS}: Prove that $P(n)$ holds for all $n \geq c$ \\
  \textit{INDUCTION STEP}: Prove that, for each natural number $i>c$, if $P(j)$ holds for all natural numbers $j$ such that $c\leq j < i$, then $P(i)$ holds as well.
  \begin{rem}
    It is important to ensure that both $j \geq c$ and $j< i$
  \end{rem}

  \begin{exmp}
    Any integer $n\geq 2$, has a prime factorization.

    \begin{proof}
      Define the predicate $P(n)$ as follows
      \[
        P(n):\quad n \text{ has a prime factorization}
      \]
      Use complete induction to prove that $P(n)$ holds for all integer $n\geq 2$. Let $i$ be an arbitrary integer such taht $i\geq 2$. Assume that $P(j)$ holds for all integers $j$, such that $2\leq j < i$. We muts prove that $P(i)$ holds as well. There are two cases \\
      \textbf{CASE 1}: $i$ is prime. Then $\langle i\rangle$ is a prime factorization of $i$. Thus $P(i)$ holds. \\
      \textbf{CASE 2}: $i$ is not prime. Thus there is a positive integer $a$ that divides $i$ such that $a\neq 1 \land a\neq i$. Let $b=\rfrac{i}{a}; i.e., i = a\cdot b$. Since $a\neq i \land a\lneq i$, it follows that $a,b$ are both integers such that $2\leq a,b \leq i$. Therefore, by the induction hypothesis, $P(a)$ and $P(b)$ both hold. That is, there is a prime factorization of $a$, say $\langle p_1, p_2, \dots, p_{k}\rangle$, and there is a prime factorisation of b, say $\langle q_1, q_2, \dots, q_l\rangle$. Since $i=a\cdot b$, it is obvious that concatenation of the prime factorisation of $a$ and $b$, i.e. $\langle p_1, p_2, \dots, p_k, q_1, q_2, \dots, q_l\rangle$, is a prime factorisation of $i$. Therefore, $P(i)$ holds in this case as well.
      Therefore $P(n)$ holds for all $n\geq 2$

      \begin{rem}
        However, if we know the factorisation of all numbers less than $i$, then we can easily find a prime factorisation of $i$: if $i$ is prime, then it is its own prime factorisation, and we are done; if $i$ is not prime, then we can get a prime factorisation of $i$ by concatenating the prime factorisations of two factors (which are smaller than $i$ and therefore whose prime factorisation we know by induction hypothesis).
      \end{rem}

    \end{proof}
  \end{exmp}

  \begin{exmp}
    Prove that ppostage of exactly $n$ cents can be made using only 5-cents and 8-cents stamps
    \begin{proof}
      Define the predicate $P(n)$ as follows
      \[
        P(n): \exists a,b\in\mathbb{N}, n = 5a + 8b
      \]
      Use proof by complete induction to prove $P(n)$ holds for $n \geq 28$. Let $i$ be an arbitrary integer such that $i\geq 28$, and assume that $P(j)$ holds for all $j$ such that $28 \leq j < i$. We will prove that $P(i)$ holds as well. \\
      \textbf{CASE 1 or the BASIS}: When $28 \leq i \leq 32$. We can make postage for all of them... Just have to calculate them... \\
      \textbf{CASE 2 or INDUCTION STEP}: When $i\geq 32$. Let $j = i-5$ and therefore, by induction hypothesis, $P(j)$ holds. This means that $\exists a,b \in\mathbb{N}, j=5a + 8b$.

      \begin{align*}
        i &= j + 5 \\
        &= 5a + 8b + 5\\
        &= 5(a+1) + 8b && &&\text{$a_1 = a + 1, b_1 = b$}\\
        &= 5a_1 + 8b_1 && &&\text{$a_1, b_1 \in\mathbb{N}$}\\
      \end{align*}

      Therefore, $P(i)$ holds as well.
    \end{proof}
    \begin{rem}
      In this problem, a set of basis were discussed instead of one. This is to ensure that the choice of $j$ satisfies $j \geq c$, which is required to use induction hypothesis.
    \end{rem}
  \end{exmp}

\end{defn}

\begin{defn}
  \label{floor and ceiling}

  \begin{align*}
    \lfloor x \rfloor &= max\{ m\in \mathbb{Z}: m \leq x\} \\
    \lceil x \rceil &= min\{ m\in \mathbb{Z}: m \geq x\}
  \end{align*}



\end{defn}

\begin{defn}
  \label{Principle of Well Ordering}
  \textbf{The Well Ordering Principle}\\ Any nonempty set $A$ of $\N$ contains a minimum element; ie, for any $A\subseteq \N$ such that $A\neq \emptyset$
  \[
    \exists a\in A, \forall a'\in A, a\leq a'
  \]
\end{defn}


\section*{4.1, 4.2 Structural Induction}

\begin{defn}
  \label{recursively defined sets}
  \textbf{Recursively Defined Sets}\\
  To define a set of objects
  \begin{enumerate}
    \item Define the simpliest or smallest objects in the set
    \item Define ways in which larger more complex objects in the set can be constructed from smaller or simpler objects in the set
  \end{enumerate}
\end{defn}



\begin{defn}
  \label{function closure}
  Let $S$ be a set, A k-nary operator on $S$ is a function
  \[
    f: S^k \to S \tag{ $S^k$ is the k-fold Cartesian product of S}
  \]
  We say that $A\subseteq S$ is \textbf{closed} under $f$ if,
  \[
    \forall a_1, a_2, \dots, a_k\in A, f(a_1), f(a_2), \dots, f(a_k)
\in A  \]
  \begin{exmp}
    $\N$ of $\mathbb{Z}$ is closed under addition but not closed on subtraction
  \end{exmp}
\end{defn}


\begin{defn}
  \label{Principle of Set Definition by Recursion}
  \textbf{Principle of Set Definition by Recursion}\\
  Let $S$ be a set, $B\subseteq S$, $m\in Z, m>0$, and $f_1, f_2, \dots, f_m$ be operators on $S$ of arity $k_1, k_2, \dots, k_m$, respectively,
  \[
    S_i =
    \begin{cases}
      B, & \text{ if } i=0\\
      S_{i-1} \cup \bigcup_{j=1}^{m}\{ f_j(a_1, a_2, \dots, a_{k_j}): a_1, a_2, \dots, a_{k_j}\in S_{i-1}\} & \text{ if } i>0
    \end{cases}
  \]
  Then $S_i$ is the smallest subset of $S$ that contains $B$ and is closed under $f_1, f_2, \dots, f_m$
\end{defn}




\begin{defn}
  \label{proof by structural induction}
  \textbf{Proof by Structural Induction}\\ To prove,
  \[
    \forall x\in X: P(x) \tag{ where $X$ is defined recursively}
  \]
  \textbf{Basis}: We prove that every smallest or simplest element of $X$ is satisfied by $P$\\
  \textbf{Induction Step}: We also prove that the infinitely many ways of constructing larger and more complex elements out of simpler and smaller ones \textit{preserves} property $P$
\end{defn}

\section*{3.1 Recursively Defined Function}

\begin{defn}
  \label{Principle of function definition by recursion}
  \textbf{Principle of function definition by recursion}\\
  Let $b\in\mathbb{Z}$, and $g:\N \times \mathbb{Z} \to \mathbb{Z}$ be a function. Then there is a unique function $f:\N \to \mathbb{Z}$ that satisfies the following:,
  \[
    f(n)=
    \begin{cases}
      b & \text{ if } n=0\\
      g(n, f(n-1)) & \text{ if } n>0 \\
    \end{cases}
  \]
  \begin{note}
    Recursively defined functions may not be well defined,
    \begin{enumerate}
      \item lacking base case
      \item inductive case either not defined for some $n$ or form a loop over iteself
    \end{enumerate}
  \end{note}

  \begin{exmp}
    The \textbf{The Fibonacci Function}
    \label{Fibonacci function}
    \[
      F(n) =
      \begin{cases}
        0 & n=0\\
        1 & n=1\\
        F(n-1) + F(n-2) & n>1
      \end{cases}
    \]
    which can be expressed as a closed-form formula,
    \[
      F(n) = \frac{\phi^n - \hat\phi^n}{\sqrt{5}} \tag{$\phi = \frac{1+\sqrt{5}}{2} \text{ , } \hat\phi = \frac{1-\sqrt{5}}{2} $}
    \]
  \end{exmp}
\end{defn}



\begin{defn}
  \label{Principle of function definition by complete recursion}
  \textbf{Principle of function definition by complete recursion}: \\
  Let $k, l$ be positive integers, $b_0,b_1,\dots,b_{k-1}$ be arbitrary integers, $h_1,h_2,\dots,h_l : \N \to \N$ be functions such that $h_i(n) < n$ for each $i$, $1\leq i\leq l $ and each $n \geq k$, and $g:\N\times \mathbb{Z}^l \to \mathbb{Z}$ be a function($Z^l$ denotes the $l$-fold Cartesian product of set $\mathbb{Z}$). Then there is a unique function $f : \N \to \mathbb{Z}$ that satisfies the following equation:
  \[
  f(n)=
  \begin{cases}
    b_n & 0 \leq n < k\\
    g(n, f(h_1(n)), f(h_2(n)), \dots, f(h_l(n))) & n \geq k\\
  \end{cases}
    \]
\end{defn}


\section*{2.2 Correctness Specification}

\begin{enumerate}
  \item A \textbf{precondition} for a program is an assertion involving some of the variables of the program;
  \item A \textbf{postcondition} for a program is an assertion involving some of the variables of the program; this assertion states what must be true when the program ends — in particular, it can describe what is a correct output for the given input.
  \item A program is \textbf{correct} with respect to the specification (or the program meets the specification), if whenever the \textbf{precondition} holds before the program starts \textbf{execution}, then the program \textbf{terminates} and when it does, the \textbf{postcondition} holds. Note that implicitly stated is that all variable stated in pre- and post-condition cannot be altered.
\end{enumerate}

\section*{2.3 Iterative Correctness of binary search}


\begin{defn}
  \label{loop invariant}
  An \textbf{invariant} is a condition that can be relied upon to be true during execution of a program. A \textbf{loop invariant} is a condition that is true at the beginning and end of every execution of a loop. Consider a program containing a loop. Let $P$ and $Q$ be predicates of (some of) the variables of the program. We say that $P$ is an \textbf{invariant} for the loop with respect to precondition $Q$ if, assuming the program’s variables satisfy $Q$ before the loop starts, the program’s variables also satisfy $P$ before the loop starts as well as at the end of each iteration of the loop. \\

  \begin{enumerate}
    \item “end of the 0-th iteration of the loop”: the point in the program just before entering the loop
    \item “each iteration of the loop”: includes this 0-th iteration
    \item \textit{An invariant is true at the end of each iteration of the loop, without explicitly saying that it is true before the loop.}
  \end{enumerate}
\end{defn}


\begin{algorithm}[H]
    \label{IterativeBinSearch Algorithm}
    \caption{Iterative Binary Search}
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwFunction{ibs}{IterativeBinSearch}

    \Fn{\ibs$(A, x)$}{
        \KwIn{$A$ is a sorted array of length at least 1}
        \KwOut{Return $t$ such that $1\leq t < length(A)$ and $A(t) = x$, if such a $t$ exists, otherwise return 0.}

        $f := 1$\\
        $l := length(A)$\\
        \While{$f\neq l$}{
          $m:= (f + l) \% 2$\\
          \eIf{$A[m] \geq x$}{
            $l := m$
          }{
            $f :=m + 1$
          }
        }
        \eIf{$A[f] = x$}{
          \Return $f$
        }{
          \Return 0
        }

    }

\end{algorithm}

$ $\\
\textbf{Proof for \textsc{IterativeBinSearch} correctness} \\
Suppose $A$ is a sorted array of length at least 1. \textsc{BinSearch}$(A,x)$ terminates and returns $t$ such that $1 \leq t \leq length(A)$ and $A[t] = x$, if such a $t$ exists; otherwise \textsc{BinSearch}$(A, x)$ terminates and returns 0. Same as,
\begin{enumerate}
  \item \textbf{Partial Correctness} Suppose $A$ is a sorted array of length at least 1. If \textsc{IterativeBinSearch}$(A, x)$ terminates then, when it does, it returns $t$ such that $1 \leq t \leq length(A)$ and $A[t] = x$, if such a $t$ exists; otherwise it returns 0.
  \item \textbf{Termination} Suppose $A$ is a sorted array of length at least 1. \textsc{IterativeBinSearch}$(A,x)$ terminates.
\end{enumerate}
$ $\\
To prove partial correctness, we prove that if precondition holds before program starts then the following is true at the end of each iteration of the loop,
\[
  1 \leq f \leq l \leq length(A)\text{, and if } x \text{ is in }A \text{ then }x \text{ is in }A[f..l].
\]
The loop ensures that the element $x$ being sought, if it is anywhere at all in the array, then it is in the part of the array that lies between indices $f$ (as a lower bound) and $l$ (as an upper bound).\\
Simply, we prove that the above is actually an \textbf{invariant} for the loop in \textsc{IterativeBinSearch} with respect to that program’s precondition. More precisely,\\

\begin{lemma}
  Suppose the precondition of \textsc{IterativeBinSearch} holds before the program starts. For each $i \in \N$, if the loop of \textsc{BinSearch}$(A, x)$ is executed at least $i$ times, then $1 \leq f_i \leq l_i \leq length(A)$, and if $x$ is in $A$, then $x$ is in $A[f_i..l_i]$
  \begin{proof}
    Define predicate,\\
    $P(i)$: if the loop is executed at least $i$ times, then \textit{(i)} $1 \leq f_i \leq l_i \leq length(A)$, and \textit{(ii)} if $x$ is in $A$, then $x$ is in $A[f_i..l_i]$\\
    Details in notes....
  \end{proof}
\end{lemma}

Then we can use the loop invariant and the loop exit condition ($f = l$) to obtain the postcondition\\
Also we need to prove that the loop terminates, specifically the loop terminates.
\begin{theorem}
  By the well ordering principle, every decreasing sequence of natural numbers is finite.
\end{theorem}
$ $\\
To prove the \textbf{termination of a loop} we typically proceed as follows. We associate with each iteration $i$ of the loop a number $k_i$, defined in terms of the values of the variables in the i-th iteration, with the properties that
\begin{enumerate}
  \item each $k_i$ is a natural number
  \item the sequence $⟨ k0,k1,k2,\dots ⟩$ is decreasing
\end{enumerate}
Then the loop must terminate, for otherwise we would have an infinite decreasing sequence of natural numbers.
$ $\\
In \textsc{IterativeBinSearch} we can associate with each iteration of the loop the value of the quantity $l_i - f_i$. This choice reflects the intuition that the reason the loop of BinSearch terminates is that the range of the array into which the search for $x$ has been confined gets smaller and smaller with each iteration. The fact that $l_i - f_i$ is a natural number follows immediately from the fact that $l_i$ and $f_i$ are natural numbers and, by previous lemma, $f_i \leq l_i$. It remains to show that the sequence $⟨ l_0 - f_0, l_1 - f_1, l_2 - f_2, \dots ⟩$ is decreasing.

\begin{lemma}
  For each $i \in \N$, if the loop is executed at least $i + 1$ times then $l_{i+1}-f_{i+1} < l_i-f_i$.
  \begin{proof}
    Details in notes...
  \end{proof}
\end{lemma}


\begin{lemma}
  For any integers $f$, $l$ such that $f<l$, $f\leq \lfloor \frac{f+l}{2}\rfloor <l$
  \begin{proof}
    Details in notes...
  \end{proof}
\end{lemma}


\textbf{Summary}\\
\begin{enumerate}
  \item Correctness proofs of iterative programs are typically divided into two parts: one proving \textbf{partial correctness} (i.e., that the program is correct assuming it terminates); and another proving \textbf{termination} (i.e., that the program does indeed terminate).
  \item The proof of termination typically involves associating a \textit{strictly decreasing} sequence of \textit{natural numbers} with the iterations of the loop, and apply the well-ordering principle.
  \item The proof of partial correctness of an iterative program is typically based on a \textbf{loop invariant}. Proving that a statement is a loop invariant involves induction. A trick to finding the proper looop invariant is to come up with one that, when used in conjunction with exit condition, implies postcondition
\end{enumerate}

\section*{2.7 Proof of correctness of recursive programs}

\begin{algorithm}[H]
    \label{recBinSearch Algorithm}
    \caption{Recursive Binary Search}
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwFunction{rbs}{RecBinSearch}

    \Fn{\rbs$(A, f, l, x)$}{
        \KwIn{$1 \leq f \leq l \leq length(A)$ and $A[f..l]$ is sorted.}
        \KwOut{Return $t$ such that $f \leq t \leq l$ and $A[t] = x$, if such a $t$ exists; otherwise, return 0.}

        \eIf{$f = l$}{
          \eIf{$A[f] = x$}{
            \Return $f$
          }{
            \Return 0
          }
        }{
          $m:= (f + l) \% 2$ \;
          \eIf{$A[m] \geq x$}{
            \Return \rbs$(A, f, m, x)$
          }{
            \Return \rbs$(A, m+1, l, x)$
          }
        }
    }
\end{algorithm}

\begin{lemma}
  Suppose that $f$ and $l$ are integers such that $1 \leq f \leq l \leq length(A)$, and that $A[f..l]$ is sorted when \textsc{RecBinSearch}$(A, f, l, x)$ is called. Then this call terminates and returns $t$ such that $f \leq t \leq l$ and $A[t] = x$, if such a $t$ exists; otherwise it returns 0.
  \begin{proof}
    \textbf{The induction will be on the length of this subarray}. Complete induction is necessary as recursive calls works on half of length of array.
  \end{proof}
\end{lemma}



\section*{3.2 Divide-and-conquer recurrences}
Inductively defined functions arise from analysis of many recursively defined functions. We can analyze \textbf{Divide and Conquer algorithms}, including binary search and merge sort, by first constructing a recurrence relation describing its time complexity and unwind the function in closed form.


\subsection*{1 Recursive binary search}
\label{recBinSearch}

\begin{defn}
  \label{correctness of recBinSearch}
  Suppose that $f$ and $l$ are integers such that $1\leq f\leq l\leq \text{ }length(A)$, and that $A[f..l]$ is sorted when \textbf{RecBinSearch($A$, $f$, $l$, $x$)} is called. Then this call terminates and return $t$ such that $f\leq t\leq l$ and $A[t] = x$, if such a $t$ exists; otherwise it returns a 0.
\end{defn}




\begin{lemma}
Suppose that $f$ and $l$ are integers such that $1 \leq f \leq l \leq length(A)$, and that $A[f..l]$ is sorted when \textsc{RecBinSearch}$(A, f, l, x)$ is called. Then this call terminates and returns $t$ such that $f \leq t \leq l$ and $A[t] = x$, if such a $t$ exists; otherwise it returns 0.

\begin{proof}
  Use induction to prove correctness on the length of subarray $A$. Note $length(A[f..l]) = l - f + 1$. Define predicate, \\
  $P(k)$: if $f$, $l$ are integers such that $1 \leq f \leq l \leq length(A)$ and $length(A[f..l]) = k$, and $A[f..l]$ is sorted when \textsc{RecBinSearch}$(A, f, l, x)$ is called, then this call terminates and returns some $t$ such that $f \leq t\leq l$ and $A[t] = x$, if such a $t$ exists; otherwise it returns 0. \\
  Now prove $P(k)$ holds for all $k\geq 1$\\
  \textbf{Basis:} \\
  Let $i=1$, let $f,l$ be integers such that $1\leq f\leq l \leq length(A)$ and $length(A)=1$. This means subarray $A$ has one element and $f=l$. \textit{if-statement} is executed and therefore program terminates by return statement at line 4 or 6. Since there is only one element in $A[f..l]$, then if $x$ is in $A$, it must be $A[f]=x$, so the program returns $f$ in line 4; on the other hand $x$ is not in $A[f..l]$, $A[f]\neq x$ so program returns 0 as expected in line 6. Either way, program returns the right value then $P(1)$ holds.\\
  \textbf{Inductive step:}\\
Let $i$ be an arbitrary integer such that $i > 1$. Let $f$, $l$ be integers such that $1 \leq f \leq l \leq length(A)$ and $length(A[f..l]) = i$, and suppose that $A[f..l]$ is sorted when \textsc{RecBinSearch}$(A, f, l, x)$ is called. Assume that $P(j)$ holds for all $j$ such that $1 \leq j < i$. We must prove that $P(i)$ holds as well. Since $length(A[f..l]) = i$ and $i > 1$, it follows that $f < l$. Therefore the “else” branch in lines 7–12 is executed. Let $m = (f + l) \% 2$. then
\[
  f\leq m<l
\]
\end{proof}
\end{lemma}


\subsection*{2 MergeSort}

\begin{defn}
  \label{MergeSort correctness}
  If $f,l$ are integers such that $1\leq f \leq l \leq length(A)$ and $length(A[f..l]) = k$ then \textbf{MergeSort($A$, $f$, $l$)} terminates and, when it does, $A[f..l]$ is sorted and all other elements of $A$ are unchanged.
\end{defn}

\begin{algorithm}[H]
  \DontPrintSemicolon
  \SetKwFunction{merge}{Merge}

  \Fn{\merge$(A, f, m, l)$}{
    \KwIn{$1\leq f\leq m\leq l\leq length(A)$ and $A[f..m], A[m+1..l]$ are sorted}
    \KwOut{$A[f..l]$ has the same element as before invocation (\textit{loop invariant}), in sorted order, and all other element of $A$ are unchanged}

    $i\leftarrow f$ \\
    $j\leftarrow m+1$ \\
    $k\leftarrow f$ \\
    \While(\tcc*[f]{Merge subarray until one is exhausted}){$i\leq f \land j\leq f$}{
      \eIf{$A[i] < A[j]$}{
        $aux[k] \leftarrow A[i]$ \\
        $i \leftarrow i+1$
      }{
        $aux[k] \leftarrow A[j]$\\
        $j \leftarrow j+1$
      }
      $k\leftarrow k+1$
    }
    \eIf(\tcc*[f]{Determine bounds of unexhausted array}){$i>m$}{
      $low \leftarrow j$ \\
      $high \leftarrow l$\\
    }{
      $low \leftarrow i$ \\
      $high \leftarrow m$
    }
    \For(\tcc*[f]{Copy unexhausted array to $aux$}){$t\leftarrow low$ \KwTo $high$}{
      $aux[k] \leftarrow A[t]$\\
      $k \leftarrow k+1$
    }
    \For(\tcc*[f]{Copy $aux$ back to $A[f..l]$}){$t\leftarrow f$\KwTo $l$}{
      $A[t]\leftarrow aux[t]$
    }
  }

  \caption{Merge}
\end{algorithm}

\begin{algorithm}[H]
  \label{mergesort algorithm}
  \DontPrintSemicolon
  \SetKwFunction{mergesort}{MergeSort}
  \SetKwFunction{merge}{Merge}


  \Fn{\mergesort$(A, f, l)$}{
    \KwIn{$1\leq f\leq l\leq length(A)$}
    \KwOut{$A[f..l]$ has the same element as before invocation (\textit{loop invariant}), in sorted order, and all other element of $A$ are unchanged}
    \eIf(\tcc*[f]{subarray of length 1 already sorted}){$f=m$}{
      \Return \tcc*[r]{do nothing}
    }{
      $m\leftarrow (a+b)//2$\\
      \mergesort$(A, f, m)$ \tcc*[f]{sort first half}\\
      \mergesort$(A, m+1, l)$ \tcc*[f]{sort second half}\\
      \merge$(A, f, m, l)$ \tcc*[f]{merge 2 sorted halves}
    }
  }
  \caption{Merge Sort}
\end{algorithm}


\begin{lemma}
  \label{sorting algorithm}
  A \textbf{sorted array} $A$ satisfies,
  \begin{align*}
    A[i] &\leq A[i+1] \tag{$\forall i\in \N, 1\leq i < \text{ }length(A)$}
  \end{align*}
\end{lemma}

\begin{lemma}
  \[
    \exists i,j\in \N, 1\leq i\leq j\leq length(A)
  \]
   $A[i..j]$ denotes the subarray of $A$ between indeces $i$ and $j$ with $n = length(A) = j-i + 1 $
\end{lemma}

\begin{lemma}
  For any integer $n>1$, $1\leq \lfloor \rfrac{n}{2}\rfloor \leq \lceil \rfrac{n}{2}\rceil < n$
\end{lemma}

\begin{lemma}
  \[
    \lfloor \frac{n+1}{2} \rfloor = \lceil \frac{n}{2} \rceil \text{ for some $n\in \mathbb{Z}$}
  \]
\end{lemma}


\begin{rem}
  Mergesort ideas:
  \begin{enumerate}
    \item If $n=1$, then array is already sorted
    \item Split $A$ to halves $A_1, A_2$, and recursively sort each
    \item Merge the now sorted subarray $A_1, A_2$ to a single sorted array
  \end{enumerate}
\end{rem}


\begin{defn}
  \label{MergeSort time complexity}
  Define $T(n)$ to be the maximum number of steps executed by a call to \textsc{MergeSort}$(A, f, l)$, where $n$ is the size of the subarray being sorted, i.e., $n = l-f+1$. Then function $T$ describes the (worst case) \textbf{time complexity} of
  \textsc{MergeSort}$(A, f, l)$ as a function of size of array sorted.
  \[
    T(n)=
    \begin{cases}
      c, & \text{if } n = 1\\
      T(\lceil \rfrac{n}{2}\rceil) + T(\lfloor \rfrac{n}{2} \rfloor) + dn, & \text{if } n>1
    \end{cases}
  \]
  Note that $c$ is some constant for sorting array of length 1. And the merging algorithm takes time proportional to $n$, with some constant $d$. To simplify the problem, assume $n$ is a power of 2
  \[
    T(n)=
    \begin{cases}
      c, & \text{if } n = 1\\
      2T(\rfrac{n}{2}) + dn, & \text{if } n>1
    \end{cases}
  \]
  Find closed form formula for $T(n)$ by \textbf{repeated substitution}, where we unwind recursive definition of $T(n)$ by applying induction step of the definition to smaller and smaller argument of $T$ until we discover a pattern. Let $n=2^k$, given $k\leq \log_2{n}$, the $\rfrac{n}{2^k}$ is also power of 2. Therefore able to use induction hypothesis. The following conjecture can be proven using induction.

  \begin{align*}
    T(n) &= 2T(2^{k-1}) + d2^k \\
    &= 2( 2T(2^{k-2}) + d2^{k-1}) + d2^k \\
    &= 2^2T(2^{k-2}) + 2d2^k \\
    \vdots\\
    &= 2^kT(1) + kd2^k \\
    &= cn + dn\log_2{n} \tag{ $k=\log_2{n}$ and $T(1) = 1$}
  \end{align*}

  The purpose of this expression is to prove $T(n)\in \mathcal{O}(n\log{n})$ and $T(n)\in \Omega(n\log{n})$,
  \begin{align*}
    &\exists \kappa\in\R^+: \forall n\geq2: T(n) \leq \kappa n\log_2{n}\\
    &\exists \kappa\in\R^+: \forall n\geq2: T(n) \geq \kappa n\log_2{n}\\
    &\text{where the value of $\kappa$ depends on $c,d$}
  \end{align*}

  \begin{theorem}
    \label{big O of mergesort proof}
    Prove $\exists \kappa\in\R^+, \forall n\geq 2, T(n)\leq \kappa n\log_2{n}$ where $T(n) = cn + dn\log_2{n}$ if $n$ is a power of 2.

    \begin{proof}
      $ $\\
      Let $\hat{n} = 2^{\lceil log_2{n}\rceil}$, here $\hat{n}$ is the smallest integer that is a power of 2 greater than or equal to $n$, i.e.,
      \[
        \frac{\hat{n}}{2} < n\leq \hat{n}
      \]
      \begin{align*}
        T(n) &\leq T(\hat{n}) \tag{here requires proving $T(n)$ non-decreasing by induction}\\
        &\leq c\hat{n} + d\hat{n}\log_2{\hat{n}} \tag{ by $T(n) = cn + dnlog_2{n}$ if $n$ is a power of 2}\\
        &\leq 2cn + 2dn\log_2{2n} \tag{$2n>\hat{n}$} \\
        &= 2cn + 2dn+ 2dn\log_2{n} \\
        &\leq 2cn\log_2{n} + 2dn\log_2{n} + 2dn\log_2{n} \tag{$\log_2{n} > 1$ for $n\geq 2$}\\
        &= \kappa n\log_2{n} \tag{let $\kappa = 2c+4d$; $\kappa > 0$}
      \end{align*}
      Therefore $\exists \kappa \geq 0, \forall n\geq 2, T(n)\leq\kappa n\log_2{n}$ or that $T(n)\in \mathcal{O}(n\log_2{n})$
    \end{proof}
  \end{theorem}
\end{defn}

\begin{defn}
  \label{big O}
  \textbf{Big O notation: } function $g(n)$ is in $O(f(n))$ iff
  \[
    \exists c\in \R^+: \exists N\in \N: \forall n\geq N \Rightarrow (g(n)\leq cf(n))
  \]
\end{defn}

\begin{defn}
  \textbf{General form of divide-and-conquer algorithm} \\
  An \textbf{instance} is a legitimate input for the problem. A \textbf{solution} of an instance is an output for the instance. Each instance has a \textbf{size}.\\

  \textit{Steps for solving a large problem,}
  \begin{enumerate}
    \item Divide up the given instance of size $n$ into a total of $a$ smaller instances of the \textit{same problem}, each of size \textit{roughly} $\frac{n}{b}$. ($\frac{n}{b}$)
    \item Recursively solve each of the smaller instances (valid because smaller they are of same problem)
    \item Combine the solutions to the smaller instances into the solution of the given “large” instance.
  \end{enumerate}

  \textit{Step 1 and 3}, i.e. dividing up instances and combining solutions to the smaller instances, is given by polynomial time $dn^l$. Recursive solution of smaller instances require $a_1T(\lceil \frac{n}{b}\rceil) + a_2T(\lfloor \frac{n}{b}\rfloor)$ steps; this is time required to solve $a_1$ instances of size $\lceil \frac{n}{b}\rceil$ and $a_2$ instances of $\lfloor \frac{n}{b}\rfloor$. \textbf{Recurrence relationship} of $T(n)$ follows,

  \begin{equation*}
    f(n) =
    \begin{cases}
      c, & \text{ if }1\leq n < b\\
      a_1T(\lceil \frac{n}{b}\rceil) + a_2T(\lfloor \frac{n}{b}\rfloor) + dn^l, & \text{ if } n\geq b
    \end{cases}
  \end{equation*}

  where $a_1, a_2\in \N, a = a_1 + a_2$, $b\in \N, b>1$. As an example, \textsc{MergeSort} has $a_1 = 1$, $a_2 = 1$, $b = 2$, $l = 1$

  To find the \textbf{closed form} of $T(n)$, consider simplify by considering $n$ as power of $b$. Then,

  \begin{equation*}
    f(n)
    \begin{cases}
      c,  & \text{ if } n = 1\\
      aT(\frac{n}{b}) + dn^l, & \text{ if } n > 1
    \end{cases}
  \end{equation*}
  where $a = a_1 + a_2$

  \begin{theorem}
    \label{maste theorem}
    There is a constant $\kappa \geq 0$ (that depends on $a$,$b$,$c$,$d$ and $l$) so that, for all integers $n \geq b$ that are powers of $b$, the function $T(n)$ satisfies,
    \begin{equation*}
      f(n)=
      \begin{cases}
        \kappa n^l, & \text{ if } a< b^l\\
        \kappa n^l \log_b{n}, & \text{ if } a=b^l\\
        \kappa n^{\log_b{a}}, & \text{ if } a> b^l
      \end{cases}
    \end{equation*}
    \begin{rem}
      Correspondingly, we can expand the theorem to all of $n$ and set up the upper and lower bounds of $f(n)$, thereby poving
      \begin{equation*}
        T(n)\in
        \begin{cases}
          \Theta(n^l), & \text{ if } a< b^l\\
          \Theta(n^l \log_b{n}), & \text{ if } a=b^l\\
          \Theta(n^{\log_b{a}}), & \text{ if } a> b^l
        \end{cases}
      \end{equation*}
    \end{rem}
  \end{theorem}


\end{defn}

\begin{defn}
  \label{closest pair problem}
  \textbf{Closest Pair Problem} Given $n$ points in metric space, find a pair of point with closest distance between them. By brute force, the algorithm requires $O(n^2)$, It is however possible to achieve $O(n\log_2{n})$ with divide-and-conquer following
  \begin{enumerate}
    \item $O(1)$ Split set of points $S$ of size $n$ into roughly two subsets $S_1, S_2$ such that $|S_1| \approx |S_2|$ with line $l$ based on x-coordinate
    \item $T(\lceil \frac{n}{2}\rceil) + T(\lfloor \frac{n}{2}\rfloor)$ Recursively compute mimimum distance $m_1, m_2$ for $S_1, S_2$.
    \item $O(1)$ Set $d = Minimum(m_1, m_2)$
    \item $O(n)$ Eliminate points that are over $d$ from $l$
    \item $O(\log{n})$ Sort rest of the points based on y-coordinate
    \item $O(n)$ Scan the remaining points in the $y$ order and compute the distances of each point to its five neighbors. (This is because a rectangle of width $d$ and height $2d$ can contain at most 6 points such that any 2 points are at distance $d$ apart. Implies that there's at most 6 point at the other set such that their distance to each other is at least $d$)
    \item update $d$ if any of distances was less than $d$
  \end{enumerate}

\end{defn}


\section*{7.1 Introduction to Formal Language}


\textbf{Terminology}

\begin{enumerate}
  \item \textbf{Alphabet}: a set $\Sigma$ whose elements are called \textbf{symbols}, i.e. $\{0, 1\}$
  \item \textbf{String}: a finite sequence of symbols from $\Sigma$, i.e. $01001$. The empty string is denoted as $\epsilon$. Note the strings are representatively concatenated.
  \begin{enumerate}
    \item \textbf{Length} of string $| x |$
    \item \textbf{Concatenation} of string $x\circ y$ is $xy$
    \item \textbf{Reversal} of string $(x)^R$ is obtained by listing elements of $x$ in reverse order
    \item \textbf{Exponentiation} k-th power of $x$ is $x^k$, represented by
    \begin{align*}
      x^k =
      \begin{cases}
        \epsilon, & k=0\\
        x^{k-1}\circ x, &x>0
      \end{cases}
    \end{align*}
    Exponentiation of strings is repeated concatenation.
    \item \textbf{Equality}: Two strings are equal if $|x| = |y|$ and if every $i$-th item of $x$ is same as $i$-th item of $y$
    \item \textbf{Substring}: String $x$ is a substring of $y$ if exists $x_1, x_2$ such that $y=x_1 x x_2$. If $x_1,x_2\neq \epsilon$, then $x$ is a \textbf{proper substring} of $y$.
    \item \textbf{Prefix/Suffix}: A string $x$ is a prefix for $y$ if exists $x_1$ such that $x x_1 = y$, if $x_1 \neq \epsilon$ then $x$ is a proper substring of $y$. Similarly for Suffix.
  \end{enumerate}
  \item The set of all string over alphabet $\Sigma$ is denoted as $\Sigma^*$. $\Sigma^*$ can also be defined recursively by construction...
  \begin{center}
    \textbf{Basis}: $\epsilon \in \Sigma^*$\\
    \textbf{Inductive step}: If $x\in \Sigma^*$ and $a\in \Sigma$, then $xa\in \Sigma^*$
  \end{center}
\end{enumerate}

\begin{theorem}
  For all strings $x$ and $y$, $(xy)^R = (x)^R (y)^R$.
\end{theorem}


\begin{theorem}
  \label{language}
  A (formal) \textbf{language} $L$ over the set $\Sigma$ is a subset of $\Sigma^*$
  \begin{rem}
    A language may be infinite, but each \textit{string} in the language must be finite. Also $\emptyset$ and $\{\epsilon\}$ are different languages
  \end{rem}
\end{theorem}

\begin{defn}
  \label{Operations on language}
  \textbf{Operations on Language}: Let $L, L'$ be languages over $\Sigma$
  \begin{enumerate}
    \item \textbf{Complementation: } $\overline{L} = \Sigma^* - L$
    \item \textbf{Union: } $L\cup L' = \{ x: x\in L \lor x\in L'\}$
    \item \textbf{Intersection: } $L\cap L' = \{ x: x\in L \land x\in L'\}$
    \item \textbf{Concatenation: } $L\circ L' = \{ xy: x\in L, y\in L'\} $. Note $\emptyset \circ L = L\circ \emptyset = \emptyset$
    \item \textbf{Kleene star: } $L^{\star}$ of language $L$ is the set of all possible concatenation of 0 or more strings in $L$, defined recursively as
    \begin{center}
      \textbf{Basis: } $\epsilon \in L^{\star}$\\
      \textbf{Inductive step: } If $x\in\L^{\star}$ and $y\in L$, then $xy\in L^{\star}$
    \end{center}
    Therefore, a string $x$ belongs to $L$  if and only if either $x = \epsilon$ or there exists some integer $k \geq 1$ and strings $x_1,\dots,x_k \in L$ such that $x = x_1x_2 \dots x_k$.
    \item \textbf{Language Exponentiation: } for any $k\in \N$, $L^k$ is the set of strings obtained by concatenating $k$ strings of $L$. For any $k$,
    \begin{align*}
      L^k =
      \begin{cases}
        \{ \epsilon \}, & k=0\\
        L^{k-1} \circ L. & k> 0
      \end{cases}
    \end{align*}
    Note $L^1 = L$
    \item \textbf{Reversal: } The reversal of $L$, $Rev(L)$ is the set of reversals of the strings in $L$
    \[
      Rev(L) = \{ (x)^R: x\in L\}
    \]
  \end{enumerate}

\end{defn}


\section*{7.2 Regular Expressions}

\begin{defn}
  \textbf{Regular expressions} is a notation for describing languages.
  \\
  Let $\Sigma$ be a finite alphabet, the set of \textbf{regular expression} $RE$ (over $\Sigma$) is the smallest set such that\\
  \begin{center}
    \textsc{Basis}: $\emptyset, \epsilon, a$ (for each $a\in \Sigma$) belong to $RE$\\
    \textsc{Inductive step}: If $R$ and $S$ belong to $RE$, then $(R+S)$, $(RS)$, $R^*$ also belong to $RE$
  \end{center}
  Use these words to describe the language denoted by the regular expression.
  \begin{enumerate}
    \item \textbf{alteration} $+$, informally meaning \textit{or}
    \item \textbf{concatenation}, informally meaning \textit{followed by}
    \item \textbf{repetition} $*$, informally meaning \textit{zero or more repetitions of}
  \end{enumerate}
\end{defn}

\begin{defn}
  The \textbf{language denoted by a regular expression} $R$ is defined by structural induction on $R$,\\
  \textbf{Basis}: Either $R=\emptyset$, or $R=\epsilon$, or $R=a$, for some $a\in\Sigma$. For each case we define $L(R)$,
  \begin{itemize}
    \item $L(\emptyset) = \emptyset$ (the empty language consisting of no strings)
    \item $L(\epsilon) = \epsilon$ (the language consisting of just empty string)
    \item for any $a\in \Sigma$, $L(a) = \{ a \}$ (langauge consisting of a one-symbol sting $a$)
  \end{itemize}
  \textbf{Inductive step:} Either $R = S+T$, $R = (ST)$, or $R=S^*$, for some expression $S$ and $T$. We define $L(R)$,
  \begin{itemize}
      \item $L((S+T)) = L(S)\cup L(T)$
      \item $L((ST)) = L(S)\circ L(T)$
      \item $L(S^*) = (L(S))^*$
  \end{itemize}

  \begin{rem}
    Note concatenation takes precedence over union. Also we might want to prove equivalence of a language and a language denoted by a regular expression, specifically,
    \[
      L(R) = L
    \]
    To prove $x\in L(R) \Rightarrow x\in L$, we unwind regular expression using definition of language listed previously and express $x$ as a concatenation of strings. \\
    To prove $x\in L \Rightarrow x\in L(R)$, we try to break down $x$ according to requirement of the language and categorize them into corresponding langugaes, whose composition is the desired $L(R)$
  \end{rem}
\end{defn}

\begin{defn}
  \textbf{Equivalence of Regular Expressions} Two regular expressions are equivalent, $R\equiv S$, if they denote the same language, i.e. $L(R) = L(S)$
  \begin{itemize}
    \item $(R+S)\equiv (S+R)$
    \item $((R+S) + T)\equiv (R+(S+T))$
    \item $((RS)T)\equiv (R(ST))$
    \item $(R(S+T))\equiv ((RS) + (RT))$
    \item $((S+T)R)\equiv (SR+TR)$
    \item $(R+\emptyset)\equiv R$
    \item $(R\epsilon)\equiv R\equiv (\epsilon R)$
    \item $(\emptyset R) \equiv \emptyset \equiv (R\emptyset)$
    \item $R^{*^*}\equiv R^*$
    \item $((\epsilon + R)R^*) \equiv R^*$
  \end{itemize}
  \begin{rem}
    We can use these equivalent expressions to simplify regular expressions
  \end{rem}
\end{defn}





\section*{7.3 Definitive Finite State Automaton}

A Definitive Finite State Automaton is a mathematical model of a machine which, given any input string $x$, accepts or rejects $x$. The automaton has a finite set of states, including a designated initial state and a designated set of accepting states. \\
It is customary to represent automata as directed graphs, with nodes (circles) corresponding to states, and edges (arcs) labeled with the symbols of the alphabet. An edge from state $q$ to state $q'$, labeled with symbol $a$, indicates that if the current state is $q$ and the current input symbol is $a$, the automaton will move to state $q$. The initial state of the automaton is indicated by drawing an unlabeled edge into that state coming from no other state. The accepting states are indicated by double circles.\\

\begin{defn}
  \label{DFSA}
  A \textbf{DFSA} $M$ is a quintuple $M=(Q, \Sigma, \delta, s, F)$
  \begin{enumerate}
    \item  $Q$ is a finite set of \textbf{states}.
    \item $\Sigma$ is a finite \textbf{alphabet}.
    \item $\delta: Q\times \Sigma \rightarrow Q$ is the \textbf{transition function}. In terms of the diagrammatic representation of the FSA, $\delta(q, a) = q'$ means that there is an edge labeled a from state $q$ to state $q'$.
    \item $s \in Q$ is the start or \textbf{initial state}.
    \item $F \subseteq Q$ is the \textbf{set of accepting states}.
  \end{enumerate}
  \begin{rem}
    we can define the \textbf{extended transition function} $\delta^* :Q\times \Sigma^* \rightarrow Q$. Intuitively, if $q \in Q$ and $x \in \Sigma^∗$, $\delta^∗(q,x)$ denotes the state in which the automaton will move after it processes input $x$ starting in state $q$. If $\delta^* (q, x) = q'$, we say that $x$ takes the automaton $M$ from $q$ to $q'$
  \end{rem}
  \begin{rem}
    DFSA is \textbf{complete} is there is a transition on every symbol from each state.
  \end{rem}
\end{defn}

\begin{defn}
    A string $x\in\Sigma^*$ is \textbf{accepted} by $M$ if and only if $\delta^*(s,x)\in F$, i.e. if and only if $x$ takes the automaton from the initial state to an accepting state.The \textbf{language accepted} by a DFSA $M$, denoted $L(M)$, is the set of all strings accepted by $M$.
\end{defn}


\begin{defn}
  \textbf{Conventions for DFSA diagrams}
  \begin{itemize}
    \item \textbf{Combining transitions}
    \item \textbf{Eliminating dead states}. A state $q_{reject}$ is dead if no accepting state is reachable from $q_{reject}$, i.e. there is no path that starts at $q_{reject}$ and ends at accepting state.
  \end{itemize}

\end{defn}

\begin{defn}
  \textbf{Designing and proving correctness of DFSA}
  For example, A DFSA that accepts the language,
  \[
    L_1 = \{ x\in\{ 0, 1 \}, x \text{ has odd number of 0s and odd number of 1s}\}
  \]
  An \textbf{state invariant} for a particular state describes what is true about the state. To prove state invariant for one state, we need to use induction on length of input string $x$ and prove state invariant for each and every states, i.e.,
  \[
    P(x): \delta^*(q_0, x) =
    \begin{cases}
      q_0, & \text{ if $x$ has an even number of 0s and an even number of 1s}\\
      q_1, & \text{ if $x$ has odd number of 0s and an even number of 1s}\\
      q_2, & \text{ if $x$ has an even number of 0s and an odd number of 1s}\\
      q_3, & \text{ if $x$ has an odd number of 0s and odd number of 1s}\\
    \end{cases}
  \]
  Note that only $if$ is required for state invariant predicate $P(x)$.Then we prove $P(x)$ holds for all strings $x$ by structural induction.
  \begin{proof}
    $ $\\
    \textit{BASIS}: when $x=\epsilon$, $x$ has zero(even) number of 0s and zero(even) number of 1s and also $\delta^*(q_0, \epsilon) = q_0$, $P(x)$ holds.\\
    \textit{INDUCTIVE STEP:} when $x=ya$, where $y\in\Sigma^*$ and $a\in\Sigma$. Assume that $P(y)$ holds, and discuss 2 cases where $a$ can be any symbol in the alphabet. Essentially, we concatenate another character from $\Sigma$ and see if the state invariant holds.
  \end{proof}

  Once we proved state invariant, we prove equivalence of language to show that a DFSA accepts a certain language
  \[
    L = L(M) \iff L\subseteq L(M) \land L\supseteq L(M)
  \]
  Remember a string is in $L(M)$ if $\delta^*(q_0, x) \in F$, the accepting states.
\end{defn}


\begin{defn}
  Systematically finding the union of DFSA $M_1$ and $M_2$, $M=M_1\cup M_2$. If $M_1$ has $Q_1=\{ p_0, p_1\}$ and $M_2$ has $Q_2=\{ q_0, q_1\}$, then their union $M$ has the same alphabet, and a different state $Q = Q_1 \times Q_2 = \{ (p_0, q_0), (p_0, q_1), (p_1, q_0), (p_1, q_1)\}$, start state $s=(p_0, q_0)$, and final states including states where any of the states were accepted in $M_1$ or $M_2$
\end{defn}



\section*{7.4 Nondeterministic finite state automata}

In a DFSA, a given state and current input symbol uniquely determine the next state of the automaton. There is a variant of finite state automata, called \textbf{nondeterministic finite state automata}, abbreviated NFSA, where this is not the case: From a given state, when the automaton reads an input symbol $a$, there may be \textbf{several states to which it may go next}. Furthermore, the automaton may “spontaneously” move from one state to another without reading any input symbol; such state transitions are called \textbf{$ \epsilon$-transitions}. The computation of a NFSA on input $x$ corresponds to not a single path, as in the case of DFSA, but to \textbf{a set of paths}.

the NFSA accepts $x$ if there is (at least) one computation path that it could follow on input $x$ that ends in an accepting state. A string is rejected only if \textit{every} computation path the NFSA could have followed ends in a nonaccepting state.

Presentationally, a FSA is considered a NFSA if there are more than one edge with the same symbol originating from the same node.


\begin{defn}
  \textbf{nondeterministic finite state automaton (NFSA)} is a quintuple $M=(Q, \Sigma, \delta, s, F)$, where
  \begin{itemize}
    \item $Q$ is a finite set of \textbf{states}
    \item $\Sigma$ is a finite alphabet
    \item $\delta: Q\times (\Sigma \cup \{ \epsilon \}) \rightarrow \rho (Q)$ is the \textbf{transition function} Note here $\rho (Q)$ represents proper subset of $Q$, a set.
    \item $s\in Q$ is the start or \textbf{initial} state
    \item $F\subseteq Q$ is the set of \textbf{accepting} states
  \end{itemize}
  \begin{rem}
    Note \textbf{extended transition function}
    \[
      \delta^*: Q\times \Sigma^* \rightarrow \rho(Q)
    \]
  \end{rem}
  A NFSA $M=(Q, \Sigma, \delta, s, F)$ \textbf{accepts} a string $x\in \Sigma^*$ if and only if $\delta^*(s,x)\cap F\neq \emptyset$ (In other words $M$ accepts $x$ if and only if there is at least one of the possible states in which the automaton could be after processing input $x$ is an accepting state) \textbf{The language accepted by} $M$, $L(M)$, is the set of strings accepted by $M$.
\end{defn}


\begin{theorem}
  \textbf{Equivalence of DFSA and NFSA}
  Any language that is accepted by a NFSA is accepted by a DFSA\\
  DFSA is a special case of NFSA, where we restrict transition function in certain ways. Therefore, NFSA is at least as powerful as DFSA. We can construct a DFSA from a NFSA via \textbf{subset construction}
\end{theorem}

\begin{defn}
  \textbf{Proof of correctness for NFSA} Just think about the path to accepted states and express it in terms of language; also think about the language and extrapolate what path the string will take the automata to, and if the final state is one of the accepting states.
\end{defn}



\section*{7.5 Closure properties of FSA-accepted languages}

\begin{theorem}
  The class of languages accepted by FSA is closed under complementation, union, intersection, concatenation, and Kleene star operation. In other wards, if $L$ and $L'$ are langauges that are accepted by FSA, then so are all of the following $\bar{L}, L\cup L', L\cap L', L\circ L', L^*$
\end{theorem}


\section*{7.6 Equivalence of regular expression and FSA}

\begin{theorem}
  For every regular expression $R$ there is a FSA $M$ such that
  \[
    L(M) = L(R)
  \]
  \begin{rem}
    Intuitively we recursively construct FSA that accept the language by the subexpressions of $R$,  and combine these automata with $\epsilon$ transition to accept the language denoted by the entire expression $R$.
    \begin{itemize}
      \item we use an $\epsilon$ transition to concat two strings
      \item we use branched $\epsilon$ transition to make unions
      \item we use an $\epsilon$ transition leading to a previous state to represent Kleene star.
    \end{itemize}
  \end{rem}
\end{theorem}

\section*{7.6 Regular Languages}

\begin{defn}
  Let $L$ be a language, then the following statements are equivalent,
  \begin{enumerate}
    \item $L$ is denoted by a regular expression
    \item $L$ is accepted by a deterministic FSA
    \item $L$ is accepted by a nondeterminstic FSA
  \end{enumerate}
  A language is called \textbf{regular} if and only if it is denoted by some regular expression, or equivalently, if and only if it is accepted by a FSA.
\end{defn}


\section*{7.7 Proving nonregularity:  the Pumping Lemma}

There are languages not accepted by FSA because FSA has only a fixed number of states, implying that it can only remember a bounded amount of things. For example,
\[
  \{ 0^n1^n: n\geq 0\}
\]

The \textbf{Pumping lemma} can be used to prove that languages are not regular. Intuitively, it states that any sufficiently long string of a regular language $L$ has a nonempty substring which can be repeated ('pumped') an arbitrary number of times, with the resulting string still being in $L$.

\begin{theorem}
  \textbf{Pumping Lemma} Let $L\subseteq \Sigma^*$ be a regular language. Then there is some $n\in\N$ (that depends on $L$) so that every $x\in L$ that has length $n$ or more satisfies the following property

  \begin{center}
    There are $u,v,w\in \Sigma^*$ such that $x=uvw$, $v\neq \epsilon$, and $uv^kw\in L$, for all $k\in\N$
  \end{center}

  \begin{rem}
    To prove that a language is not regular, we assume for contradiction that $L$ is regular. Therefore we let $n\in\N$ be the natural numbe which the Pumping lemma assserts that exists if $L$ is regular. And then construct a string $x = uv^kw$ that is not in the language for all $k\in\N$. The trick is trying to pick an exponent $m$ such that $m>n$ so that pumping must have happened if $L$ is regular.
  \end{rem}
\end{theorem}





% end document
\end{document}
