\documentclass[11pt]{article}
\input{/Users/markwang/.preamble}
\begin{document}



% arg1=pdfurl arg2=pagenum arg3=sectiontitle
\newcommand{\linksection}[3][../../linear_algebra_friedberg_insel_spence_4ed.pdf]{
    \subsection*{\href[page=#2]{#1}{#3}}
}

\newcommand{\linkinline}[3][../../linear_algebra_friedberg_insel_spence_4ed.pdf]{
    \noindent\href[page=#2]{#1}{#3}
}

\newcommand{\linksolution}[3][../../solution_compiled.pdf]{
    \noindent\href[page=#2]{#1}{#3} \\
}

\newcommand{\vecspace}{\mathcal{V}}
\newcommand{\field}{\mathcal{F}}
\newcommand{\trace}[1]{tr(#1)}
\renewcommand{\span}[1]{span(#1)}
\renewcommand{\dim}[1]{dim(#1)}
\newcommand{\nullity}[1]{nullity(#1)}
\newcommand{\rank}[1]{rank(#1)}
\newcommand{\cvec}[2]{\left[ #1 \right]_{#2}}
\renewcommand{\matr}[3]{\left[ #1 \right]_{#2}^{#3}}
\newcommand{\ltspace}[1]{\mathcal{L}(#1)}
\renewcommand{\det}[1]{det(#1)}
\newcommand{\tinvariant}[2]{\langle#2\rangle_{#1}}
\newcommand{\innerp}[2]{\langle#1,#2\rangle}
\renewcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\orthocomp}[1]{#1^{\perp}}
\newcommand{\divides}{\mid}
\renewcommand\qedsymbol{$\blacksquare$}


\linksection{34}{Direct Sum Definition}

\begin{defn*}
    \textbf{Summation of Sets} If $S_1$ and $S_2$ are nonemtpy subsets of a vector space $V$, then the \textbf{sum} of $S_1$ and $S_2$, denoted $S_1 + S_2$, is the set 
    \[
        \{x+y : x\in S_1 \text{ and } y\in S_2\}    
    \]
    \begin{enumerate}
        \item $W_1+W_2$ is a subspace of $V$ containing both $W_1$ and $W_2$
        \item If for a subset $S\subseteq V$, $W_1\subseteq S$ and $W_2\subseteq S$, then $W_1+W_2\subseteq S$
    \end{enumerate}
\end{defn*}

\begin{defn*}
    \textbf{Direct Sum} A vector space $V$ is called the direct sum of $W_1$ and $W_2$, denoted as $V = W_1 \oplus W_2$, if $W_1$ and $W_2$ are subspaces of $V$ such that 
    \begin{enumerate}
        \item $V = W_1 + W_2$
        \item $W_1 \cap W_2 = \{0\}$ (implies uniqueness)
    \end{enumerate}
    More generally, assume $W_1, \cdots, W_k$ are subspaces of $V$, then $V = W_1 \oplus W_2 \oplus \cdots \oplus W_k$ if
    \begin{enumerate}
        \item $V = W_1 + \cdots + W_k$
        \item $W_i \bigcap (\textstyle\sum_{j\neq i} W_j) = \{ 0\} $
    \end{enumerate}
    \begin{enumerate}
        \item Direct sum of the set of upper triangular like matrices and lower triangular matrices is $M_{m\times n}(F)$
        \item The trick of decomposing vector space into direct sums is that the intersection of subsets yield the zero vector
    \end{enumerate}
\end{defn*}




\linksection{330}{5.4 Invariant Subspaces and Direct Sum}


\linksection{494}{Chapter 7 Canonical Forms}
\linksection{494}{7.1 The Jordan Canonical Form}


\begin{defn*}
    \textbf{Jordan Block and Jordan Canonical Form} Select ordered basis whose union is an ordered basis $\beta$, the Jordan caconical basis for $T$, for $V$ such that 
    \[
        \cvec{T}{\beta} = 
        \begin{pmatrix}
            A_1 & O & \cdots & O \\
            O & A_2 & \cdots & O \\
            \vdots & \vdots & & \vdots \\
            O & O & \cdots & A_k \\ 
        \end{pmatrix}    
    \]
    where $A_i$ are jordan block corresponding to $\lambda$
    \[
        A_i = 
        \begin{pmatrix}
            \lambda
        \end{pmatrix}
        \qquad 
        \text{or}
        \qquad 
        A_i = 
        \begin{pmatrix}
            \lambda & 1 & O & \cdots & O & O \\
            O & \lambda & 1 & \cdots & O & O \\
            \vdots & \vdots & \vdots & & \vdots & \vdots \\
            O & O & O & \cdots & \lambda & 1 \\ 
            O & O & O & \cdots & O & \lambda \\ 
        \end{pmatrix}
    \]
\end{defn*}


\begin{defn*}
    \textbf{Generalized Eigenvector} Let $T$ be a linear operator on a vector space $V$, and let $\lambda$ be a scalar. A nonzero vector $x$ in $V$ is called a generalized eigenvector of $T$ corresponding to $\lambda$ if $(T-\lambda I)^p(x) = 0$ for some positive integer $p$
    \begin{enumerate}
        \item For $v$ in a Jordan canonical basis for $T$, $(T-\lambda I)^p (v) = 0$ for sufficiently large $p$. Eigenvectors satisfy this condition for $p=1$
        \item If $x$ is a generalized eigenvector of $T$ corresponding to $\lambda$, and $p$ is smallest positive integer for which $(T-\lambda I)^p(x)=0$, then $(T-\lambda I)^{p-1}(x)=0$ is an eigenvector of $T$ corresponding to $\lambda$
        \[
            (T-\lambda I)(v) = 0
            \qquad 
            \text{ where eigenvector }
            v = (T-\lambda I)^{p-1}(x) \neq 0
        \]
    \end{enumerate}
\end{defn*}

\begin{defn*}
    \textbf{Generalized Eigenspace} Let $T$ be a linear operator on a vector space $V$, and let $\lambda$ be an eigenvalue of $T$. The generalized eigenspace of $T$ corresponds to $\lambda$, denoted $K_{\lambda}$, is the subset of $V$ defined by 
    \[
        K_{\lambda} = 
        \{ x\in V: (T-\lambda I)^p(x) = 0 \text{ for some positive integer } p\} = 
        \bigcup_{p\geq 1} N((T-\lambda I)^p)
    \]
    \begin{enumerate}
        \item Note 
        \[
            N(U) \subseteq N(U^2) \subseteq \cdots \subseteq N(U^k) \subseteq N(U^{k+1}) \subseteq \cdots
        \]
    \end{enumerate}
\end{defn*}


\begin{theorem*}
    \textbf{7.1 Properties of Generalized Eigenspace} Let $T$ be linear operator on a vector space $V$, and let $\lambda$ be an eigenvalue of $T$. Then 
    \begin{enumerate}
        \item $K_{\lambda}$ is a T-invariant subspace of $V$ containing $E_{\lambda}$ (the eigenspace of $T$ corresponding to $\lambda$)
        \item For any scalar $\mu \neq \lambda$, the restiction $T - \mu I$ to $K_{\lambda}$ is one-to-one.
        \begin{enumerate}
            \item $E_{\mu} = N(T-\mu I) = 0$ for all $\mu \neq \lambda$, so $\lambda$ is the only eigenvalue of $T_{\lambda_k}$
            \item For $\mu \neq \lambda$, $K_{\lambda} \cap K_{\mu} = 0$. 
        \end{enumerate}
    \end{enumerate}
    \begin{proof}
        Prove 2.2 \\
        Suppose $\mu \neq \lambda$, $T-\mu I |_{K_{\lambda}}$ is invertible on $K_{\lambda}$ by property 2. Then let 
        \[
            x \in K_{\lambda} \cap N(T-\mu I)    
        \]
        then $x = 0$. Similarly, consider large enough $q$, such that $K_{\mu} = (T-\mu I)^q$, which is invertible as it is a composition of invertible transformation. So then 
        \[
            K_{\mu} \cap K_{\lambda} = \emptyset
        \]
    \end{proof}
\end{theorem*}


\begin{theorem*}
    \textbf{7.2 Property of Generalized Eigenspace When Characteristic Polynomial Splits} Let $T$ be a linear operator on a finite-dimensional vector space $V$ such that the characteristic polynomial of $T$ splits. Suppose that $\lambda$ is an eigenvalue of $T$ with multiplicity $m$. Then 
    \begin{enumerate}
        \item $\dim{K_{\lambda}} \leq m$ 
        \item $K_{\lambda} = N((T-\lambda I)^m)$
    \end{enumerate}
    For proofs
    \begin{enumerate}
        \item Use \linkinline{326}{theorem 5.21} T-invariant $W\subseteq V$ have $P_{T_W}(t) \divides P_T(t)$, we have $\cvec{T_W}{\beta}$ in the form of a Jordan Block, therefore 
        \[
            h(t) = P_{T_W}(t) = (-1)^d(t-\lambda)^d    
        \]
        \item Prove forward direction $(\Rightarrow)$ Use \linkinline{329}{theorem 5.23 Cayley-Hamilton} $f(T) = T_0$, i.e. linear operator satisfies its characteristic equation, on $T_W$
        \[
            h(T_W) = (-1)^d (T-\lambda I)^d = T_0
        \]
        So $(T-\lambda I)^d(x) = 0$ for all $x\in W$ where $d\leq m$, so $K_{\lambda} \subseteq N((T-\lambda I)^m)$
    \end{enumerate}
\end{theorem*}


\begin{defn*}
    \textbf{Nilpotent} A linear operator $T$ on a vector space $V$ is called nilpotent if $T^p = T_0$ for some positive $p$. An $n\times n$ matrix $A$ is called nilpotent if $A^p = 0$ for some positive integer $p$
\end{defn*}

\begin{lemma*}
    \textbf{Fitting Decomposition} For $S\in L(V)$, there is a unique decomposition 
    \[
        V = W \oplus U    
    \]
    where $W,U$ are $S$-invariant, and 
    \begin{enumerate}
        \item $S|_W$ invertible 
        \item $S|_U$ nilpotent that is, if $(S|_U)^q = 0$ for some $q > 0$
    \end{enumerate}
    \begin{proof}
        Note 
        \[
            N(S) \subseteq N(S^2) \subseteq \cdots 
            \qquad 
            R(S) \supseteq R(S^2) \supseteq \cdots
        \]
        have to stablize for nilpotent $S = (T-\lambda I)$, that is there exists $p>0$, such that 
        \[
            N(S^p) = N(S^{p+1})
            \qquad 
            R(S^p) = R(S^{p+1})
        \]
        Now let $U = N(S^p)$ and $W = R(S^p)$, both $S$-invariant. It is obvious that $S|_V$ is nilpotent. Also $S(W) = S(R(S^p)) = R(S^{p+1}) = R(S^p) = W$, i.e. on-to. so $S|_W$ invertible. Claim $V = W\oplus U$, let $x\in V$, then 
        \[
            S^px \in R(S^p) = R(S^{2p})
        \]
        So exists $y\in V$, such that $S^px = S^{2p}y$, so then $S^p(x - S^py) = 0$, then $x - S^p y \in N(S^p) = U$. So then
        \[
            x = x_1 + x_2 
            \qquad 
            x_1 = S^p y \in W
            \quad
            x_2 = x - x_1 \in U
        \]

    \end{proof}
\end{lemma*}
 

\begin{theorem*}
    \textbf{7.3 Sum of Generalized Eigenspace Fills the Space} \\
    Let $T$ be a linear operator on a finite-dimensional vector space $V$ such that the characteristic polynomial of $T$ splits, and let $\lambda_1,\lambda_2,\cdots, \lambda_k$ be the distinct eigenvalues of $T$. Then for every $x\in V$, there exists vectors $v_1\in K_{\lambda_i}$, $1\leq i \leq k$, such that 
    \[ 
        x = v_1 + v_2 + \cdots + v_k    
    \]
    \begin{proof}
        Cayley-Hamilton theorem works on some special case of characteristic polynomial of the form $(t-\lambda)^d$ yields the zero transformation, which makes some subset of the vector space satisfy condition for generalized eigenspace, i.e. $(T-\lambda I)(x) = 0$
    \end{proof}
\end{theorem*}


\begin{theorem*}
    \textbf{7.4 Generalized Eigenspace Decomposition} \\
    Let $T$ be a linear operator on a finite-dimensional vector space $V$ sucht hat the characteristic polynomial of $T$ splits, and let $\lambda_1, \cdots, \lambda_k$ be the distinct eigenvalues of $T$ with corresponding multiplicity $m_1,\cdots, m_k$. For $1\leq i \leq k$, let $\beta_i$ be an ordered basis for $K_{\lambda_i}$. Then the following statements are true 
    \begin{enumerate}
        \item $\beta_i \cap \beta_j = \emptyset$ for $i\neq j$ 
        \item $\beta = \beta_1 \cap \beta_2 \cap \cdots \cap \beta_k$ is an ordered basis for $V$
        \item $\dim{K_{\lambda_i}} = m_i$ for all $i$
    \end{enumerate} 
    Equivalently, we have 
    \[
        V = K_{\lambda_1} \oplus \cdots \oplus K_{\lambda_k}    
    \]
\end{theorem*}

\begin{corollary*}
    \textbf{Assumption for Diagonalizability} Let $T$ be a linear operator on a finite-dimensional vector space $V$ sucht hat the characteristic polynomial of $T$ splits. Then $T$ is diagonalizable if and only if $E_{\lambda} = K_{\lambda}$ for every eigenvalue $\lambda$ of $T$
\end{corollary*}

\begin{defn*}
    \textbf{Cycle of Generalized Eigenvectors} Let $T$ be a linear operator on a vector space $V$, and let $x$ be a generalized eigenvector of $T$ corresponding to the eigenvalue $\lambda$. Then $x$ is a generalized eigenvector of \textbf{height} $p$ if $p$ is the smallest positive integer for which $(T-\lambda I)^p (x) = 0$ but $(T-\lambda I)^{p-1} (x) \neq 0$. Then the ordered set,
    \[
        \{ (T-\lambda I)^{p-1}(x), (T-\lambda I)^{p-2}(x), \cdots, (T-\lambda I)(x), x \}
    \]
    is called a cycle of generalized eigenvectors of $T$  corresponding to $\lambda$. The vectors $(T-\lambda I)^{p-1}(x)$ and $x$ are called the \textbf{initial vector} and the \textbf{end vector} of the cycle, respectively. We say that the \textbf{length} of the cycle is $p$ (number of vectors). 
    \begin{enumerate}
        \item The elements of a cycle are linearly independent
    \end{enumerate}
    \begin{proof}
        Given 
        \[
            a_1 (T-\lambda I)^{p-1} x + \cdots + a_{p-1}(T-\lambda I)    x + a_p x = 0
        \]
        Apply $(T-\lambda I)^{p-i}$ for $i = 1, \cdots, p$ times. For $i=1$, we have
        \[
            0 + \cdots + 0 + a_p (T-\lambda I)^{p-1}x = 0    
        \]
        Note $(T-\lambda I)^{p-1}x \neq 0$, so then $a_p = 0$. We can deduce $a_1 = \cdots = a_p = 0$
    \end{proof}
\end{defn*}

\begin{theorem*}
    \textbf{7.5 Disjoint Union of Cycles of Generalized Eigenvectors as Jordan Canonical Basis} \\
    Let $T$ be a linear operator on a finite-dimensional vector space $V$ whose characteristic polynomial splits, and suppose that $\beta$ is a basis for $V$ such that $\beta$ is a disjoint union of cycles of generalized eigenvectors of $T$. Then the following are true 
    \begin{enumerate}
        \item For each cycle $\gamma$ of generalized eigenvectors contained in $\beta$, $W = \span{\gamma}$ is T-invariant and $\cvec{T_W}{\gamma}$ is a Jordan block 
        \item $\beta$ is a Jordan canonical basis for $V$
    \end{enumerate}
\end{theorem*}

\begin{theorem*}
    \textbf{7.6 Existence Condition for a Disjoint Union of Cycles} \\ 
    Let $T$ be a linear operator on a vector space $V$, and let $\lambda$ be an eigenvalue of $T$. Suppose that $\gamma_1, \gamma_2, \cdots, \gamma_q$ are cycles of generalized eigenvectors of $T$ corresponding to $\lambda$ such that the initial vectors of the $\gamma_i$'s are 
    \begin{enumerate}
        \item \textbf{distinct}, and
        \item form a \textbf{linearly independent set}
    \end{enumerate}
     Then the $\gamma_i$'s are 
     \begin{enumerate}
         \item \textbf{disjoint}, i.e. $\gamma_i \cap \gamma_j = \emptyset$ for $i\neq j$, and
         \item their union $\gamma = \bigcup_{i=1}^q \gamma_i$ is \textbf{linearly independent}
     \end{enumerate}
     \begin{proof}
        To prove cycles disjoint. Assume there exits $x\in K_{\lambda}$ with height $p$, such that $x\in \gamma_1$ and $x\in \gamma_2$, without loss of generality of choice of $\gamma$s'. Then $(T-\lambda I)^{p-1} x \neq 0$ is initial vector for both $\gamma_1$ and $\gamma_2$. Contradiction as we assumed that initial vectors are all distinct. \\
        Let $\gamma = \{x_1, \cdots, x_n\}$, suppose
        \[
        a_1 x_1 + \cdots + a_n x_n = 0 
        \]
        where $a_j$ not all zero. Let $k$ be such that $a_k \neq 0$ and that $x_k$ has largest height $p$ possible. Apply $(T-\lambda I)^{p-1}$ to the equation, we get 
        \[
        \cdots + 0 + a_k (T - \lambda I)^{p-1} x_k + 0 + \cdots = 0
        \]
        since $x_j$ with height less than $p$ is killed by $(T-\lambda I)^{p-1}$ and $x_j$ whose height is larger than $p$ has $a_j = 0$ by the choice of $k$, so then, $a_k (T-\lambda I)^{p-1} x_k = 0$ implies $a_k = 0$, contradiction.
     \end{proof}
\end{theorem*}
 

\begin{corollary*}
    Every cycle of generalized eigenvectors of a linear operator is linearly independent
\end{corollary*}


\begin{theorem*}
    \textbf{7.7 Existence of Disjoint Union in Generalized Eigenspace}\\ 
    Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $\lambda$ be an eigenvalue of $T$. Then $K_{\lambda}$ has an ordered basis consisting of a union of disjoint cycles of generalized eigenvectors corresponding to $\lambda$, 
    \[
        \gamma = \gamma_1 \cup \cdots \cup \gamma_q
    \]
    where the initial vectors of $r_1, \cdots, r_q$ are eigenvectors that form a basis of $E_{\lambda}$
\end{theorem*}

\begin{corollary*}
    \textbf{$P_T(t)$ Splits Ensures Existence of Jordan Canonical Form} Let $T$ be a linear opertor on a finite-dimensional vector space $V$ whose characteristic polynomial splits. Then $T$ has a Jordan Canonical Form
\end{corollary*}

\begin{defn*}
    \textbf{Jordan Canonical Form for Matrices} Let $A\in M_{n\times n}(F)$ be such that the characteristic polynomial of $A$ (and hence of $L_A$) splits. Then the Jordan canonical form of $A$ is defined to be the Jordan canonical form of the linear operator $L_A$ on $F^n$
\end{defn*}

\begin{corollary*}
    Let $A$ be $n\times n$ matrix whose characteristic polynomial splits. Then $A$ has a Jordan canonical form $J$, and $A$ is similar to $J$
\end{corollary*}

\begin{defn*}
    \textbf{Finding Basis For JCF}
    \begin{enumerate}
        \item Compute characteristic polynomial 
        \item Compute $\dim{E_{\lambda_i}}$, which is the number of disjoint cycles as basis for $K_{\lambda_i}$
        \item Find proper end vector
        \item Take union of vectors in the disjoint union of cycles of generalized eigenvectors
    \end{enumerate}
\end{defn*}



\linksection{509}{7.2 The Jordan Canonical Form II}


\begin{defn*}
    \textbf{Get Away}
    \begin{enumerate}
        \item $T$ is unique up to an ordering of eigenvalues of $T$
        \item $\beta_i$ for $\beta$ is not unique
        \item for each $i$, the number $n_i$ of cycles that form $\beta_i$, and length $p_j$ of each cycle, is completely determined by $T$
    \end{enumerate}
\end{defn*}

\begin{defn*}
    \textbf{Dot Diagram} Use an array of dots called dot diagram of $T_i$, where $T_i$ is restriction of $T$ to $K_{\lambda_i}$, to visualize each of $A_i$ and ordered basis $\beta_i$. Suppose $\beta_i$ is a disjoint union of cycles of generalized eigenvectors $\gamma_1, \cdots, \gamma_{n_i}$ with lengths $p_1 \geq \cdots \geq p_{n_i}$, respectively. The dot diagram $T_i$ contains one dot for each vector in $\beta_i$, and the dots are configured as follows 
    \begin{enumerate}
        \item there are $n_i$ columns (each representing a cycle or Jordan block)
        \item $j$-th column consists of $p_j$ dots that correspond to cycle $\gamma_j$ starting with initial vector at the top and continuing down to the end vector
    \end{enumerate}
    Note
    \begin{enumerate}
        \item Dot diagram has dimension $p_1 \times n_i$
        \item Let $r_j$ be number of dots in $j$-th row, then $r_1 \geq r_2 \geq \cdots \geq r_{p_1}$
        \item Dot diagram is complete determined by $T$ and $\lambda_i$
    \end{enumerate}
\end{defn*}


\begin{theorem*}
    \textbf{7.9 Dots in First $r$ Rows are a Basis for $N((T-\lambda I)^r)$} \\ 
    For any positive integer $r$, the vectors in $\beta_i$ that are associated with the dots in the first $r$ rows of the dot diagrams of $T_i$ constitute a basis for $N((T-\lambda_i I)^r)$. Hence the number of dots in the first $r$ rows of the dot diagram equals $\nullity{(T-\lambda_i I)^r}$
    \begin{enumerate}
        \item Implies number of dots in a row ($r_j$), the dot diagram, and consequently the number of Jordan blocks ($n_i$ columns) all does not depend on choice of basis
    \end{enumerate}
\end{theorem*}

\begin{corollary*}
    \textbf{Number of Jordan Blocks is Dimension of Eigenspace} \\
    The dimension of $E_{\lambda_i}$ is $n_i$. Hence in Jordan canonical form of $T$, the number of Jordan blocks corresponding to $\lambda_i$ equals the dimension of $E_{\lambda_i}$
\end{corollary*}


\begin{theorem*}
    \textbf{7.10 Supplementing Preivous Theorem} \\
    Let $r_j$ denote number of dots in $j$th row of dot diagram of $T_i$, the restriction of $T$ to $K_{\lambda_i}$. Then the following statements are true 
    \begin{enumerate}
        \item $r_1 = \dim{V} = \rank(T-\lambda_i I)$ 
        \item $r_j = \rank{(T-\lambda_i I)^{j-1}} - \rank{(T-\lambda_i I)^j}$ if $j>1$
    \end{enumerate}
\end{theorem*}

\begin{corollary*}
    \textbf{Dot Diagram of $T_i = T|_{K_{\lambda_i}}$ is Unique} \\
    For any eigenvalue $\lambda_i$ of $T$, the dot diagram of $T_i$ is unique. Thus, subject to the convention that the cycles of the generalized eigenvectors for the bases of each generalized eigenspace are listed in order of decreasing length, the Jordan canonical form of a linear operator or a matrix is unique up to the ordering of the eigenvalues
\end{corollary*}

\begin{theorem*}
    \textbf{7.11 Similar Matrix $\iff$ Same JCF} \\
    Let $A$ and $B$ be $n\times n$ matrices, each having Jordan canonical forms computed according to the conventions of this section. Then $A$ and $B$ are similar if and only if they have (up to an ordering of their eigenvalues) the same Jordan canonical form.
    \begin{proof}
        A property: If $A$ and $B$ similar, then exists $Q$ such that $A = Q^{-1}BQ$, then $A$ and $B$ have same eigenvalues. Specifically, if $Av = \lambda v$, then 
        \[
            Q^{-1}BQ v = \lambda v 
            \qquad \iff \qquad 
            B (Qv) = \lambda (Qv)
        \]
    \end{proof}
\end{theorem*}


\begin{defn*}
    \textbf{Steps for Finding Jordan Canonical Form/Basis} \\
    \begin{enumerate}
        \item Determine the shape of Jordan Canonical Form $J$
        \begin{enumerate}
            \item Compute characteristic polynomial 
            \item Determine the dot diagram for each $K_{\lambda_i}$
            \item Compute $\dim{N((T-\lambda I)^i)}$ for $i=1,\cdots, p$
            \item Compute $r_j$ based on $\dim{N(T-\lambda I)^i}$
            \item Determine the shape of Jordan Canonical Form from dot diagrams for all $K_{\lambda_i}$    
        \end{enumerate}
        \item Find a Jordan Canonical Basis for each $K_{\lambda_i}$
        \begin{enumerate}
            \item Compute matrix $(T-\lambda I)^i$ for $i=1,\cdots,p$ 
            \item Find a basis for $K_{\lambda_i} = N((T-\lambda I)^p)$ and select an end vector for the first cycle 
            \item Compute the cycle
            \item Compute other cycles, by selecting vectors that are linearly independent of the vectors already determined
            \item In case when $K_{\lambda_i} = E_{\lambda_i}$, Jordan canonical basis for $T_i$ is simply the basis for $E_{\lambda_i}$
        \end{enumerate}
    \end{enumerate}
\end{defn*}

\linksection{531}{7.3 Minimal Polynomial} 

\begin{defn*}
    \textbf{Minimal Polynomial} Let $T$ b a linear operator on finite-dimensional vector space. A polynomial $p(t)$ is called a minimal polynomial of $T$ if $p(t)$ is a monic polynomial (leading coefficient is 1) of least positive degree for which $p(T) = T_0$ 
\end{defn*}


\begin{theorem*}
    \textbf{7.12 Property of Minimal Polynomial} Let $p(t)$ be a minimal polynomial of $T$ on finite dimensional $V$ 
    \begin{enumerate}
        \item For any polynomial $g(t)$ where $g(T) = T_0$, $p(t)$ divides $g(t)$. In particular, $p(t)$ dividies characteristic polynomial of $T$ 
        \item The minimal polynomial of $T$ is unique
    \end{enumerate}
\end{theorem*}


\begin{defn*}
    \textbf{Minimal Polynomial of Matrix} Let $A\in M_{n}(F)$. The minimal polynomial $p(t)$ of $A$ is the monic polynomial of least positive degree for which $p(A)=O$
\end{defn*}

\begin{theorem*}
    \textbf{7.13 Operator and Matrix Equivalence} For any $A\in M_n(F)$, the minimal polynomial $A$ is the same as the minimal polynomial of $L_A$
\end{theorem*}

\begin{theorem*}
    \textbf{7.14 Characteristic/Minimal Polynomial Have the Same Zeros} \\
    Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $p(t)$ be a minimal polynomial of $T$. A scalar $\lambda$ is an eigenvalue of $T$ if and only if $p(\lambda)=0$. Hence characteristic polynomial and minimal polynomial of $T$ have the same zeros.
\end{theorem*}

\begin{corollary*}
    If $T$ has minimal polynomial $p(t)$ and characteristic polynomial $f(t)$, then 
    \[
        f(t) = (\lambda_1 - t)^{n_1} \cdots  (\lambda_k - t)^{n_k}
    \]
    where $\lambda_1, \cdots, \lambda_k$ are distinct eigenvalues. Then exists $m_1, \cdots, m_k$ where $1\leq m_i \leq n_i$ and 
    \[
        p(t) = (t-\lambda_1)^{m_1} \cdots (t-\lambda_k)^{m_k}
    \]
    \begin{enumerate}
        \item We can somewhat infer the minimal polynomial from shape of characteristic polynomial
        \item The degree of the minimal polynomial of an operator must be greater than or equal to the number of distinct eigenvalues of the operator
    \end{enumerate}
\end{corollary*}


\begin{theorem*}
    \textbf{7.15 $T$-cyclic Space Have Minimal Polynomial of Largest Degree} \\ 
    Let $T$ be a linear operator on an $n$-dimensional vector space $V$ such that $V$ is $T$-cyclic subspace of itself. Then the characteristic polynomial $f(t)$ and the minimal polynomial $p(t)$ have the same degree, and hence 
    \[
        f(t) = (-1)^n p(t)    
    \]
    \begin{enumerate}
        \item Gives the condition under which the degree of minimal polynomial of an operator is as large as possible
    \end{enumerate}
\end{theorem*}

\begin{theorem*}
    \textbf{7.16 Diagonalizable Operator Has Minimal Polynomial with Smallest Degree} \\
    Let $T$ be a linear operator on a finite-dimensional vector space. Then $T$ is diagonalizable if and only if the minimial polynomial of $T$ is of the form 
    \[
        p(t) = (t-\lambda_1) (t-\lambda_2) \cdots (t-\lambda_k)    
    \] 
    where $\lambda_1 , \cdots, \lambda_k$ are distinct eigenvalues of $T$
    \begin{proof}
        Realize that $p(t) = (t-\lambda_1) \cdots (t-\lambda_k)$ is the minimal polynomial since it brings each eigenvector $v_i$ to 0 for some $(T-\lambda_i I)$
    \end{proof}
\end{theorem*}

\begin{defn*}
    \textbf{Describing Minimal Polynomial}
    \begin{enumerate}
        \item If $T$ diagonalizable, then 
        \[
            p(t) = (t-\lambda_1) \cdots (t-\lambda_k)
        \]
        \item If $V$ $T$-cyclic subspace of itself, then 
        \[
            f(t) = (-1)^n p(t)    
        \]
        \item If characteristic polynomial splits, we describe $p(t)$ with Jordan canonical form. Let $p_i$ be size of largest Jordan block corresponding to $\lambda_i$ in a Jordan canonical form of $T$, then
        \[
            p(t) = (t-\lambda_1)^{p_1}  \cdots (t-\lambda_k)^{p_k}   
        \]
        \item If characteristic polynomial does not split, then we describe $p(t)$ with rational canonical form
    \end{enumerate}
\end{defn*}


\linksection{539}{The Rational Canonical Form}

\begin{defn*}
    \textbf{Irreducible Monic Polynomial} Let $T$ be a linear operator on a finite-dimensional vector space $V$ with characteristic polynomial 
    \[
        f(t) = (-1)^n (\phi_1(t))^{n_1} \cdots (\phi_k(t))^{n_k}  
    \]
    where $\phi_i(t)$ are distinct irreducible monic polynomials and the $n_i$'s are positive integers. For $1\leq i \leq k$, define subset $K_{\phi_i}$ of $V$ by 
    \[
        K_{\phi_i} = \{x\in V: (\phi_i(T))^p(x) = 0 \text{  for some positive integer } p\}    
    \]
    \begin{enumerate}
        \item In case $f(t)$ splits, $\phi_i = t-\lambda_i$
        \item Each $K_{\phi_i}$ is $T$-invariant subspace of $V$ 
    \end{enumerate}
\end{defn*}


\begin{defn*}
    \textbf{T-cyclic Basis and Companion Matrix} Let $x\in V$ be nonzero. Use $C_x$ be $T$-cyclic subspace generated by $x$, if $\dim{C_x}=k$, then 
    \[
        \beta_x = \{x, T(x), T^2(x), \cdots, T^{k-1}(x)\}    
    \]
    is an ordered basis for $C_x$. Let $A = \cvec{T|_{C_x}}{\beta_x}$, then 
    \[
        A = 
        \begin{pmatrix}
            0 & 0 & \cdots & 0 & -a_0 \\
            1 & 0 & \cdots & 0 & -a_1 \\
            0 & 1 & \cdots & 0 & -a_2 \\
            \vdots & \vdots &  & \vdots & \vdots \\
            0 & 0 & \cdots & 1 & -a_{k-1} \\
        \end{pmatrix}    
    \]
    where 
    \[
        a_1 x + a_2 T(x) + \cdots + a_{k-1} T^{k-1}(x) + T^k (x) = 0    
    \]
    Furthermore, the charateristic polynomial of $A$ given by (proved with induction)
    \[
        det(A-tI) = (-1)^k (a_0 + a_1 t + \cdots + a_{k-1}t^{k-1} + t^k)
    \]
    The matrix $A$ is the \textbf{companion matrix} of the monic polynomial
    \[
        h(t) = a_0 + a_1 t + \cdots + a_{k-1}t^{k-1} t^k    
    \]
    \begin{enumerate}
        \item Every monic polynomial $h(t)$ has a companion matrix, whose characteristic polynomial $f(t) = (-1)^k h(t)$
        \item Monic Polynomial $h(t)$ is also a minimal polynomial of $A$, 
    \end{enumerate}
\end{defn*}


\begin{defn*}
    \textbf{Rational Canonical Form} For every linear operator $T$, there eixsts an ordered basis $\beta$ for $V$ such that 
    \[
        \cvec{T}{\beta}=  
        \begin{pmatrix}
            C_1 & O & \cdots & O \\
            O & C_2 & \cdots & O \\
            \vdots & \vdots &  & \vdots \\
            O & O & \cdots & C_r \\ 
        \end{pmatrix}    
    \]
    where $C_i$ is the companion matrix of a polynomial $(\phi(t))^m$ such that $\phi(t)$ is a monic irreducible divisor of the characteristic polynomial of $T$ and $m$ is positive integer. $\cvec{T}{\beta}$ is called the rational canonical form of $T$ and the accompanying basis is the rational canonicl basis for $T$
\end{defn*}


\begin{defn*}
    \textbf{$T$-annihilator} Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $x$ be a nonzero vector in $V$. The polynomial $p(t)$ is called a $T$-annihilator of $x$ if $p(t)$ is a monic polynomial of least degree for which $p(T)(x)=0$
\end{defn*}


\begin{theorem*}
    \textbf{7.17} Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $\beta$ be a ordered basis for $V$. Then $\beta$ is a rational canonical basis for $T$ if and only if $\beta$ is the disjoint union of $T$-cycilc bases $\beta_{v_i}$, where each $v_i$ lies in $K_{\phi}$ for some irreducible monic divisor $\phi(t)$ of the characteristic polynomial of $T$
\end{theorem*}


\begin{theorem*}
    \textbf{7.22 Existence for Rational Canonical Basis} Each linear operator on a finite-dimensional vector space has a rational canonical basis and, hence, a rational canonical form
\end{theorem*}




\end{document}
