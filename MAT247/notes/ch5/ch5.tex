\documentclass[11pt]{article}
\input{/Users/markwang/.preamble}
\begin{document}


% arg1=pdfurl arg2=pagenum arg3=sectiontitle
\newcommand{\linksection}[3][../../linear_algebra_friedberg_insel_spence_4ed.pdf]{
    \subsection*{\href[page=#2]{#1}{#3}}
}


\newcommand{\vecspace}{\mathcal{V}}
\newcommand{\field}{\mathcal{F}}
\newcommand{\trace}[1]{tr(#1)}
\renewcommand{\span}[1]{span(#1)}
\renewcommand{\dim}[1]{dim(#1)}
\newcommand{\nullity}[1]{nullity(#1)}
\newcommand{\rank}[1]{rank(#1)}
\newcommand{\cvec}[2]{\left[ #1 \right]_{#2}}
\renewcommand{\matr}[3]{\left[ #1 \right]_{#2}^{#3}}
\newcommand{\ltspace}[1]{\mathcal{L}(#1)}
\renewcommand{\det}[1]{det(#1)}


\linksection{257}{Chapter 5 Diagonalization}
\linksection{257}{5.1 Eigenvalues and Eigenvectors}


\begin{defn*}
    \textbf{Diagonalizable} A linear operator $T$ on a finite-dimensional vector space $V$ is called diagonalizable if there is an ordered basis $\beta$ for $V$ such that $\cvec{T}{\beta}$ is a diagonal matrix. A square matrix $A$ is called diagonalizable if $L_A$ is diagonalizable. 
    \begin{rem}
        Want to determine if an linear operator $T$ is diagonalizable and if so, ways to obtain the basis $\beta = \{v_1,v_2,\cdots, v_n\}$ for $V$ such that $\cvec{T}{\beta}$ is a diagonal matrix. Note that if $D = \cvec{T}{\beta}$ is a diagonal matrix, then for each $v_j\in \beta$, we have 
        \[
            T(v_j) = \sum_i^n D_{ij} v_i = D_jj v_j =\lambda_j v_j    
        \]
        where $\lambda_j = D_jj$. Conversely, if $\beta = \{v_1,v_2,\cdots, v_n\}$ is an ordered basis for $V$ such that $T(v_j) = \lambda_j v_j$ for some scalars $\lambda_1, \lambda_2,\cdots, \lambda_n$, then 
        \[
            \cvec{T}{\beta} = 
            \begin{pmatrix}
                \lambda_1 & 0 & \cdots & 0 \\
                0 & \lambda_2 & \cdots & 0 \\
                \vdots & \vdots & & \vdots \\
                0 & 0 & \cdots & 0 \lambda_n \\ 
            \end{pmatrix}    
        \]
    \end{rem}
\end{defn*}


\begin{defn*}
    \textbf{Eigenvalue and Eigenvector (characteristic/proper value or vector)} Let $T$ be a linear operator on a vector space $V$. A nonzero vector $v\in V$ is called an eigenvector of $T$ if there exists a scalar $\lambda$ such that $T(v) = \lambda v$. The scalar $\lambda$ is called the eigenvalue corresponding to the eigenvector $v$. \\
    Let $A$ be in $M_{n\times n}(F)$. A nonzero vector $v\in F^n$ is called an eigenvector of $A$ if $v$ is an eigenvector of $L_A$; that is, if $Av = \lambda v$ for some scalar $\lambda$. The scalar $\lambda$ is the eigenvalue of $A$ corresponding to the eigenvector $v$
\end{defn*}

\begin{theorem*}
    \textbf{5.1 Diagonalizable and Eigenvalue/Eigenvector}\\
     A linear operator $T$ on a finite-dimensional vector space $V$ is diagonalizable if and only if there exists an ordered basis $\beta$ for $V$ consisting of eigenvectors of $T$. Furthermore, if $T$ is diagonalizable, $\beta = \{v_1,v_2,\cdots, v_n\}$ is an ordered basis of eigenvectors of $T$, and $D = \cvec{T}{\beta}$, then $D$ is diagonal matrix and $D_{jj}$ is the eigenvalue corresponding to $v_j$ for $1\leq j \leq n$
\end{theorem*}


\begin{theorem*}
    \textbf{5.2 Computing Eigenvalues} \\ 
    Let $A\in M_{n\times n}(F)$. Then a scalar $\lambda$ is an eigenvalue of $A$ if and only if $\det{A-\lambda I_n} =0$
\end{theorem*}


\begin{defn*}
    \textbf{Characteristic Polynomial of a Matrix} Let $A\in M_{n\times n}(F)$. The polynoimal $f(t) = \det{A - tI_n}$ is called the characteristic polynomial of $A$
    \begin{enumerate}
        \item THe eigenvalues of a matrix are the zeros of its characteristic polynomial 
        \item To determine the eigenvalues of a matrix or linear operator, we normally compute its characteristic polynomial.
    \end{enumerate}
\end{defn*}


\begin{defn*}
    \textbf{Characteristic Polynomial of a Linear Operator} Let $T$ be a linear operator on an n-dimensional vector space $V$ with ordered basis $\beta$. We define the characteristic polynomial $f(t)$ of $T$ to be the characteristic polynomial of $A = \cvec{T}{\beta}$. That is,
    \[  
        f(t) = \det{A - tI_n}    
    \]
    We denote characteristic polynomial of an operator $T$ by $\det{T - tI}$. Note the definition is independent of the choice of ordered basis $\beta$, the resulting characteristic polynomial is the same regardless the choice of basis.
\end{defn*}

\begin{theorem*}
    \textbf{5.3 Properties of Characteristic Polynomial} \\
    Let $A\in M_{n\times n}(F)$
    \begin{enumerate}
        \item The characteristic polynomial of $A$ is a polynomial of degree $n$ with leading coefficients $(-1)^n$
        \item $A$ has at most $n$ distinct eigenvalues. 
    \end{enumerate}
\end{theorem*}

\begin{theorem*}
    \textbf{5.4 Computing Eigenvectors} \\
    Let $T$ be a linear operator on a vector space $T$, and let $\lambda$ ber an eigenvalue of $T$. A vector $v\in V$ is an eigenvector of $T$ corresponding to $\lambda$ if and only if $v\neq 0$ and $v\in N(T-\lambda I)$
\end{theorem*}





\end{document}
