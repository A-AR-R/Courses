\documentclass[11pt]{article}
\input{/Users/markwang/.preamble}
\begin{document}

% arg1=pdfurl arg2=pagenum arg3=sectiontitle
\newcommand{\linksection}[3][../../linear_algebra_friedberg_insel_spence_4ed.pdf]{
    \subsection*{\href[page=#2]{#1}{#3}}
}
\newcommand{\linkinline}[3][../../linear_algebra_friedberg_insel_spence_4ed.pdf]{
    \noindent\href[page=#2]{#1}{#3}
}


\newcommand{\vecspace}{\mathcal{V}}
\newcommand{\field}{\mathcal{F}}
\newcommand{\trace}[1]{tr(#1)}
\renewcommand{\span}[1]{span(#1)}
\renewcommand{\dim}[1]{dim(#1)}
\newcommand{\nullity}[1]{nullity(#1)}
\newcommand{\rank}[1]{rank(#1)}
\newcommand{\cvec}[2]{\left[ #1 \right]_{#2}}
\renewcommand{\matr}[3]{\left[ #1 \right]_{#2}^{#3}}
\newcommand{\ltspace}[1]{\mathcal{L}(#1)}
\newcommand{\augmatr}[2]{(#1|#2)}


\linksection{159}{Chapter 3 Elementary Matrix Operation and System of Linear Equations}

\begin{defn*}
    \textbf{Elementary Row(Column) Operations} Let $A$ be $m\times n$ matrix Any of 3 operations on $A$ is called an elementary row (column) operation 
    \begin{enumerate}
        \item Interchanging any two rows (column) of $A$
        \item Multiplying any row (column) of $A$ by a nonzero scalar 
        \item Adding any scalar multiple of a row (column) of $A$ to another row (column)
    \end{enumerate}
\end{defn*}

\begin{defn*}
    \textbf{Elementary Matrix} An $n\times n$ elemntary matrix is a matrix obtained by performing an elementary operation on $I_n$. The elementary matrix is said to be of type 1,2,3 according to whether the elementary operation performed on $I_n$ is a type 1,2,3 operation, respectively.
\end{defn*}

\begin{theorem*}
    \textbf{3.1 Existence of Elementary Matrix that Act as Elementary Operations} Let $A\in M_{n\times n}(F)$ and suppose $B$ is obtained from $A$ by performing an elementary row (column) operation. Then there exists an $m\times m$ ($n\times n$) elementary matrix $E$ such that $B=EA$ ($B=AE$), where $E$ is obtained from $I_m$ ($I_n$) by performing the same elementary row (colunn) operation as that which was performed on $A$ to obtained $B$. Conversely, if $E$ is an elementary matrix, then $EA$ is the matrix obtained from $A$ by performing the same elementary row (column) operation as that which produces $E$ from $I_m$ ($I_n$)
\end{theorem*}


\begin{theorem*}
    \textbf{3.2 Elementary Matrix are Invertible} Elementary matrices are invertible, and the inverse of an elementary matrix is an elementary matrix of the same type
\end{theorem*}


\linksection{164}{3.1 The Rank of a Matrix and Matrix Inverses}


\begin{defn*}
    \textbf{Rank} If $A\in M_{m\times n}(F)$, the rank of $A$, denoted as $\rank{A}$ to be the rank of the linear transformation $L_A: F^n \to F^m$
\end{defn*}


\begin{defn*}
    \textbf{Properties for Rank} 
    \begin{enumerate}
        \item $n\times n$ matrix is invertible if and only if its rank is $n$
        \item Every matrix $A$ is the matrix representation of linear transformation $L_A$ with respect to appropriate standard ordered bases. So the rank of a $L_A$ is the same as the rank of \textbf{one of} its matrix representations, namely $A$.
    \end{enumerate}
\end{defn*}

\begin{theorem*}
    \textbf{3.3 Equivalence of Rank for Linear Transformation and Matrix} Let $T:V\to W$ be a linear transformation between finite-dimensional vector spaces, and let $\beta$ and $\gamma$ be ordered bases for $V$ and $W$, respectively. Then 
    \[
        \rank{T} = \rank{\matr{T}{\beta}{\gamma}}    
    \]
\end{theorem*}

\begin{theorem*}
    \textbf{3.4 Rank Preserving Operations} Let $A$ be $m\times n$ matrix. If $P$ and $Q$ are invertible $m\times m$ and $n\times n$ matrices, respectively, then 
    \begin{enumerate}
        \item $\rank{AQ} = \rank{A}$
        \item $\rank{PA} = \rank{A}$
        \item $\rank{PAQ} = \rank{A}$
    \end{enumerate}
\end{theorem*}

\begin{corollary*}
    \textbf{Elementary Operation is Rank Preserving} Elementary row and column operations on a matrix are rank-preserving
\end{corollary*}

\begin{theorem*}
    \textbf{3.5 Rank is Number of Linearly Independent Columns} \\
    The rank of any matrix equals the maximum number of its linearly independent columns; that is, the rank of a matrix is the dimension of the subspace generated by the columns 
\end{theorem*}

\begin{theorem*}
    \textbf{3.6 Existence Matrix Transformation to a Specific Form} \\
    Let $A$ be an $m\times n$ matrix of rank $r$. Then $r\leq m$, $r\leq n$, and, by means of a finite number of elementary row and column operations, $A$ can be transformed into the matrix 
    \[
        D = 
        \begin{pmatrix}
            I_r & O_1 \\
            O_2 & O_3 \\ 
        \end{pmatrix}    
    \] 
    where $O_1, O_2, O_3$ are zero matrices. Thus $D_{ii}=1$ for $i\leq r$ and $D_{ij}=0$ otherwise (proof with induction on number of row of $A$)
\end{theorem*}


\begin{corollary*}
    \textbf{1 Elementary Decomposition} Let $A$ be $m\times n$ matrix of rank $r$. Then there exist invertible matrices $B$ and $C$ of sizes $m\times m$ and $n\times n$, respectively, such that $D = BAC$, where 
    \[
        D = 
        \begin{pmatrix}
            I_r & O_1 \\
            O_2 & O_3 \\ 
        \end{pmatrix}    
    \]
    is the $m\times n$ matrix in which $O_1,O_2,O_3$ are zero matrices.
\end{corollary*}

\begin{corollary*}
    \textbf{2 Column Space and Rank} 
    \begin{enumerate}
        \item $\rank{A^t} = \rank{A}$
        \item The rank of any matrix equals the maximum number of its linearly independent rows; that is, the rank of a matrix is the dimension of the subspace generated by its rows
        \item The rows and columns of any matrix generate subspaces of the same dimension, numerically equal to the rank of the matrix (use previous 2 corollaries)
    \end{enumerate}
\end{corollary*}

\begin{corollary*}
    \textbf{3} Every invertible matrix is a product of elementary matrices
\end{corollary*}

\begin{theorem*}
    \textbf{3.7 L.T. Composition / Matrix Multiplication Always Reduces Rank} \\
    Let $T:V\to W$ and $U:W\to Z$ be linear transformations on finite-dimensional vector spaces $V$, $W$, and $Z$, and let $A$ and $B$ be matrices such that the product $AB$ is defined. Then 
    \begin{enumerate}
        \item $\rank{UT}\leq \rank{U}$
        \item $\rank{UT}\leq \rank{T}$
        \item $\rank{AB}\leq \rank{A}$
        \item $\rank{AB}\leq \rank{B}$
    \end{enumerate}
\end{theorem*}

\begin{defn*}
    \textbf{Augmented Matrix} Let $A$ and $B$ be $m\times n$ and $m\times p$ matrices, respectively. By the augmented matrix $\augmatr{A}{B}$, we mean the $m\times (n+p)$ matrix $(A\,\,B)$, that is the matrix whose first $n$ columns are the columns of $A$, and whose last $p$ columns are the columns of $B$
\end{defn*}

\begin{defn*}
    \textbf{Computing Matrix Inverse} If $A$ is $n\times n$ matrix, and the matrix $\augmatr{A}{I_n}$ is transformed into a matrix of the form $\augmatr{I_n}{B}$ by means of a finite number of elementary row operations, then $B = A^{-1}$. If $A$ is an $n\times n$ matrix tha tis not invertible, then any attempt to transform $\augmatr{A}{I_n}$ into a matrix of the form $\augmatr{I_n}{B}$ produces a row whose first $n$ entries are zeros. \\
    Convenient for \linkinline{176}{computing inverse of linear transformation by computing inverse of matrix representation of the transformation}
\end{defn*}



\linksection{164}{3.3 Systems of Linear Equations -- Theoretical Aspects}

\begin{defn*}
    \textbf{System of Linear Equations} 
    \begin{enumerate}
        \item The system of equations $S$ where $a_{ij}$ and $b_i$ are scalars in field $F$ and $x_1,x_2,\cdots, x_n$ are $n$ variables taking values in $F$, is called the system of $m$ linear equations in $n$ unknowns over field $F$
        \[
            Ax = b 
            \qquad 
            A = 
            \begin{pmatrix}
                a_{11} & a_{12} & \cdots & a_{1n} \\ 
                a_{21} & a_{22} & \cdots & a_{2n} \\ 
                \vdots & \vdots & & \vdots \\
                a_{m1} & a_{m2} & \cdots & a_{mn} \\ 
            \end{pmatrix}    
            \quad 
            x =  
            \begin{pmatrix}
               x_1 \\ x_2 \\ \vdots \\ x_n 
            \end{pmatrix}
            \quad 
            b = 
            \begin{pmatrix}
                b_1 \\ b_2 \\ \vdots \\ b_m
            \end{pmatrix}
        \]
        \item A \textbf{solution} to the system is an $n$-tuple 
        \[
            x = 
            \begin{pmatrix}
                s_1 \\ s_2 \\ \vdots \\ s_n
            \end{pmatrix}
            \in F^n
        \]
        The set of all solutions to $S$ is called \textbf{solution} set of the system. System is \textbf{consistent} if its solution set is nonempyty, otherwise \textbf{inconsistent}
    \end{enumerate}
\end{defn*}

\begin{defn*}
    \textbf{Homogenous/Nonhomogeneous System} A system $Ax=b$ of $m$ linear equations in $n$ unknowns is said to be homogeneous if $b=0$. Otherwise the system is said to be nonhomogeneous
\end{defn*}

\begin{theorem*}
    \textbf{3.8 Solution Set to a Homogeneous System Is a Nullspace} \\
    Let $Ax=0$ be a homogeneous system of $m$ linear equations in $n$ unknowns over a field $F$ ($A$ is $m\times n$). Let $K$ denote the set of all solutions to $Ax=0$. Then $K=N(L_A)$. Hence $K$ is a subspace of $F^n$ of dimension $n-\rank{L_A}=n-\rank{A}$
\end{theorem*}

\begin{corollary*}
    If $m<n$, then the system $Ax=0$ has a nonzero solution
\end{corollary*}

\begin{rem}
    \linkinline{184}{Solving homogeneous system of equations} \\
    For computing solution to a system of equations $Ax=0$. Use $\rank{K=N(L_A)} = n - \rank{A}$ to compute the dimension of subspace consisting of solutions. Then describe solution set $K$ as span of linearly independent basis to describe
\end{rem}

\begin{theorem*}
    \textbf{3.9 Express Solutions to Nonhomogeneous Systems as Solutions to the Corresponding Homogeneous System}  \\
    Let $K$ be the solution set of a system of linear equations $Ax=b$, and let $K_H$ be the solution set of the corresponding homogeneous system $Ax=0$. Then for any solution $s$ to $Ax=b$
    \[
        K = \{s\} + K_H =\{s+k : k\in K_H\}    
    \]
\end{theorem*}

\begin{theorem*}
    \textbf{3.10 Square Invertible Matrix as a Condition for Exactly One Solution} \\
    Let $Ax = b$ be a system of $n$ linear equations in $n$ unknowns. If $A$ is invertible, then the system has exactly one solution, namely, $A^{-1}b$. Conversely, if the system has exactly one solution, then $A$ is invertible (invertibility from $K_H = \{0\}$)
    \begin{rem}
        Idea is if we can find one solution to a given system and a basis for solution set of corresponding homogeneous system then we have all solution to a given system
    \end{rem}
\end{theorem*}


\begin{theorem*}
    \textbf{3.11 Necessary and Sufficient Condition for a Consistent System} \\
    Let $Ax=b$ be a system of linear equations. Then the system is consistent if and only if $\rank{A} = \rank{A|b}$ \linkinline{186}{proof}
\end{theorem*}


\linksection{194}{3.4 Systems of Linear Equations -- Computational Aspects}

\begin{defn*}
    \textbf{Equivalent System of Equations} Two systems of linear equations are called equivalent if they have the same solution set
\end{defn*}

\begin{theorem*}
    \textbf{3.13 Left Multiply an Invertible Matrix Yields an Equivalent System}\\
    Let $Ax=b$ be a system of $m$ linear equations in $n$ unknowns, and let $C$ be an invertible $m\times m$ matrix. Then the system $(CA)x=Cb$ is equivalent to $Ax=b$
\end{theorem*}

\begin{corollary*}
    \textbf{Elementary Operation Yields Equivalent System} Let $Ax=b$ be a system of $m$ linear equations in $n$ unknowns. If $\augmatr{A'|b'}$ is obtained from $\augmatr{A|b}$ by a finite number of elementary row operations, then the system $A'x=b'$ is equivalent to the original system.
\end{corollary*}


\begin{defn*}
    \textbf{Reduced Row Echelon Form} A matrix is in reduced row echelon form if the following three conditions are satisfied 
    \begin{enumerate}
        \item Any row containing a nonzero entry precedes any row in which all the entries are zero (if any)
        \item The first nonzero entry in each row is the only nonzero entry in its column 
        \item The first nonzero entry in each row is 1 and it occurs in a column to the right of the first nonzero entry in the preceding row
    \end{enumerate}
\end{defn*}

\begin{defn*}
    \textbf{Gaussian Elimination} A method for reducing an augmented matrix to reduced row echelon form 
    \begin{enumerate}
        \item \textbf{Forward Pass} The augmented matrix is transformed into an upper triangular matrix in which the first nonzero entry of each row is 1, and it occurs in a column to the right of the first nonzero entry of each preceding row 
        \item \textbf{Backward Pass/Substitution}  The upper triangular matrix transformed into reduced row echelon form by making the first nonzero entry of each row the only nonzero entry of its column
    \end{enumerate}
\end{defn*}

\begin{theorem*}
    \textbf{3.14 Gaussian Elimination Guarantees} Gaussian Elimination transforms any matrix into its reduced row echelon form
\end{theorem*}


\begin{defn*}
    \textbf{Methods for Solving a System}\\
    \begin{enumerate}
        \item Transform $\augmatr{A}{b}$ into reduced row echelon form $\augmatr{A'}{b'}$
        \item If a row is obtained in which the only nonzero entry lies in the last column, then system is inconsistent. Otherwise discard any zero rows and write the corresponding system of equations 
        \item \linkinline{200}{Solve the system in reduced row echelon form} to yield a solution 
        \[
            s = s_0 + t_1u_1 + t_2u_2 + \cdots + t_{n-r}u_{n-r}    
        \]
        where $r$ is number of nonzero rows in $A'$. $s$ is a \textbf{general solution} to $Ax=b$
    \end{enumerate}
\end{defn*}

\begin{theorem*}
    \textbf{3.15 General Solution} Let $Ax=b$ be a system of $r$ nonzero equations in $n$ unknowns. Suppose $\rank{A} = \rank{A|b}$ and that $(A|b)$ is in reduced row echelon form. Then 
    \begin{enumerate}
        \item $\rank{A}=r$
        \item If general solution in form $s = s_0 + t_1u_1 + t_2u_2 + \cdots + t_{n-r}u_{n-r}$, then $\{u_1,u_2, \cdots, u_{n-r}\}$ is a basis for the solution set of corresponding homogeneous system, and $s_0$ is a solution to the original system
    \end{enumerate}
\end{theorem*}


\begin{theorem*}
    \textbf{3.16 Property of Reduced Row Echelon Form} \\
    Let $A$ be $m\times n$ matrix of rank $r$, where $r>0$, and let $B$ be the reduced row echelon form of $A$. Then 
    \begin{enumerate}
        \item The number of nonzero rows in $B$ is $r$
        \item For each $i=1,2,\cdots, r$, there is a column $b_{j_i}$ of $B$ such that $b_{j_i} = e_i$
        \item The columns of $A$ numbered $j_1, j_2, \cdots, j_r$ are linearly independent
        \begin{enumerate}
            \item \linkinline{204}{can be used to find linearly independent subset (basis) of a generating set}
            \item \linkinline{206}{can be used to extend a linearly independent subset to a basis}
        \end{enumerate}
        \item For each $k=1,2,\cdots, n$, if column $k$ of $B$ is $d_1e_1 + d_2e_2 + \cdots + d_re_r$, then column $k$ of $A$ is $d_1a_{j1} + d_2a_{j2} + \cdots + d_r a_{j_r}$
    \end{enumerate}
\end{theorem*}


\end{document}
