%% This is file `elsarticle-template-1-num.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
% \documentclass[preprint,12pt]{elsarticle}
%% Use the option review to obtain double line spacing
% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
\documentclass[final,1p,times]{elsarticle}
% \documentclass[final,1p,times,twocolumn]{elsarticle}
% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
% \documentclass[final,5p,times]{elsarticle}
% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% The graphicx package provides the includegraphics command.
% \usepackage{graphicx}
%% The amssymb package provides various useful mathematical symbols
% \usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
% \usepackage{lineno}

%% \biboptions{comma,round}

% \biboptions{}
\usepackage{nameref}
\usepackage{siunitx}


% include graphics
\usepackage{graphicx}
\graphicspath{ {figures/} }

% include pdfs
\usepackage{pdfpages}


%% using bibtex with biber
\usepackage[
    backend=biber,
    style=nature,
    sortlocale=de_DE,
    url=false,
    doi=true,
    eprint=false
]{biblatex}
\addbibresource{reference.bib}


\journal{authors of this study}
\begin{document}


\begin{frontmatter}

%% Title
\title{Ki-67 Digital Image Analysis: Reliability and Sources of Variability}
%% Authors
\author[molgen]{Peiqi Wang}
\author[music]{Tian Yu Liu}
\author[pmh]{Willa Shi}
\author[pmh]{Fei-Fei Liu}
\author[pmh]{Susan J. Done\corref{cor}}
\ead{Susan.Done@uhn.ca}
%% address
\cortext[cor]{Principal corresponding author}
\address[molgen]{Department of Molecular Genetics and Microbiology, University of Toronto, Canada}
\address[music]{Faculty of Music, Univeristy of Toronto, ON, Canada}
\address[pmh]{Princess Margaret Cancer Centre, Canada}

\begin{abstract}
Ki-67 is a nuclear protein reflective of tumour proliferative state. The usage of Ki-67 labeling index as a prognostic and predictive biomarker in breast cancer is undeniable. However, it is not recommended for routine clinical usage because of a lack of standardization. Digital image analysis (DIA) holds good potential; however investigation on the accuracy as well as intra- and interalgorithmic variability of different DIA methods is lacking. In this study, we scored a set of cases (n=278) utilizing manual hotspot counting and two digital image analysis (DIA) methods, Aperio ePathology and Definiens Tissue Studio. The Definiens system achieved high agreement (ICC: 0.892) with manual score reference and classified cases accurately (kappa: 0.67) based on a cut-off of 14\%. DIA is able to achieve comparable results with manual hotspot counting. The Aperio system was run twice on two sets of independently segmented images; Agreement to the manual score reference was at best moderate; (ICC: 0.173 and 0.439, kappa: 0.155 and 0.233) Considerable intra- and interalgorithmic variability was observed. In addition to heterogeneous tumour biology and varying algorithm implementation, settings assignments and image segmentation are main contributors to such variability. Calibrating analytical settings and novel designs of automatic image segmentation are crucial toward harmonizing DIA.


\end{abstract}

\begin{keyword}
ki67 \sep breast cancer
\end{keyword}

\end{frontmatter}

%%
%% Start line numbering here if you want
%%
\linenumbers

%% main text
\section*{Introduction}

Ki-67 is a human nuclear protein detected exclusively in the active phases of the cell cycle, namely $G_1$, $S$, $G_2$, and mitosis, while absent in the resting $G_0$ phase.\cite{Gerdes1984} It is highly sensitive to cell cycle changes, making it an ideal marker for quantifying uncontrolled proliferation, a hallmark of cancer. Unsurprisingly, Ki-67 immunohistochemical (IHC) staining of human neoplasmic cell has emerged as a rapid and cost-effective analytics capable of determining the growth fraction of tumour cell populations,  \cite{Scholzen2000} The use of Ki-67 labelling index, or the percentage of Ki-67-positive cells, has great prognostic potential particularly in carcinomas of the breast, where a multitude of studies report the use of Ki-67 labeling index in predicting disease free/overall survival and tumour recurrence \cite{Stuart-Harris2005, DeAzambuja2007, Petrelli2015} as well as in guiding neoadjuvant chemotherapy. \cite{Jones2009, Nishimura2010, Fasching2011} Practically, Ki-67 labeling index may contribute to improved tumour grading, where proliferation is routinely assessed using mitotic count. \cite{VanDiest2004} Additionally, Ki-67 labeling index used in conjunction with established breast histopathological markers may serve as a feasible and cost-effective alternative to gene signature based assessments such as OncotypeDx in cancer subtyping. \cite{Cuzick2011}

Despite its apparent value in cancer prognosis, widespread use of Ki-67 labeling index in clinical pathology is hampered by the lack of standardization and suffers from substantial intra- and interobserver variability. \cite{Dowsett2011a, Polley2013a} Although recommendations and quidelines exist in an effort to harmonize such variability, \cite{Polley2015} the choice of scoring methods and selection of cut-off for Ki-67 positivity remain a subject of debate. One promising approach to the problem utilizes digital image analysis (DIA), which ensures automaticity, repeatability and reproducibility. However, aforementioned characteristics do not guarantee objectivity; Differences in image segmentation and algorithm used could still give rise to variability. \cite{Tadrous2010} Some DIA methods were reported to agree comparably with \cite{Mohammed2012, Tang2012} or even outperform visual assessments; \cite{Laurinavicius2014, Stalhammar2016} Others suggested that DIA methods were less reliable and prognostic. \cite{Chabot-Richards2011} It is apparent that inter-algorithmic variability is high and performance is context dependent. Therefore, there is a great need to validate the reliability of existent Ki-67 DIA methods so as to identify major sources of variability and potential solutions.

In this study, we evaluated two digital image analysis methods - Aperio ePathology and Definiens Tissue Studio. The former requires explicit manual image segmentation; while the latter is semi-automatically segment the images by first calibrating against a few test cases. We assessed reliability of the two DIA methods by reporting their agreement to a set of manual scores previously identified to be a predictor of ipsilateral breast relapse in the the Toronto-British Columbia (TBC) trial patient cohort. \cite{Liu2015} We compared these agreements so as to evaluate intra- and inter-algorithmic variability, as well as inter-rater reliability for specifically the Aperio system. We also discussed potential sources of variability and ways to mitigate them.

\section*{Materials and Methods}

\subsection*{Sample Collection}
A subset of patient cohort from the TBC trial were used for this study. \cite{Liu2015} The TBC trial consists of node-negative patients who were older than 50 years of age randomly assigned to receive tamoxifen alone or tamoxifen and breast radiotherapy after breast-conserving surgery. \cite{Fyles2009} Tissue microarrays were constructed using a triplicate of \SI{0.6}{\milli\metre} tumour cores from formalin-fixed, paraffin-embedded blocks. A total of 6 TMA blocks, amounting to 278 cases, where used for subsequent IHC and image analysis. TMA blocks were cut in \SI{0.5}{\micro\metre} sections, stained with 1:500 dilution SP6 (NeoMarker) and counter-stained with hematoxylin.

\subsection*{Scoring Methodologies}

\subsubsection*{Manual Assessment}
A trained individual, assigned as rater 1, counted at least 200 cells within tumour hot spot, or areas in which Ki-67 most frequently expressed, for each core. The total number of nuclei and positively stained nuclei over the span of three cores were summed and the Ki-67 labeling index was calculated for each case. 10\% of the samples were randomly chosen and rescored for quality assurance. As the scores resulting from this set of manual assessment was clinically significant in predicting ipsilateral breast relapse, they were used as a reference to be compared with results from other scoring methods.

\subsubsection*{Digital Image Analysis (DIA)}
To assess intra-algorithmic variability of the DIA methods, specifically the Aperio system, 2 trained individuals, assigned as rater 1 and rater 2, independently marked tumour region of interest (ROI) for proper image segmentation. Settings, such as minimum nucleus radius and staining intensity threshold, for the algorithm were subjectively adjusted for by another experienced pathologist and used in both set of images. To assess inter-algorithmic variability, the same set of images were analyzed using the Definiens system in addition to the Aperio system. In this case, a technician, assigned as rater 3, segmented images in a few cases, which calibrated the software to perform semi-automatic segmentation. Minor adjustments were made to correct for faulty segmentation. Intra- and inter-algorithmic variability was evaluated by comparing the agreements of the two DIA methods to the manual score reference. Additionally, Inter-rater reliability when using a DIA method, specifically the Aperio system, was determined.

\subsection*{Statistics}
Data distribution for different scoring methods were visualized using boxplot, accompanied by summary statistics. Bland-Altman plot was used to visualize agreements between results from two DIA methods in relation to manual score reference. \cite{Bland1986} 95\% confidence interval for the limits of agreement as well as the mean difference was calculated based on an alpha of 0.05. Two methods were considered unbiased and precise if the mean difference centered about zero with a small standard deviation. \cite{Hanneman2008} To correct for positive skewness, Ki-67 labeling indices were log base 2 transformed after incrementing by 1\% for subsequent statistical calculation. Inter-rater reliability (IRR) was quantified using a two-way mixed, average-measures intraclass correlation coefficient (ICC) to assess the degree that raters provide absolute agreement in their ratings of Ki-67 labeling index using the Aperio system. \cite{Shrout1979} An ICC close to 1 represents high reliability. Similarly, ICC was used to assess the degree that results from the two DIA methods agree with that of the manual score reference. Conger generalized Kappa were calculated based on a set of commonly used cut-offs for Ki-67 positivity to evaluate the practicality of consistent classification using results from manual assessment as reference. \cite{Conger1980} R (version 3.2.4) was used generate all statistics and graphs.


\section*{Results}

\subsubsection*{Overall Distribution}
Boxplot of untransformed Ki-67 labeling index as well as summary statistics presented in Figure~\ref{boxplot}. The Aperio system tended to overestimate Ki-67 labeling index; whereas the Definiens system showed a similar distribution to manual score reference.

\begin{figure}
\includegraphics[width = \linewidth]{boxplot}
\includegraphics[width = \linewidth]{boxStat}

\centering
\caption{{\bf Boxplot and summary statistics of Ki-67 labeling index}
Distribution of Ki-67 labeling index generated using manual assessment and DIA methods. Outliers are represented as darkened circles. Corresponding summary statistics quantitatively descibes the boxplot.
}
\label{boxplot}
\end{figure}


\subsubsection*{Agreement of DIA methods to Manual Score Reference}

Bland-Altman plot for every DIA method compared to manual score reference and relevant statistics were presented in Figure~\ref{baplot}. It was apparent that the Aperio system systematically overestimated Ki-67 labeling index by a large margin in both scoring instances. The Definiens system faired better in introducing minimal bias, but still exhibited non-negligible variability.


\begin{figure}
\includegraphics[width = 0.3\linewidth]{baplot}
\includegraphics[width = \linewidth]{baStat}

\centering
\caption{{\bf Bland-Altman Plot}}
\label{baplot}
\end{figure}


ICC of two raters using the Aperio system when compared directly to the manual score reference was 0.173 (95\%CI -0.245 $\sim$ 0.459) and 0.439 (95\%CI -0.258 $\sim$  0.72) respectively, representing poor to moderate agreements. Intra-algorithmic variability was significant in the Aperio system. ICC of rater using the Definiens system when compared to the manual score reference was 0.892 (95\%CI 0.841 $\sim$ 0.924). High degree of agreement was observed, suggesting that the Ki-67 labeling index was scored similarly using manual assessment and a DIA method. Unsurprisingly, ICC for the two DIA methods differ, a direct consequence of the systematic bias previously shown in the Bland-Altman plot.

It may be misleading to solely measure absolute agreement, as ultimately cases would be classified into clinically relevant groups based on the Ki-67 labeling index. Kappa statistics calculated using cut-offs from a meta-analysis study were listed in Figure~\ref{kappaStat}. \cite{Petrelli2015} With a 14\% cut-off used to distinguish  luminal B from luminal A tumours, \cite{Cheang2009} the kappa value obtained using the Definiens system was 0.67, suggesting a substantial agreement in making clinically relevant classifications. \cite{Landis1977} With a hypothetical 25\% cut-off used to distinguish {'}luminal B-like{'} tumours proposed in the recent St. Gallen Breast Cancer Conference, \cite{Coates2015} the two DIA methods achieved fair to moderate agreement with kappa value of 0.35 and 0.57 respectively.


\begin{figure}
\includegraphics[width = \linewidth]{kappaStat}
\centering
\caption{{\bf Kappa statistics }}
\label{kappaStat}
\end{figure}



The discrepancy in agreements of the two DIA methods to manual score reference could be largely attributable to subjective assignments of settings in addition to varying algorithm implementation. When there was no reliable benchmark to fallback on, unbiased image segmentation could be challenging.

\subsubsection*{Inter-rater Reliability Using a DIA Method}
ICC between two raters using the the Aperio system was 0.538 (95\%CI: 0.31-0.68) The resulting ICC could be considered moderate, suggesting that a substantial amount of variability was introduced in the process of image segmentation in addition to heterogeneous tumour biology. \cite{Cicchetti1994} Additionally, Kappa statistics for two raters using the Aperio system indicated slight to fair agreement as presented in Figure~\ref{kappaStat}. \cite{Landis1977}


\section*{Discussions}

There has been developing interest in using Ki-67 labeling index to quantify proliferation levels in cancer research, for cancer subtyping, prognosis, and deciding treatments. However, only a highly reproducible and accurate procedure could be used routinely and reliably in the clinics. Comparison of counting methodologies yield varying results. \cite{Mikami2013, Reid2015} Although there are promosing efforts to standardize manual counting methodologies \cite{Polley2013a, Polley2015}, inherent limitations, such as poor scalability for high throughput assays, are often left unconsidered. Digital image analysis (DIA) offers a viable alternative that is more efficient, repeatable, and scalable. Systematic evaluation of intra- and inter-algorithmic variability is warranted but rarely done.

In this study, we assessed agreements of results from two DIA methods to a set of manual score reference (n=278) that is prognostically relevant and observed substantial intra-algorithmic and inter-algorithmic variability. However, variability does not undermine the fact that DIA methods can be highly accurate. The Definiens system was observed to agree well with the manual score reference, both in absolute value of Ki-67 labeling index and in its ability to segregate cases into clinically relevant groups. Controlling the introduction of bias is an important factor in achieving high agreement. In our study, we identified settings assignments as potential major sources of such discrepancy, in addition to different algorithm implementations. Additionally, manual image segmentation alone contribute to considerable disagreements when using identical system and settings for analysis. Semi-automated image segmentation could be a superior substitute for manual image segmentation.

A study reported using a test validation, calibration and measurement error correction methodology to fine-tune settings for accurate Ki-67 labeling index estimation, achieving a 2X reduction in misclassification rates. \cite{Laurinavicius2014} Such approach could be adapted to other DIA methods and reduce variability arisen from subject setting assignments, a predominant source of variability found in this study. However, test validation in the form of stereological test grid counting necessitates manual effort, which goes against the very idea of automation. Deciding the optimal settings for a given set of cases require further investigation on developing automated calibration methodologies.

One caveat of this study lies in comparing scores from DIA methods to a set of manual {'gold standards'}. Even though the manual score reference was a predictor of clinical outcome, the comparison is nonethless an indirect one. Instead of pursuing agreements in Ki-67 labeling index, one can assess statistical association of Ki-67 labeling index generated using DIA methods with clinical outcome directly and validate its significance with that of manual assessment. Other studies have explored such idea and found that results from DIA may be a superior prognostic factor. \cite{Stalhammar2016}

In conclusion, we reinforced the notion that DIA method can perform comparably with traditional manual assessment methods. Intra- and interalgorithmic variability is considerable amongst the two DIA methods tested and may be a prevalent phenomenon, hindering valid comparison cross different DIA platforms. We identified settings assignments and image segmentation as major sources of such variability.



\printbibliography

\end{document}
