window.COURSE_DATA = {"language":"en-CA","lastDownload":"2019-05-17T16:27:52-04:00","title":"CSC367H1 S LEC0101 20191:Parallel Programming","modules":[{"id":103310,"name":"Week 1","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i6cd488061e6b52a449c13a36e6846f18","items":[{"id":491112,"title":"Lab 1","type":"Assignment","indent":0,"locked":true,"submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":"2019-01-09T22:00:00-05:00","lockAt":"2019-01-09T22:00:00-05:00","unlockAt":"2019-01-09T10:00:00-05:00","requirement":null,"completed":false,"exportId":"ic721b62ff17ca6526b900404635ccf82"},{"id":501800,"title":"Lec1.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec01P.pdf"},{"id":503040,"title":"A short intro to Scinet.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/A short intro to Scinet.pdf"},{"id":519250,"title":"Lec2\u00263.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec02P.pdf"},{"id":519982,"title":"CSC367 Syllabus.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/CSC367 Syllabus (1).pdf"}]},{"id":110879,"name":"Week 2","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i0d201b9d7fb3a80684c7870af1a9eaa6","items":[{"id":513327,"title":"Take Home Task on Wed Jan 16th and Assignment One","type":"DiscussionTopic","indent":0,"locked":false,"lockAt":null,"unlockAt":null,"graded":false,"requirement":null,"completed":false,"content":"\u003cp\u003eHi everyone,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eWe will not have a lab on Wed Jan 16th because of Scinet downtime. Instead, \u003cspan style=\"font-weight: 400;\"\u003eyou must read sections 1 through 5.3 from this \u003c/span\u003e\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epthreads tutorial\u003c/span\u003e\u003c/a\u003e  (\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003ehttps://computing.llnl.gov/tutorials/pthreads/\u003c/a\u003e) \u003cspan style=\"font-weight: 400;\"\u003efrom the Lawrence Livermore National labs. This is a mandatory take-home task and should be done on Wed Jan 16th. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eRemember that you can not submit Assignment1 jobs to Scient during the Scinet downtime dates (Jan 15th and Jan 16th), you should do tests and debug the assignment on a local or a lab machine and when Scinet is up again you will be able to continue the assignment there. Your assignment will only be graded on Scinet so do not use any other platform for fine-tuning your code, obtaining final results, and writing your report!\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eAssignment one will be posted sometime today. \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"i0874e8c0e4f3e5fce98e7f273a719a3d"},{"id":524336,"title":"Assignment one","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":"2019-01-28T22:00:00-05:00","lockAt":null,"unlockAt":"2019-01-14T10:00:00-05:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAssignment 1 - System Performance \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Monday January 28, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 10 \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 16th at 10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this assignment!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eIntro to Scinet:\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this assignment. You should have already received an email with your Scinet login. In that email, you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eOverview\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work on groups of two. For this assignment, you will work on learning about the limitations of system memory performance. You will study some of the concepts discussed in lecture in a practical context, by performing performance measurements, profiling, and designing code meant to expose your system's boundaries. Additionally, you will experience first hand the impact of programming efficiently with your system's memory performance in mind.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work with a partner on this assignment. Please log into MarkUs as soon as possible to find your repository and invite your partner, and make sure that you can commit and push to your repo. For all assignments and labs, you will be given your repo URL on MarkUs. Make sure to use this repository (which should already be created for you), otherwise, MarkUs won't know about it and we won't be able to see your work.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available on \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet under \u003cem\u003e\u003cspan\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003c/em\u003e\u003cspan\u003e\u003cem\u003e/assignments/assignment1/\u003c/em\u003e\u003c/span\u003e\u003cem\u003estarter_code.tgz\u003c/em\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 1 - Know the Scinet machine's memory system!\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you will test the memory bandwidth and cache size of the Scinet machine.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003eA) \u003c/strong\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eDesign an experiment to measure the memory bandwidth in the Scinet machines. In particular,\u003c/span\u003e you will measure the write\u003cspan style=\"font-weight: 400;\"\u003e bandwidth, by creating a program that accesses memory in a specific way, designed to test the limits of the memory bus. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cem\u003eHint:\u003c/em\u003e\u003c/span\u003e You will want to write to memory as fast as possible; a naive approach like writing to memory byte by byte using a for-loop might not give you a reasonable estimate of memory bandwidth.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cem\u003eNote:\u003c/em\u003e\u003c/span\u003e This will help you reason about Scinet system's performance limitations and scaling issues. This will be particularly useful later in the course in understanding the benefits and limitations of GPU devices.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003eB)\u003c/strong\u003e Design an experiment to determine the number of levels in the CPU cache hierarchy, and to measure cache sizes and cache (write) latencies for each level, as well as the write latency of main memory. You must create a program that accesses memory in a particular manner, such that it allows you to calculate these parameters. Keep in mind how memory accesses are serviced within the memory hierarchy and design your code to expose this behaviour.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eTo measure the elapsed time of a piece of code, you can use the \u003cem\u003eclock_gettime()\u003c/em\u003e function (with the CLOCK_MONOTONIC clock) to capture the time before and after, then subtract them using the \u003cem\u003edifftimespec()\u003c/em\u003e helper function defined in \u003cem\u003etime_util.h\u003c/em\u003e in the starter code, and convert the difference to time units of your choice using the helper functions in \u003cem\u003etime_util.h\u003c/em\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce your design your experiment, you must represent your results visually (with graphs) and analyze them in a short report (called \u003cem\u003ereport.pdf\u003c/em\u003e). You should describe your approach, analyze the findings and draw conclusions. More on \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethis in a later section.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must automate running the experiments, collecting the data and generating the graphs. You need to write a script \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(e.g. Bash or Python) that invokes your C program (\u003cem\u003epart1.c\u003c/em\u003e) to performs all measurements, and produces all the graphs and other necessary data that you use to draw conclusions that your describe in your report. Invoke the script in the 'run' target of the part 1 makefile (see \u003cem\u003epart1/Makefile\u003c/em\u003e in the starter code). You must also describe your data collection programs and scripts in your report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eNote:\u003c/span\u003e\u003c/em\u003e In your experiments, you can assume that the cache line size is known (usually 64 bytes, check file \u003cem\u003e/proc/cpuinfo\u003c/em\u003e on the machine you're using for experiments). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eBONUS (10%):\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e Design an experiment to measure the cache line size.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eHint:\u003c/span\u003e\u003c/em\u003e measuring memory write bandwidth is all about hitting the memory with heavy requests and measuring the performance of your code, while measuring cache sizes and latencies is all about hitting the memory with accesses that are increasingly unlikely to hit in the cache, until you see significant drops in performance. Particularly for cache measurements, you are encouraged to draw graphs to support your analysis.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eHint:\u003c/span\u003e\u003c/em\u003e when your program accesses a memory region for the first time after it is dynamically allocated using \u003cem\u003emalloc()\u003c/em\u003e, or when it accesses a static global array for the first time, it might incur some overhead (you don't need to worry about what these are, but if you're taking CSC369 or just curious, this involves setting up the virtual to physical address translation - populating the page tables and the TLB). These are called cold accesses. To avoid the negative impact of the initial (cold) access overheads on the accuracy of your measurements, you can \"warm up\" the data by touching (e.g. writing to) the respective memory before starting the measurements.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eNote:\u003c/span\u003e\u003c/em\u003e Since memory and cache latency are typically very small, you want to avoid as much as possible time-consuming operations within the code being timed. For example, avoid division or modulo operations inside the timed code, if possible. You can also use bit shift operations if the denominator is a power of 2, instead of a division, etc. You might have to play a bit with such tweaks if your measurements do not seem right.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 2 - Performance and profiling\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you will implement a piece of simple parallel code, and profile its performance. \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eThe profiling should guide you into how to optimize your code further.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou'll start with a program (part2.c in the part2/ subdirectory in the starter code) that computes the historic average grades for a set of courses. Profile your code (e.g., using the kcachegrind tool of valgrind or gprof), and then parallelize (in part2/part2-parallel.c) the piece(s) of code which take a considerable amount of execution time, and which are also parallelizable.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe provide you with a data generator (datagen.c) that is automatically invoked with default parameters by 'make' when you build the code (see comments in the makefile). This default dataset should be enough, but you can generate more data if you wish (please do not commit any data files!). Refer to the starter code for more details on the data generator. You can run the programs (part2*.c) on generated data by specifying the path to the data (the one that you gave to the generator) as an argument.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eTo profile your code, you have several options:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse gprof. For full documentation, see\u003c/span\u003e\u003ca href=\"https://sourceware.org/binutils/docs/gprof/\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e. \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e The most basic usage involves simply adding the \"-pg\" flag to the compilation and linking of your program, and then running your code. After you run your code, a \"gmon.out\" file will be generated. To inspect the gprof details, simply use: \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003cspan style=\"font-weight: 400;\"\u003e$ gprof ./myprogram gmon.out \u0026gt; gprof_analysis.txt\u003c/span\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can then inspect the \u003cem\u003egprof_analysis.txt\u003c/em\u003e file for details on how much time is spent in each function. \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse valgrind's\u003c/span\u003e\u003ca href=\"http://valgrind.org/docs/manual/cl-manual.html\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ecallgrind\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e tool and kcachegrind for a more visual representation. For example: \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003cspan style=\"font-weight: 400;\"\u003e$ valgrind --tool=callgrind ./myprogram \u003c/span\u003e\u003c/pre\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis will generate a trace file that starts with \"callgrind\". You can view this with a text editor, but this won't be very helpful since the trace can be quite cryptic. You can analyze visually the trace results using a tool like kcachegrind. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse a tool like oprofile. For more documentation, see\u003c/span\u003e\u003ca href=\"http://oprofile.sourceforge.net/docs/\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce you have parallelized your code, you must use the perf tools to capture architectural performance counters that might help you optimize your code. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eHint:\u003c/span\u003e\u003c/em\u003e look at your cache misses in particular! You must then optimize your code accordingly and measure the improvements. Document your findings and discuss them in the report. You will implement the optimized version in part2/part2-parallel-opt.c.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you have trouble getting stable measurements from perf, you can try building the code as follows: \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEMBED_DATA=1 make (instead of a simple make invocation) This will embed the data in the compiled executable file (instead of loading it from a file explicitly by default; see the source code for details), and might help to make perf readings less \"noisy\". Please do not commit the generated .c files with embedded data (\u003cem\u003epart2_data.c\u003c/em\u003e for example)!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cstrong\u003eNote:\u003c/strong\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e you \u003cstrong\u003e\u003cem\u003emust not\u003c/em\u003e\u003c/strong\u003e add any gcc optimization options in your part2 makefile. This is important for the particular performance effects we want you to explore in this assignment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eBONUS (5%):\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e study the effect of the gcc optimization level (-O0, -O1, -O2, -O3) on the performance issues that you encounter in your initial parallel implementation. Describe your findings in the report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTesting\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFirst read the \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003erun-job-**.sh \u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003efiles in the code folders.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e1- Running Part 1: \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eAfter you have logged in to Scinet and copied the code into your \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003e$SCRATCH\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e folder, you can start working on the assignment. A script called \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003erun-job-part1.sh\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e is provided that builds and runs your code on a Scinet compute node\u003c/span\u003e\u003cstrong\u003e.\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e2- Running Part 2: \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eThree scripts are provided called \u003cem\u003erun-job-serial.sh\u003c/em\u003e, \u003cem\u003erun-job-parallel.sh\u003c/em\u003e and \u003cem\u003erun-job-parallel-opt.sh\u003c/em\u003e that build, generate data, and run in order the \u003cem\u003epart2.c\u003c/em\u003e, \u003cem\u003epart2-parallel.c\u003c/em\u003e, and \u003cem\u003epart2-parallel-opt.c\u003c/em\u003e codes on a compute node. Also, script \u003cem\u003erun-gprof.sh\u003c/em\u003e is provided to profile code on a compute node. If you want to use Valgrind write your own script similar to \u003cem\u003erun-gprof.sh\u003c/em\u003e and remember to load the Valgrind module. You can change any of these scripts to test for different data based on the comments inside the scripts. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eReport\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must write a report documenting your implementation, displaying your results in a meaningful way, and analyzing your findings, for each part of the assignment. In your report, you should present your ideas, the experimental setup and results. You should discuss what you noticed, draw conclusions and explain any optimization decisions, if any. The report should be written in a scientific manner (clear structure, clear description of your approach, results, findings, etc., and should use technical writing instead of colloquial terminology or phrases). Keep in mind that presenting your experimental findings and observations to a technical audience is an important skill to develop as a computer scientist.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eSubmission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must keep the same structure as the starter code: part1 code under the \"part1/\" directory, part2 code under the \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\"part2/\" directory. You must submit all the files required to build and run all your programs (including any header files and the makefiles, etc.). Make sure your code compiles and runs correctly on the teaching lab machines.\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor part1, you may keep all your C code in\u003cem\u003e part1.c\u003c/em\u003e, but if you add any other source files, make sure that you update the makefile accordingly. You must also submit the scripts for collecting data and generating graphs, and\u003cspan style=\"text-decoration: underline;\"\u003e create a target called \"run\"\u003c/span\u003e in the part1 makefile that invokes the script(s) to collect all the necessary data and generate all the graphs that you use in your report. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor part2, you shouldn't need to add any new files to the starter code, but if you do, make sure that you update the makefile accordingly.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eBe sure to make it clear how to run your code with various configurations, in your report! \u003cspan style=\"text-decoration: underline;\"\u003eDo not submit any executables or object files!\u003c/span\u003e (do a \"make clean\" before making your final commit)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit the report (named \u003cem\u003ereport.pdf\u003c/em\u003e, in the top directory of the assignment) documenting your approach, presenting the results, and discussing your findings. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAdditionally, you must submit an \u003cem\u003eINFO.txt\u003c/em\u003e file, which contains as the first 2 lines the following: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour name(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour UtorID(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you want us to grade an earlier revision of your assignment for whatever reason \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(for example, for saving some grace tokens if you had a stable submission before the deadline, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003etried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want marked. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAs a general rule, by default we will always take the last revision before the deadline \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(or last one after the deadline, up to your remaining unused grace tokens), so you should \u003c/span\u003e\u003cstrong\u003enot\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens if you submit late) is the one you want graded.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFinally, whether you work individually or in pairs with a partner, you \u003c/span\u003e\u003cstrong\u003emust\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e submit a \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003eplagiarism.txt\u003c/em\u003e file (in the top directory of the assignment), with the following statement: \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cem\u003e\u003cspan style=\"font-weight: 400;\"\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/span\u003e\u003c/em\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA missing \u003cem\u003eINFO.txt\u003c/em\u003e file will result in a 10% deduction (on top of an inherent penalty if we do not end upgrading the revision you expect). \u003c/span\u003e\u003cstrong\u003eAny missing code files or makefile will result in a 0 on this assignment\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e! \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ePlease reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAgain, make sure your code compiles without any errors or warnings.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eCode that does not compile will receive zero marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eMarking scheme\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be marking based on correctness (90%), and coding style (10%). Make sure to write legible code, properly \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eindented, and to include comments where appropriate (excessive comments are just as bad as not providing enough comments). Code structure and clarity will be marked strictly!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eOnce again: code that does not compile will receive 0 marks!\u003c/strong\u003e \u003cspan style=\"font-weight: 400;\"\u003eMore details on the marking scheme: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 1: 40%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 2: 30%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eReport: 20% (12% for Part 1 + 8% for Part 2)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e(BONUS) Cache line size measurement: 10% (5% for the implementation, 5% for explaining the rationale clearly in the report, justifying your approach)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e(BONUS) Studying the effect of compiler optimizations for Part2: 5%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode style and organization: 10% - code design/organization (modularity (if applicable), code readability, reasonable variable names, avoid code duplication, appropriate comments where necessary, proper indentation and spacing, etc.)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eNegative deductions (please be careful about these!):\u003c/strong\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eCode does not compile: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e for *any* mistake, for example missing source file necessary for building your code (including makefile, header files, etc.), typos, any compilation error, etc\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eNo plagiarism.txt file: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (we will assume that your code is plagiarised and wish to withdraw your submission if this file is missing)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eMissing or incorrect INFO.txt: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eWarnings: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eExtra output: -20%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (for any output other than what is required in the handout)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eCode placed in other subdirectories than indicated: -20%\u003c/strong\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e","exportId":"i0fd6573bf2128c4f5deadae5daaf811b"},{"id":536533,"title":"Lec4\u00265.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec03P.pdf"}]},{"id":116852,"name":"Week 3","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"iee99aa3dd8b31d057dfc80fc720d2627","items":[{"id":541745,"title":"Lec4\u00265.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec03P_E.pdf"},{"id":543316,"title":"Lab 02","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":"2019-01-23T22:00:00-05:00","lockAt":null,"unlockAt":"2019-01-23T10:00:00-05:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 2 - POSIX Threads\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 23, at 10pm\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 1\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 23th at 2:10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this lab!\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e \u003c/h2\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this lab. You should have already received an email with your Scinet login. In that email, you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e1. Introduction\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with POSIX threads. Please start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will work with a partner for this lab, but you may also discuss your results with your classmates. Please log into MarkUs well before the deadline to find your repository and make sure that you can commit to it. Do not create a separate directory in your repository, it should already be created for you. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ebefore\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e2. Requirements\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e Scinet from \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/labs/lab2/starter_code.tgz so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour task for this exercise is to work on implementing a basic algorithm both sequentially and in parallel, using pthreads. The goal is to get some insight into the decisions involved in parallelizing an algorithm.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003ePart1: Sequential algorithm\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you are to implement a basic algorithm for scaling down a set of measurements by a set of weights. The measurements are stored in an array of floating-point numbers M, of size N, and the weights are stored in an array \u003cimg class=\"equation_image\" title=\"R\" src=\"https://q.utoronto.ca/equation_images/R\" alt=\"LaTeX: R\" data-equation-content=\"R\"\u003e, of the same size. The result \u003cimg class=\"equation_image\" title=\"R\" src=\"https://q.utoronto.ca/equation_images/R\" alt=\"LaTeX: R\" data-equation-content=\"R\"\u003e is generated by scaling down the items of \u003cimg class=\"equation_image\" title=\"M\" src=\"https://q.utoronto.ca/equation_images/M\" alt=\"LaTeX: M\" data-equation-content=\"M\"\u003e by the weights \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ein \u003cimg class=\"equation_image\" title=\"W\" src=\"https://q.utoronto.ca/equation_images/W\" alt=\"LaTeX: W\" data-equation-content=\"W\"\u003e, as follows:\u003cimg class=\"equation_image\" title=\"R_i\\:=\\:M_i\\:\\times W_i\" src=\"https://q.utoronto.ca/equation_images/R_i%255C%253A%253D%255C%253AM_i%255C%253A%255Ctimes%2520W_i\" alt=\"LaTeX: R_i\\:=\\:M_i\\:\\times W_i\" data-equation-content=\"R_i\\:=\\:M_i\\:\\times W_i\"\u003e  for \u003cimg class=\"equation_image\" title=\"0\\:\\le i\\:\u0026lt;\\:n\" src=\"https://q.utoronto.ca/equation_images/0%255C%253A%255Cle%2520i%255C%253A%253C%255C%253An\" alt=\"LaTeX: 0\\:\\le i\\:\u0026lt;\\:n\" data-equation-content=\"0\\:\\le i\\:\u0026lt;\\:n\"\u003e. Both \u003cimg class=\"equation_image\" title=\"M\" src=\"https://q.utoronto.ca/equation_images/M\" alt=\"LaTeX: M\" data-equation-content=\"M\"\u003e and \u003cimg class=\"equation_image\" title=\"W\" src=\"https://q.utoronto.ca/equation_images/W\" alt=\"LaTeX: W\" data-equation-content=\"W\"\u003e are generated internally in the starter code.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must time the computation part involving the scaling algorithm (do not include other items like reading from a file or printing output). You must use the \u003cem\u003eclock_gettime()\u003c/em\u003e function for this purpose. For further documentation on this, please consult the manual pages. For testing purposes, the array R must be saved to a file \"sequential_output.txt\" (this is done by the starter code).\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003ePart2: Parallel algorithm\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePOSIX threads or pthreads offer a standardized API for writing multithreaded programs. To implement a multithreaded program you will need to create a set of threads, and wait for them to finish. Before you start, you must read sections 1 through 5.3 from this \u003c/span\u003e\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epthreads tutorial\u003c/span\u003e\u003c/a\u003e \u003cspan style=\"font-weight: 400;\"\u003efrom the Lawrence Livermore National labs. The sections indicated contain a basic introduction to pthreads, which you will need to complete this lab.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you must parallelize the algorithm from part1 using pthreads. Each thread computes a set of items from the result R, independently of all other threads. Your code must take a command line argument: the number of threads, T. This is already implemented in the starter code.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour parallel algorithm must contain two versions corresponding to the following approaches: \u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded: Each thread processes an equal amount of consecutive elements from R (using the corresponding elements from M and W). For example, if N = 8 and T = 2, then thread 0 is assigned elements R0, R1, R2, and R3 from the result, while thread 1 computes elements R4, R5, R6, and R7. N is selected to be power of two so, an even number of elements get assigned to each thread. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eStrided: Each thread processes every T-th item. For example, if T = 4, then thread 0 will process items R0, R4, R8, etc., thread 1 will process items R1, R5, R9, etc.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this part, you must also time your code, and compare the two parallel versions between each other, as well as against the sequential version. For testing purposes, the array R must be saved to the files \"sharded_output.txt\" and \"strided_output.txt\". This is already implemented in the starter code. You can increase N  to see significant differences. If N does not divide exactly by T, then the last thread gets assigned a few elements more or less than all other threads. Remember to set N back to the original number in the starter code since we autograde using that value. What do you notice? Discuss your findings with your TA. One easy sanity check is to run the diff command on your output files. For instance, diff sequential_output.txt sharded_output.txt should produce no output, i.e., the files are identical.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003e3. Running the code:\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor running Lab02 on Scinet compute nodes a script named with run-job-lab02.sh is provided. You can call this script by calling ./run-job-lab02.sh \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e4. Submission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints the execution time for the sequential and parallel code. All your code should be included in a single C file, named lab2pthreads.c. Your output should consist of 4 lines, two lines for the sequential implementation, one for each parallel implementation. Each line must contain the name of the implementation, followed by a single space, followed by the equals sign, followed by a single space, followed by a floating point number representing the time taken (in seconds) for the respective algorithm. For example:\u003c/span\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003cspan style=\"font-weight: 400;\"\u003esequential = 0.0123123123\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003esequential = 0.0123123123\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eparallel strided = 0.01231231\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eparallel sharded = 0.01231231\u003c/span\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe order in which the implementations are reported should be exactly as above, that is, sequential, then parallel strided, then parallel sharded. Make sure to commit the Makefile as well. \u003c/span\u003e\u003cstrong\u003eDo not commit any of the .txt files\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e. Make sure your code compiles and runs on the Scinet cluster. \u003c/span\u003e\u003c/p\u003e","exportId":"id33b9075ac365305b2f60e75d4c28bec"},{"id":551050,"title":"Lec6.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec6P.pdf"}]},{"id":119259,"name":"Week 4","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i3f8f7ceda3f321eae2d89e99a5ec0a7b","items":[{"id":555154,"title":"Assignment two","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":"2019-02-11T22:00:00-05:00","lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAssignment 2 - Parallel Data and Task Management\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Monday February 11, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 10 \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday January 30, at 10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this assignment!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eIntro to Scinet:\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this assignment. You should have already received an email with your Scinet login. In that email you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et  document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eOverview\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work in groups of two for this assignment. Before you start, you must read section 7 from this \u003c/span\u003e\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epthreads tutorial\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e from the Lawrence Livermore National labs.  Your task is to implement a series of image processing methods, then parallelize them using data decomposition (partitioning) and the following parallel models: the data parallel model, and the work pool model.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease log into MarkUs as soon as possible to find your repository and invite your partner, and make sure that you can commit and push to your repo. For all assignments and labs you will be given your repo URL on MarkUs. Make sure to use this repository (which should already be created for you), otherwise MarkUs won't know about it and we won't be able to see your work.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eon\u003c/span\u003e \u003cem\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter/assignments/assignment2/starter_code.tgz\u003c/span\u003e\u003c/em\u003e \u003cspan style=\"font-weight: 400;\"\u003e \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments. \u003c/span\u003e\u003cstrong\u003eTo encourage you to avoid versioning things that you won't need to submit, we've included a \".gitignore\" file for you in the starter code. Feel free to adjust it for your needs.\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease note that this assignment is once again, meant to be practical and encourage your critical thinking ability. Therefore, the implementation component is not incredibly time consuming (although you do have to reserve reasonable time for it), but you will likely spend quite a bit of time in analyzing your findings and reasoning about your results.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eImage representation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be working with images in the pgm format. Feel free to go over the image specification\u003c/span\u003e\u003ca href=\"http://netpbm.sourceforge.net/doc/pgm.html\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e (don't read the \"Plain PGM\" section). You don't have to worry too much about the format, as we provide you with code that reads a pgm image and transforms it into an array of pixels in grayscale, and all of your work will be done with this array. If you are curious, this code is in the files \u003cem\u003epgm.h\u003c/em\u003e and \u003cem\u003epgm.c\u003c/em\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will notice that images are represented as a 1-dimensional array in the code, even though intuitively they are 2-dimensional (why do we do this?). It is your job to calculate the corresponding offsets in the 1 dimensional array of pixels in the 2-dimensional image.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eImage processing\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eImage processing techniques are exciting and useful in many situations: to obtain various artistic effects, sharpen blurry photos, perform edge detection, etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, you will be working with monochrome (greyscale) images. Monochrome images are represented as a two-dimensional array of pixels. Each pixel is stored as a byte and encodes a greyscale color as a value between 0 and 255.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA discrete Laplace operator is used to compute the second derivatives of an image, which can emphasize edges within an image. This is useful in image processing for performing edge detection and various other related applications. The discrete Laplacian filter is a 3 x 3 array, which typically contains a high negative value at the center, surrounded by small positive values. Some variations include opposite signs, to achieve a similar effect.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHere are some examples of two Laplacian filters:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\left(\r\n\\begin{matrix}\r\n1 \u0026amp; 1 \u0026amp; 1 \\\\\r\n1 \u0026amp; -8 \u0026amp; 1 \\\\\r\n1 \u0026amp; 1 \u0026amp; 1\r\n\\end{matrix}\r\n\\right)\" src=\"https://q.utoronto.ca/equation_images/%255Cleft(%250A%255Cbegin%257Bmatrix%257D%250A1%2520%2526%25201%2520%2526%25201%2520%255C%255C%250A1%2520%2526%2520-8%2520%2526%25201%2520%255C%255C%250A1%2520%2526%25201%2520%2526%25201%250A%255Cend%257Bmatrix%257D%250A%255Cright)\" alt=\"LaTeX: \\left(\r\n\\begin{matrix}\r\n1 \u0026amp; 1 \u0026amp; 1 \\\\\r\n1 \u0026amp; -8 \u0026amp; 1 \\\\\r\n1 \u0026amp; 1 \u0026amp; 1\r\n\\end{matrix}\r\n\\right)\" data-equation-content=\"\\left(\r\n\\begin{matrix}\r\n1 \u0026amp; 1 \u0026amp; 1 \\\\\r\n1 \u0026amp; -8 \u0026amp; 1 \\\\\r\n1 \u0026amp; 1 \u0026amp; 1\r\n\\end{matrix}\r\n\\right)\" data-mathml='\u0026lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"\u0026gt;\r\n  \u0026lt;mrow\u0026gt;\r\n    \u0026lt;mo\u0026gt;(\u0026lt;/mo\u0026gt;\r\n    \u0026lt;mtable rowspacing=\"4pt\" columnspacing=\"1em\"\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mo\u0026gt;\u0026amp;#x2212;\u003c!-- − --\u003e\u0026lt;/mo\u0026gt;\r\n          \u0026lt;mn\u0026gt;8\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n    \u0026lt;/mtable\u0026gt;\r\n    \u0026lt;mo\u0026gt;)\u0026lt;/mo\u0026gt;\r\n  \u0026lt;/mrow\u0026gt;\r\n\u0026lt;/math\u0026gt;'\u003e or \u003cimg class=\"equation_image\" title=\"\\left(\r\n\\begin{matrix}\r\n0 \u0026amp; 1 \u0026amp; 0 \\\\\r\n1 \u0026amp; -4 \u0026amp; 1 \\\\\r\n0 \u0026amp; 1 \u0026amp; 0\r\n\\end{matrix}\r\n\\right)\" src=\"https://q.utoronto.ca/equation_images/%255Cleft(%250A%255Cbegin%257Bmatrix%257D%250A0%2520%2526%25201%2520%2526%25200%2520%255C%255C%250A1%2520%2526%2520-4%2520%2526%25201%2520%255C%255C%250A0%2520%2526%25201%2520%2526%25200%250A%255Cend%257Bmatrix%257D%250A%255Cright)\" alt=\"LaTeX: \\left(\r\n\\begin{matrix}\r\n0 \u0026amp; 1 \u0026amp; 0 \\\\\r\n1 \u0026amp; -4 \u0026amp; 1 \\\\\r\n0 \u0026amp; 1 \u0026amp; 0\r\n\\end{matrix}\r\n\\right)\" data-equation-content=\"\\left(\r\n\\begin{matrix}\r\n0 \u0026amp; 1 \u0026amp; 0 \\\\\r\n1 \u0026amp; -4 \u0026amp; 1 \\\\\r\n0 \u0026amp; 1 \u0026amp; 0\r\n\\end{matrix}\r\n\\right)\" data-mathml='\u0026lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"\u0026gt;\r\n  \u0026lt;mrow\u0026gt;\r\n    \u0026lt;mo\u0026gt;(\u0026lt;/mo\u0026gt;\r\n    \u0026lt;mtable rowspacing=\"4pt\" columnspacing=\"1em\"\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mo\u0026gt;\u0026amp;#x2212;\u003c!-- − --\u003e\u0026lt;/mo\u0026gt;\r\n          \u0026lt;mn\u0026gt;4\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n    \u0026lt;/mtable\u0026gt;\r\n    \u0026lt;mo\u0026gt;)\u0026lt;/mo\u0026gt;\r\n  \u0026lt;/mrow\u0026gt;\r\n\u0026lt;/math\u0026gt;'\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA Laplacian filter can be applied to an existing image, by considering each pixel and its surrounding 8 neighbors and multiplying the 9-pixel values with the corresponding values in the Laplacian filter. The sum of the pairwise multiplications is used as the new value of that pixel.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePixels on the edges and corners of the image are dealt with a bit differently since they do not have all 8 neighbors. Only the valid neighbors and the corresponding filter weights are factored into computing the new value of such a \"marginal\" pixel.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIntuitively, the Laplacian filter emphasizes sudden changes in pixel values. The weights in the Laplacian filter end up setting a darker tone for areas with low pixel changes, and contrasting white tones for sharp changes which represent edges.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce a pixel value is updated, you might notice that the new pixel values may end up outside the [0,255] range. When processing an image, the new pixel values must be brought back to the original range by a process called \u003cstrong\u003enormalization\u003c/strong\u003e. This involves finding the minimum (Min) and maximum (Max), from the new (out-of-bounds) pixel values, then using these to normalize the pixel values back into the [0,255] range. For example, assume that the new pixel values are in the range [-100, 190]. In this case, you must add 100 to all pixels to bring all pixels in the range [0, 290]. Then, you must scale all pixels multiplying with 255/290, to bring all pixels in the [0,255] range.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eYour program\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will implement a program which, given an image, it applies a discrete Laplacian filter to produce a new image. You will work with 4 different filters listed below; their respective matrices are already in the starter code provided (\u003cem\u003efilters.c\u003c/em\u003e).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe program takes the following command line arguments:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe input image: \"-i input.pgm\". This is an optional argument and can be ignored if the built-in parameter is used (see below).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe built-in parameter: \"-b image_number\". This argument indicates that your program will be run with one of the hardcoded images we provided. The reason for using these images and how to generate them will be explained later, in the testing tips section. Use 1 for a big square image or 2 for a very tall (one column) image. Either -b or -i must be specified.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe output image: \"-o output.pgm\". This is the resulting image after applying \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethe filter to the input image (or the built-in image selected). This is an optional argument. If the output image is not specified, then no output image is produced. That is, the program still computes the resulting image in memory but does not write it to a file on disk and its contents will be lost once the program exits. The reason for this will be clear in the testing tips section.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe number of threads: \"-n num_threads\". You must vary the number of \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethreads between 1 and the number of cores available on the test machine.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eTiming enabled: \"-t toggle_timing\". Timing is enabled if toggle_timing is set to 1, and disabled if set to 0. As described later, you will need to time the execution time of your \u003c/span\u003e\u003cstrong\u003eimage processing code\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe filter: \"-f filter_number\"\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe execution method: -m method_number\". If the method is SEQUENTIAL, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethe num_threads parameter can either not be provided or simply ignored.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe work chunk: \"-c chunksize\". This argument is optional and is only used when the execution method is WORK_QUEUE. This is described further in Part 3.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe are providing in the starter code a set of filters and run method macros which should be self-explanatory. The filter is one of a set of predefined filters (you will find the relevant macros in the starter code):\u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 3x3 Laplacian\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 5x5 Laplacian\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 9x9 Laplacian of Gaussian\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 1x1 Identity\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe method is the mode of execution, either sequential or one of several parallel strategies (described in Part 2 \u0026amp; 3):\u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSEQUENTIAL\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSHARDED_ROWS\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSHARDED_COLUMNS_COLUMN_MAJOR\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSHARDED_COLUMNS_ROW_MAJOR\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWORK_QUEUE\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will find an enumeration defining those methods in \u003cem\u003efilters.h\u003c/em\u003e. We have given you code that handles the parsing of the command line arguments in the \u003cem\u003emain.c\u003c/em\u003e file, so you don't have to change it.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 1 - Sequential implementation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this part, you will be using the SEQUENTIAL method and the predefined filters. This task is as simple as implementing the function\u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003e apply_filter2d\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e in the file \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003efilters.c\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNOTE:\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e you must especially test your sequential implementation \u003c/span\u003e\u003cstrong\u003ethoroughly\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e, with lots of corner cases and check against your own manual calculations on paper, to make sure that your code produces the correct image. Correctness is \u003c/span\u003e\u003cstrong\u003ecrucial\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e here, especially if you re-use the sequential code for filtering pieces of the image in your parallel implementations!\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 2 - Data Parallel implementation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will now write a Data Parallel implementation using pthreads. Each thread is statically assigned a chunk of the data to process. You must partition the data in three ways: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003ehorizontal sharding (or row partitioning):\u003c/span\u003e each thread processes a set of \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003econsecutive rows, such that each thread gets a roughly equal number of rows. If the total number of rows is not divisible by the number of threads, then each thread will be assigned nrows\u003cem\u003e/\u003c/em\u003enthreads rows, except possibly for the last thread, which may get assigned more rows.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003evertical sharding (or column partitioning):\u003c/span\u003e similar to horizontal sharding, but instead, each thread processes a (roughly) equal number of consecutive columns. For this partitioning, there are two processing methods: column major and row major. In column-major, a thread processes all the pixels in a column before moving on to its next assigned column. In row major, a thread processes first all the pixels from the first row of every column in its subset of columns, then moves on to the pixels from the second row of its columns, and so on.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis part consists of implementing part of the function \u003cem\u003eapply_filter2d_threaded\u003c/em\u003e in \u003cem\u003efilters.c\u003c/em\u003e. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor now, only handle the cases where the method parameter is one of: \u003c/span\u003e\u003cspan style=\"font-size: 1rem;\"\u003eSHARDED_ROWS, SHARDED_COLUMNS_COLUMN_MAJOR, SHARDED_COLUMNS_ROW_MAJOR.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eYou must now profile your code and determine where most of the execution time is spent.\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e If you have modularized your code well, it should be easy to prove that the code which does the image processing is where most of the computation time is spent.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 3 - Work Pool implementation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will now write a Work Pool implementation using pthreads. This is specified as the WORK_QUEUE method number. In the WORK_QUEUE method, the image is divided in square tiles of size chunk x chunk (where chunk is the command line argument described as the work chunk earlier). All the tiles (work chunks) are statically placed in a queue at the start of the program. A task has the granularity of one tile. That is, each thread will take one tile at a time from the queue and process it before proceeding to grab another tile. You must implement this abstraction \u003c/span\u003e\u003cstrong\u003eefficiently\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNote: Your implementation must ensure that accesses to shared resources are synchronized. Keep in mind that although your program may be run in sequential mode (that is, using a work pool with 1 thread), you should still use locking where necessary.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis part consists of implementing the remaining part of the function \u003cem\u003eapply_filter2d_threaded\u003c/em\u003e in \u003cem\u003efilters.c\u003c/em\u003e, in other words, you should handle the case where method is WORK_QUEUE.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eGeneral parallel guidelines\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn the parallel implementations, you have to consider the fact that normalization cannot be done until all threads know the Min and Max pixel values. We suggest structuring your computation into the following steps:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e- In the first stage, while applying the filters on a data partition, threads must also calculate a partial Min and Max pixel value from their assigned data partition. Consider having each of the threads store their partial Min and Max values into separate elements of a shared global array.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e- Once the filter is applied by all threads and each thread has calculated their local Min and Max values, all threads must synchronize to ensure that everyone has finished this step. This can be achieved by using a \u003cem\u003epthread_barrier\u003c/em\u003e construct (check out the documentation for further details).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e- Next, all threads calculate the global Min and global Max values using the other threads' local Min and Max. Once the threads all have the global Min and Max, the next step involves all threads performing the normalization on their assigned data partitions.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 4 - Data collection and analysis\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce you have implemented all the parts of the assignment and verified the correctness \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eof the output, you must measure the time taken in each of the previous parts, and collect all the necessary data points. We have already provided time measurements in the starter code, inside main.c. It's up to you to design meaningful experiments using this timing functionality.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should also collect other data using perf tools.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must plot your results visually (graphs!) and analyze your results.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must automate running the experiments, collecting the data and generating the graphs. You need to write a script (e.g. Python) that invokes your C program, performs all measurements, and produces all the graphs and other necessary data that you use to draw conclusions that you describe in your report. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe have provided a sample script perf_student.py to get you started. You must also describe your data collection programs and scripts in your report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003ci\u003e(Please note that the python scripts that help with generating the graphs is only made \u003cstrong\u003eavailable in the starter code after 6pm of Tuesday Jan 29th\u003c/strong\u003e to not overlap with the grace period of Assignment 1)\u003c/i\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn a report (you must name this file Report.pdf, see the following section), you must describe your implementation, your experiments and include the graphs, then analyze your results, draw conclusions and report your findings. It is important to show insight into what you are measuring and explain the performance of various strategies under certain conditions and inputs, explain why different methods perform in a certain way, etc. For example, you should discuss how well your algorithms scale and how various considerations discussed in class play a factor into the results. You should keep your report reasonably concise (e.g., 5-10 pages is ok, 40 pages is rather excessive), assuming a reasonable font size and readable figures.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eTo help guide your observations, we are recommending the following experiments and plotting the corresponding data points. You are welcome to run extra experiments and investigate further, but your report should at least describe your results and analyze your findings for the following experiments. \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eRun the sequential algorithm as well as the parallel methods for a given image. For each run, vary the number of threads from 1 to the total number of cores by doubling the number of threads (i.e.,., 1, 2, 4, 8.). We want the experiments to be on up to 8 threads which is the number of physical cores. Consider checking the L1 cache misses and explaining why and how these factor into your results. \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor the work queue implementation, the length of the tile is set to be equal to the number of threads used. That is, the chunk will be N x N, where N is the number of threads. Remember that your implementation uses synchronization regardless of N. In fact, observing the locking overhead when N=1 is an interesting aspect to consider. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eTest the work pool method for a variety of chunk sizes. For example, using N threads, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eyou could measure the time depending on chunk size, by changing the chunk size: 1x1, 2x2, 4x4, 8x8, 16x16, 32x32, etc. Plot a separate line for each N between 1 and the number of cores on the same graph. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eNow vary the filter size for each of the methods (including the sequential one). Keep the number of threads constant to an N = 8, i.e. the number of physical cores, and (for work pool) use a chunk size of N x N. You may additionally vary these if you wish, or if you plan to gain further insights. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eVary the images used for testing using the built-in ones, and any additional images \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eyou may wish to create yourself. Consider special cases that might help you gain certain insights into the differences between various methods (e.g., when would some of them likely perform better than others). Keep in mind that you must analyze your results in the report and discuss your findings. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch2\u003e\u003cstrong\u003eReport\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must write a report documenting your implementation, displaying your results in a meaningful way, and analyzing your findings. Name it \"Report.pdf\". In your report, you should present your implementation, the experimental setup and results. You should discuss what you noticed, draw conclusions and analyze the tradeoffs, if any. The report should be written in a scientific manner (clear structure, clear description of your approach, results, findings, etc., and should use technical writing instead of colloquial terminology or phrases). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eKeep in mind that presenting your experimental findings and observations to a technical audience is an important skill to develop as a computer scientist.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eTesting tips\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, here are a few tips to help you get a better experimentation \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eenvironment:\u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the Scinet server to run your experiments.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eA job file named with \u003cem\u003erun-job-a2.sh\u003c/em\u003e is provided that you can use for running the \u003cem\u003eperf_student.py\u003c/em\u003e on the Scinet compute node. You can execute \u003cem\u003erun-job-a2.sh\u003c/em\u003e by typing:\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e ./run-job-a2.sh.sh\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should be able to see some graphs by running the scripts but the graphs will be correct once you finish the TODOs properly.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eMeasuring architectural events using perf tools cannot be done accurately for the part you intend to measure, if your program is also writing the output image to a file, or doing \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eany serious IO (including printing timing measurements). This is why it is possible to disable writing the output to a file and collecting the timing. In other words, when using perf tools don't use -o and use -t 0. Consider carefully what you are measuring and how your program's execution parameters can impact your tests.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSince reading an image from disk might affect your architectural counter measurements too, you should consider using the hardcoded images we provide as part of the starter code, or generate your own in a similar fashion. Read the \u003cem\u003erun-job-a2.sh\u003c/em\u003e script in order to learn how to generate those images.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor each experiment, you must take the average of 10 runs. Measure the standard deviation of your timing results across the 10 runs, and (this takes a lot of work to code, so it is just a suggestion) consider adding error bars on your measurements, for clarifying if the difference between two test results is significant or whether your results are very noisy.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse small scale experiments or contrived examples, if you must test a specific behaviour. Check the correctness of your code though (including when making substantial code changes), because an incorrect result will render any performance measurement meaningless. For instance, you can create a small image by hand, apply one filter by hand (it's just basic arithmetic operations, after all), and compare the result with what your code produces. \u003c/span\u003e\u003cstrong\u003eAgain, you \u003c/strong\u003e\u003cstrong\u003e\u003ci\u003emust\u003c/i\u003e\u003c/strong\u003e\u003cstrong\u003e check on paper on a small example that your sequential algorithm works correctly.\u003c/strong\u003e\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003ch2\u003e\u003cstrong\u003eSubmission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will submit your code on MarkUs under your\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e Assignment2\u003c/em\u003e director\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ey (do not create this manually, it should be created for you when you log into your MarkUs web interface). Be sure to make it clear how to run your code with various configurations, in your report! You must also submit any files required to build your program (including any header files (optional), a \u003cem\u003eMakefile\u003c/em\u003e (mandatory!), etc.). \u003cspan style=\"text-decoration: underline;\"\u003eDo not submit executables or object files!\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOur autotesting script will invoke \u003cem\u003emake main\u003c/em\u003e to test the correctness of your code, that is, if it produces the correct output image. In other words, \u003cem\u003emake main\u003c/em\u003e MUST generate your binary file (the starter code already does that for you). Furthermore, you must provide a \u003cem\u003emake run\u003c/em\u003e target (see the provided Makefile), which will generate ALL graphs included in your report. It is ok if \u003cem\u003emake run\u003c/em\u003e takes roughly one hour to run.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may NOT modify the \u003cem\u003emain.c\u003c/em\u003e file, nor the\u003cem\u003e make main\u003c/em\u003e or \u003cem\u003emake pgm_creator\u003c/em\u003e targets in the Makefile. You must include at least the files\u003cem\u003e filters.c,\u003c/em\u003e \u003cem\u003efilters.h,\u003c/em\u003e \u003cem\u003emain.c, Makefile, pgm.c,\u003c/em\u003e \u003cem\u003epgm_creator.c,\u003c/em\u003e \u003cem\u003epgm.h\u003c/em\u003e. An ideal submission would only modify \u003cem\u003efilters.c\u003c/em\u003e and add the scripts for graph generation. Do NOT include the files related to the hardcoded images (\u003cem\u003every_{big,tall}_sample.{c,h}\u003c/em\u003e).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit the report documenting your implementation, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003epresenting the results, and discussing your findings. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAdditionally, you must submit an \u003cem\u003eINFO.txt\u003c/em\u003e file, which contains as the first 2 lines the following: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour name(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour UtorID(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you want us to grade an earlier revision of your assignment for whatever reason \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(for example, for saving some grace tokens if you had a stable submission before the deadline, tried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want marked. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAs a general rule, by default we will always take the last revision before the deadline \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(or last one after the deadline, up to your remaining unused grace tokens), so you should \u003c/span\u003e\u003cstrong\u003enot\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eif you submit late) is the one you want graded.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFinally, whether you work individually or in pairs with a partner, you \u003c/span\u003e\u003cstrong\u003emust\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e submit a \u003cem\u003eplagiarism.txt\u003c/em\u003e file, with the following statement:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA missing INFO.txt file will result in a 10% deduction (on top of an inherent penalty if we do not end up grading the revision you expect). \u003c/span\u003e\u003cstrong\u003eAny missing code files or Makefile will result in a 0 on this assignment\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e! \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ePlease reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAgain, make sure your code compiles without any errors or warnings.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eCode that does not compile will receive zero marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eChecklist\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eMake sure you have: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eImplemented the sequential version of the code and checked with a small \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eexample on paper to see if it produces the correct output pixel values.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eImplemented the parallel versions of the code:\u003c/span\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded rows\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded columns, column major\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded columns, row major\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWork queue\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWritten your make run target, which will invoke scripts that generate the graphs in your report.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eNOT modified make main and make pgm_creator.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eNOT modified main.c.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eCommited your: \u003c/span\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003esource code files (including headers)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003escripts for the graphs\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eMakefile\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eINFO.txt file\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eplagiarism.txt file\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eReport.pdf file\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003ch2\u003e\u003cstrong\u003eMarking scheme\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be marking based on correctness (90%), and coding style (10%). Make sure to write legible code, properly indented, and to include comments where appropriate (excessive comments are just as bad as not providing enough comments). Code structure and clarity will be marked strictly!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eOnce again: code that does not compile will receive 0 marks!\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e More details on the marking scheme: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSequential implementation: 5%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded parallel implementation: 30% (10% each)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWork-queue implementation: 15%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eReport: 40% (including testing scripts)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode style and organization: 10% (code organization and modularity (if applicable), code readability, reasonable variable names, avoid code duplication, appropriate comments where necessary, proper indentation and spacing, etc.)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eNegative deductions (please be careful about these!):\u003c/strong\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eCode does not compile: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e for *any* mistake, for example: missing source file necessary for building your code (including Makefile, header files, etc.), typos, any compilation error, etc\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eNo plagiarism.txt file: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (we will assume that your code is plagiarised and you wish to you withdraw your submission, if this file is missing)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eMissing or incorrect INFO.txt: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eWarnings: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eExtra output: -20%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (for any output other than what is required in the handout)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eCode placed in other subdirectories than indicated: -20%\u003c/strong\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"iddb96613ce5edd328efd7037b8c58fe5"},{"id":557002,"title":"Lab03","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":"2019-01-30T22:00:00-05:00","lockAt":null,"unlockAt":"2019-01-29T18:00:00-05:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 3 - \u003cstrong\u003e\u003cspan style=\"text-decoration: underline;\"\u003ePOSIX Threads and Synchronization\u003c/span\u003e\u003c/strong\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday January 30, at 10pm\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 1.5\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 30th at 2:10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this lab!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this lab. You should have already received an email with your Scinet login. In that email, you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e1. Introduction\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with pthreads and basic synchronization using mutexes. Please start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work with a partner for this lab, but you may also discuss your results with your classmates. Please log into MarkUs well before the deadline to find your repository and make sure that you can commit and push to it. Do not create a separate directory in your repository, it should already be created for you. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit/push your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e2. Requirements\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on Scinet under \u003c/span\u003e\u003cem\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/labs/lab3/starter_code.tgz\u003c/span\u003e\u003c/em\u003e \u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour task for this exercise is to work on implementing a basic hashtable, both a single-threaded version and a concurrent version, using pthreads. The goal is to get some exposure to synchronizing accesses to shared data, in a practical context.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 1: Non-concurrent hashtable\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you are to implement a basic hashtable which does not support concurrent accesses. We are providing a skeleton of the hash table implementation (\u003cem\u003ehash.h\u003c/em\u003e, \u003cem\u003ehash-nolock.c\u003c/em\u003e) as well as a basic program (\u003cem\u003etest-simple.c\u003c/em\u003e) that uses the hashtable to add items and retrieve them. You must not modify the \u003cem\u003ehash.h\u003c/em\u003e file, and must implement the exact interface specified in \u003cem\u003ehash.h\u003c/em\u003e, using the \"skeleton\" provided in \u003cem\u003ehash-nolock.c\u003c/em\u003e. You must time your hashtable using the stress test program (\u003cem\u003etest-perf.c\u003c/em\u003e) we provided. Important: your program shouldn't print anything on stdout/stderr except the execution time (see \u003cem\u003emain()\u003c/em\u003e function in \u003cem\u003etest-perf.c\u003c/em\u003e) if no errors occur; otherwise our autotester will fail your submission. Please remove all debugging output in your final submission.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 2: Concurrent hashtable\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eBefore you start, you must read section 7 from this pthreads\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/#Mutexes\"\u003e tutorial\u003c/a\u003e from the Lawrence Livermore National labs. The section contain a basic introduction to mutex locks, which you will need to complete this lab.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part you must implement a concurrent version of your hash table (in \u003cem\u003ehash-mutex.c\u003c/em\u003e), respecting the same interface in the \u003cem\u003ehash.h\u003c/em\u003e file. You must ensure that concurrent accesses (get or put items) to the same hashtable bucket are protected using mutexes, avoiding race conditions. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should also implement a parallel version of the stress test program we gave you in part1 (in \u003cem\u003etest-perf-parallel.c\u003c/em\u003e), using pthreads. Each thread must be assigned an equal number of operations to the hashtable (the one specified as a command line argument; see comments in \u003cem\u003etest-perf-parallel.c\u003c/em\u003e in the starter code).\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this part, you must also time your code, and compare the concurrent hashtable version against the single-threaded version. Discuss your findings with your TA.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003e3. Running the code:\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor running Lab03 on Scinet compute nodes two scripts called with \u003cem\u003erun-job-lab03-seq.sh\u003c/em\u003e and \u003cem\u003erun-job-lab03-parallel.sh\u003c/em\u003e  are provided in order to run the sequential and parallel implementation. You can call any of these scripts by putting “./” before it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e4. Submission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push all the files required to compile and run your code (all the source code and the makefile). \u003cstrong\u003eYou shouldn't need to add any new files to the starter code\u003c/strong\u003e, but if you do, make sure that you update the makefile accordingly. Make sure your code compiles and runs correctly on the Scinet teach cluster machines.\u003c/span\u003e\u003c/p\u003e","exportId":"i9064ec2df15c199a7449fbf111e04753"},{"id":563890,"title":"Lec7.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec7.pdf"},{"id":563891,"title":"Lec8.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec8.pdf"}]},{"id":120877,"name":"Week 5","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"ib6f3d0e7c9e4c8a53665b468bb8e35c7","items":[{"id":566438,"title":"Lec9.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec9.pdf"},{"id":576963,"title":"Lec10.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec10.pdf"}]},{"id":121938,"name":"Week 6","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"ie1807d0222a3978cee2dbbde576dd1ae","items":[{"id":573492,"title":"Assignment three","type":"Assignment","indent":0,"locked":true,"submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":"2019-03-01T22:00:00-05:00","lockAt":"2019-03-01T22:00:00-05:00","unlockAt":"2019-02-11T22:00:00-05:00","requirement":null,"completed":false,"exportId":"if0e304adfe4a3b8ccb76f63596570a95"},{"id":573493,"title":"Lab 04","type":"Assignment","indent":0,"locked":true,"submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":"2019-02-13T22:00:00-05:00","lockAt":"2019-02-13T22:00:00-05:00","unlockAt":"2019-02-12T18:00:00-05:00","requirement":null,"completed":false,"exportId":"id1659b985830a8dac0cd8f0207ec6cc6"},{"id":576964,"title":"Lec11.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec11.pdf"},{"id":585131,"title":"Lec12.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec12.pdf"}]},{"id":123391,"name":"Week 8","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i447507b353a1fd1bfbc2f910360fc9d9","items":[{"id":586356,"title":"Project","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":20.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eProject - Parallelizing a Particles Simulation \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eTotal Points: 20\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday  February 27, at noon. Your group partners for part 1 and part 2 remain the same. DO NOT change partners between the two parts or you will be flagged for plagiarism because of shared design between the parts!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue Date for Part 1:\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e This part includes the serial and the OpenMP section should be submitted on Monday, March 11th at 10PM. You have to submit the code using the project-part1 MarkUs instance. Grace tokens will be deducted if you submit part 1 after this deadline. You have to submit a report called report-part1.pdf on this deadline along with your complete code for Part 1 of the project. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue Date for Part 2: \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis part includes the MPI section should be submitted on Friday, March 22th at 10PM. You have to submit the code using the project-part2 MarkUs instance. Grace tokens will be deducted if you submit part 2 after this deadline. You have to submit a report called report-part2.pdf on this deadline along with your complete code for Part 2 of the project. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eImportant note for phase 2: \u003c/strong\u003eMPI jobs can run for a very long time if you have created a deadlock. Do not leave your jobs running for long periods of time. Always monitor your jobs submitted to the compute nodes. ALso, do not run large jobs on the login node! You are only allowed to run very short jobs on the login node. Jobs on the login node should only run for a few minutes at max! Always check that you do not have a long-running job on the login node. A code with a deadlock is considered a long job since it will never terminate. We will deduct 30% to 100% of your grade if you run long jobs on the login node. We do have the complete log of all jobs submitted to Scinet.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this project. You should have already received an email with your Scinet login. In that email you see a link to The short intro to Scinet  document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eBefore you start!\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNote that this is a project not an assignment. You will be evaluated on \u003cspan style=\"text-decoration: underline;\"\u003eyour efforts to \u003c/span\u003e\u003c/span\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eunderstand the problem\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e and \u003cspan style=\"text-decoration: underline;\"\u003eto \u003c/span\u003e\u003c/span\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan\u003ef\u003c/span\u003eind answers to issues that come up\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e as you start implementations. The project code, handout, and resources listed at the end of the handout provide you with all that is needed to understand the problem and even provide hints (read items 6 and 7 before you start the project, they are very helpful!). Being able to understand these and leverage them in your implementation is a part of your grade. To allow for a fair grading and to not give out answers, we might not be able to answer questions in Piazza that relate to questions that want us to explain the problem in detail or ask to resolve issues with your implementation. You are encouraged to ask questions from your classmates in Piazza, we will take note of students that actively help others and answer questions. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003cbr\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eOverview\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work with a partner for this project. In this project, we will be parallelizing a toy particle simulation (similar simulations are used in\u003c/span\u003e\u003ca href=\"http://www.thp.uni-duisburg.de/~kai/index_1.html\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e mechanics\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e,\u003c/span\u003e\u003ca href=\"http://www.ks.uiuc.edu/Research/namd/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e biology\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e, and\u003c/span\u003e\u003ca href=\"http://www.mpa-garching.mpg.de/gadget/clusters/index.html\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e astronomy\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e).  In our simulation, particles interact by repelling one another.  A run of our simulation is shown here:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"viewer/files/unnamed-1.gif\" alt=\"unnamed-1.gif\" width=\"200\" height=\"200\" data-api-endpoint=\"https://q.utoronto.ca/api/v1/courses/69683/files/2804499\" data-api-returntype=\"File\"\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe particles repel one another, but only when closer than a cutoff distance highlighted around one particle in grey.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eAsymptotic Complexity\u003c/span\u003e\u003c/h2\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eSerial Solution Time Complexity\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf we were to naively compute the forces on the particles by iterating through every pair of particles, then we would expect the asymptotic complexity of our simulation to be O(n^2).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHowever, in our simulation, we have chosen a density of particles sufficiently low so that with n particles, we expect only O(n) interactions.  An efficient implementation can reach this time complexity. The first part of your assignment will be to implement this linear time solution in a serial code, given a naive O(n^2) implementation.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eParallel Speedup\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eSuppose we have a code that runs in time T = O(n) on a single processor. Then we'd hope to run close to time T/p when using p processors.  After implementing an efficient serial O(n) solution, you will attempt to reach this speedup using two different programming models.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eStarter Code\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available on Scinet under:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter/assignments/project/starter.tgz\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code provides correct implementations of the particle simulation problem in serial/OpenMP/MPI, however, these implementations are not optimized for performance. Note that correctness does not mean optimized, it only means that the provided code correctly computes the particles interactions.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eRead the below on the source code structure carefully:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ecommon.cpp, common.h ; these files provide an implementation of common functionality, such as I/O, numerics and timing. Do not change these files by any means.  You will alter the physics if you do! We will use the default version (what we provide with the starter code) of these files for grading. You do not need to understand the underlying physics (such as ordinary differential equations and the Euler method) used in the common.cpp and common.h files since the movement of particles and how forces are applied are already correctly implemented for you in these two files.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eautograder.cpp; a code that helps calculate performance for both serial and parallel implementations. Do not change this file. We will use the default version (what we provide with the starter code) of this file for grading. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eMakefile; a makefile that compiles your code on Scinet. Do not create a make run command. Run your code using the sbatch files provided. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eserial.cpp: This file provides a correct serial implementation to the problem, however, the implementation is not optimal and is a naive O(n^2) implementation. Do not try to run this code for large particle sizes. It will not finish on-time and the sbatch files will timeout.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eopenmp.cpp: This file provides a correct parallel implementation of the problem in OpenMP. However, the implementation is not optimized for performance or scalability!\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003empi.cpp: This file provides a correct MPI implementation to the problem. However, the implementation is not optimized for performance or scalability!\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003esetup-project.sh: This file loads the modules and compiles your code. The jobs scripts are not called with this file.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ejob-teach-serial, job-teach-openmp, job-teach-mpi: are sbatch files that run your code with small number of particles and do not include the “-no” flag.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eauto-teach-*: are sbatch files that run your code with different number of particles/cores/processors and call the autograder. These runs are with the “-no” flag.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe recommend that you only change the serial.cpp, openmp.cpp, and mpi.cpp files. However, if you do decide to include other files or modify the Makefile (do not modify common.cpp, common.h, autograder.cpp), spell out the changes in your report. Also, spell out in your report what Makefile targets we are to build for the different parts of your report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eCorrectness and Performance\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA simple correctness check which checks the smallest distance between 2 particles during the entire simulation is provided (look inside the provided source code!). A correct simulation will have particles stay at greater than 0.4 (of cutoff) with typical values between 0.7-0.8. A simulation were particles don't interact correctly will have particles closer than 0.4 (of cutoff) with typical values between 0.01-0.05 . More details as well as an average distance are described in the source file.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe'd recommend keeping the correctness checker in your code (for the OpenMP and MPI codes the overhead isn't significant) but depending on performance desires it can be deleted as long as the simulation can still output a correct txt file.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe performance of the code is determined by doing multiple runs of the simulation with increasing particle numbers and comparing the performance with the autograder.cpp provided. This can be done automatically with the auto-* scripts.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThere will be two types of scaling that are tested for your parallel codes:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn strong scaling we keep the problem size constant but increase the number of processors\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn weak scaling we increase the problem size proportionally to the number of processors so the work/processor stays the same \u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor more details on the options provided by each file you can use the -h flag on the compiled executables.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eImportant notes for Performance and the Autograder:\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe scripts we are providing have small numbers of particles and large number of particles. We will use the same particles sizes to test the performance of your code! We will put great weight on your code running correctly and performing well for the large particles so don't just optimize for the small particles! \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eRemember to use the -no flag to “turn off all correctness checks and particle location outputs” for actual timing runs. Our auto-teach* scripts use the -no flag, but the job-teach-* does not include the -no flag. So use the job-teach-* for debugging and checking for correctness before moving to the job-teach* sbatch files that will help with actual timings and information on scaling and efficiency that the autograder provides. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eMore details on the autograder:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eSerial code performance will be tested via fitting multiple runs of the code to a line on a log/log plot and calculating the slope of that line. This will determine whether your code is attaining the O(n) desired complexity versus the starting O(n^2\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e). \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eOpenMP Memory performance and MPI Performance will be tested via calculating the strong and weak scaling average efficiencies for 1,2,4,8,16 processor/thread runs.\u003c/span\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe strong and weak average efficiencies ( eff\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ess\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e , eff\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ews\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e) are reported for your reference. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eImportant note about the autograder: The strong and weak scaling numbers reported by the autograder should only be taken seriously when you have optimized the serial code. To clarify, if you run the starter code only, the scaling efficiency and speedups reported by the autograder might not be bad, but don't be fooled! Recall the discussions in class on “how to fool the masses with reporting performance numbers!”  \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003c/span\u003e\u003c/h2\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 1: Serial and OpenMP\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you will write two versions of our simulation.  DO NOT change the headers in the provided sbatch scripts. First, you will write an O(n) serial code.  Then, you will write a parallel version of this O(n) code for shared memory architectures using OpenMP.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThere are two source files (serial.cpp and openmp.cpp) you need to modify.  You need to create one serial code (serial.cpp) that runs in O(n) time and one shared memory implementation (openmp.cpp) using OpenMP.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must represent your results visually (graphs!) and analyze them in a short report (you must name this file: report-part1.pdf). You should describe your implementation, plot and analyze your results, draw conclusions and report your findings in a written report. Write a very technically sound report and it is important to show insight into what you are measuring and explain the results you are seeing. Below lists examples of what you can include in your report:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA description of the design choices that you tried and how did they affect the performance.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlots: Serial: (1) A table that shows the running time of your optimized code for different particles sizes as well as the slope estimate for your optimized serial code. (2) A log-log plot of running time vs the number of particles to show that your optimized serial implementation runs in O(n) time.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlots: OpenMP: (1) The strong and weak scaling plots that show the running time of your optimized OpenMP implementation.  (2) The strong scaling plots that show the speedup of your optimized OpenMP implementation. (3) The strong and weak scaling plots that show the efficiency of your optimized OpenMP implementation. (4) Average weak and strong scaling efficiency.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eAnalyze the speedup plots to show how closely your OpenMP code approaches the idealized p-times speedup and a discussion on whether it is possible to do better.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWhere does the time go? Discuss the synchronization and locking strategies used in your code and the optimization you have made to make the code more efficient. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA discussion on your serial and OpenMP implementation.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 2: MPI\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe MPI part of the project is set to be implemented on one Scinet node. DO NOT change the headers in the provided sbatch scripts. Note that you should not make assumptions of the underlying network and do not optimize for a specific topology. We are using a “logical view” of a distributed system in this section so refer to “cores” as “processors” in all your plots. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThere is one source file (mpi.cpp) you need to modify. You need to create one distributed memory implementation (MPI) that runs in O(n) time with as close as possible to O(n/p) scaling.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must represent your results visually (graphs!) and analyze them in a short report (you must name this file: report-part2.pdf. You should describe your implementation, plot and analyze your results, draw conclusions and report your findings in a written report. It is important to show insight into what you are measuring and explain the results you are seeing.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHere are some items you might add to your report:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlots: (1) The strong and weak scaling plots that show the running time of your optimized MPI implementation.  (2) The strong scaling plots that show the speedup of your optimized MPI implementation. (3) The strong and weak scaling plots that show the efficiency of your optimized MPI implementation. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA description of the communication you used in the distributed memory implementation.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA description of the design choices that you tried and how they affect performance.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eAnalyze the speedup plots to show how closely your MPI code approaches the idealized p-times speedup and a discussion on whether it is possible to do better.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWhere does the time go? Consider breaking down the runtime into computation time or communication time. You can plot the distribution or even comeup with a parameterized expression that estimates the amount of data communication vs the computation cost.  How do they scale with p? If you have designed your partitioning to reduce communication costs, explain your strategy and why it works. What else comes into mind to improve your code?\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA discussion on your MPI implementation.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eTesting tips\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, you are required to use the teach cluster (SciNet) to get accurate performance results. You will be graded on the teach cluster only. You are free to use C or C++. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ejob-teach* files: These files will run one instance of your serial (or OpenMP, or MPI) implementation for small number of particles (see inside the job-teach-* file for more information)  with the -no flag disabled to print outputs related to particles locations and correctness issues. Run these files (one at a time) using sbatch job-teach-*\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eauto-teach-* files: These files will run your code for different particles sizes and/or a different number of particles and then run the autograder to report scaling and efficient numbers. Note that the -no flag is included to report accurate timings. Also note that these jobs will take longer to run and should not be used for checking code correctness.  The auto-teach-* files have two versions: *-small and *-large. The small files run your code for small particles. Please note that auto-teach-serial-small has a different number of particles compared to auto-teach-openmp-small and auto-teach-mpi small. This is because the unoptimized serial code runs very slow so we provide smaller particle sizes for the serial-small script. DO NOT use auto-teach-serial-large on an unoptimized serial code since it will timeout and never finish. Always optimize your code and test with the *-small scripts first then move to *-large files. Also, if you have not created efficient data structures or allocated memory properly, your code might crash for *-large files or you might get a segmentation fault. So optimize your code properly and remember that the optimizing your code for *-large files will be harder because of the large particle sizes!   Run these files (one at a time) using sbatch auto-teach-*\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400; font-size: 24pt;\"\u003eReport\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must write two reports (report-part1.pdf for part 1 and report-part2.pdf for part 2) documenting your implementation, displaying your results in a meaningful way, and analyzing your findings, for each part of the assignment. In your report, you should present your implementation, the experimental setup and results. You should discuss what you noticed, draw conclusions and analyze the tradeoffs, if any. The reports should be written in a scientific manner (clear structure, clear description of your approach, results, findings, etc., and should use technical writing instead of colloquial terminology or phrases). Keep in mind that presenting your experimental findings and observations to a technical audience is an important skill to develop as a computer scientist.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eTwo-Phase Submission\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is critical to read the below to submit your project properly. The project should be submitted in two parts:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003ePart 1 of the project that includes the serial and the OpenMP section should be submitted on Monday, March 11th at 10PM. You have to submit the code using the project-part1 MarkUs instance. Grace tokens will be deducted if you submit part 1 after this deadline. You have to submit a report called report-part1.pdf on this deadline along with your complete code for Part 1 of the project. Your submission for part 1 will be the only instance that we will use to grade for serial and OpenMP implementations. Please read the below on “\u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ecommon submission rules for both parts”\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003ePart 2 of the project that includes MPI section should be submitted on Friday, March 22th at 10PM. You have to submit the code using the project-part2 MarkUs instance. Grace tokens will be deducted if you submit part 2 after this deadline. You have to submit a report called report-part2.pdf on this deadline along with your complete code for Part 2 of the project. Your submission for part 2 will be the only instance that we will use to grade for MPI implementations. DO NOT assume that the course staff will look at your submission from part 1 to grade this section. Two different course staff might grade parts 1 and part 2. So include anything needed for this part to be fully stand alone. Please read the below on “\u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ecommon submission rules for both parts”\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eCommon submission rules for both parts: You must keep the same structure in your repository as the starter code. You must submit all the files required to build and run all your programs (including any header files and the makefile, etc.). You shouldn't need to add any new files to the starter code, but if you do, make sure that you update the makefile accordingly. Make sure your code compiles and runs correctly on Scinet. Be sure to make it clear in the report how to run your code! Do not submit any executables or object files! (do a \"make clean\" before making your final commit). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIMPORTANT: make sure to keep the optimization options (-O3) in the makefile in your final submission, otherwise your code will be too slow, even if your algorithms are efficient.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit two reports (named report-part1.pdf and report-part1.pdf) with the required content as described above. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eAdditionally, you must submit an INFO.txt file, which contains as the first 2 lines the following:\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour name(s)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour UtorID(s)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you want us to grade an earlier revision of your project for whatever reason (for example, for saving some grace tokens if you had a stable submission before the deadline, tried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want marked. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAs a general rule, by default we will always take the last revision before the deadline (or last one after the deadline, up to your remaining unused grace tokens), so you should not be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens if you submit late) is the one you want graded.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFinally, you must submit a plagiarism.txt file (in the top directory of the assignment), with the following statement: \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eA missing INFO.txt file will result in a 10% deduction (on top of an inherent penalty if we do not end up grading the revision you expect). Any missing code files or Makefile will result in a 0 on this assignment! Please reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eAgain, make sure your code compiles without any errors or warnings. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode that does not compile will receive zero marks!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eMarking Scheme\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour grade will depend on the performance and efficiency sustained by your codes on Scinet and will be broken into 3 parts. We will be marking based on performance and efficiency (65%), coding style (5%), and report (30%). This grading criteria will be applied to different parts as follows: Serial - 30%, OpenMP - 30%, MPI - 40%.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode that does not compile or computes the particle interactions incorrectly will receive 0 marks (for the part that applies)! \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor grading your performance, we will consider multiple factors such as the running time of the implementation as well the strong and weak scaling performances and efficiency. It is our discretion on how to distribute the performance grade between these metrics. For example, an unoptimized serial code has not merit and it will also invalidate all the weak and strong scaling numbers in the OpenMP and MPI parts!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNegative deductions (please be careful about these!):\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode does not compile: -100% for *any* mistake, for example: missing source file necessary for building your code (including Makefile, header files, etc.), typos, any compilation error, etc\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eChanges to common.h, common.c: -100%, you are not allowed to change these two files!\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eNo plagiarism.txt file: -100% (we will assume that your code is plagiarised and that you wish to withdraw your submission, if this file is missing)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eMissing or incorrect INFO.txt: -10%\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eWarnings: -10%\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eExtra output: -20% (for any output other than what is required in the handout)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode placed in other subdirectories than indicated: -20%\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSubmitted unnecessary files (compiled code, test reports, data files, etc.): -10%\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will deduct 30% to 100% of your grade if you run long jobs on the login node.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eCopyright\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe project is adapted from the XSEDE online course Applications of Parallel Computing. The copyright belongs to XSEDE and the staff for this online course as well as the University of Toronto CSC367 staff. Similar to all the assignments and labs, distribution of this project and your solutions, during or after the semester, is strictly prohibited and is considered plagiarism. Do not post your solutions online! Searching for solutions online is also considered plagiarism. We will use technology to track plagiarism and violations of any of the above rules. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eResources\u003c/span\u003e\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eShared memory implementations may require using locks that are available as \u003c/span\u003e\u003ca href=\"http://msdn.microsoft.com/en-us/library/7d2zxc0s(VS.80).aspx\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eomp_lock_t\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e in OpenMP (requires omp.h).\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eDistributed memory implementation may benefit from overlapping communication and computation that is provided by \u003c/span\u003e\u003ca href=\"http://www.mpi-forum.org/docs/mpi-1.1/mpi-11-html/node46.html\"\u003e\u003cspan style=\"font-weight: 400;\"\u003enonblocking MPI routines\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e such as MPI_Isend and MPI_Irecv.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eOther useful resources: \u003c/span\u003e\u003ca href=\"http://openmp.org/wp/2008/11/sc08-openmp-hands-on-tutorial-available/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eOpenMP tutorial\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e, \u003c/span\u003e\u003ca href=\"http://www.openmp.org/specifications/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eOpenMP specifications\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e and \u003c/span\u003e\u003ca href=\"http://mpi-forum.org/docs/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eMPI specifications\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eProgramming in shared and distributed memory models are introduced in Lectures.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eIf you want a parallel debugging tool, Scinet has DDT installed, however, if you plan to use DDT on Scinet, remember the ask for a dedicated node (\u003c/span\u003e\u003ca href=\"https://docs.scinet.utoronto.ca/index.php/Niagara_Quickstart\"\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://docs.scinet.utoronto.ca/index.php/Niagara_Quickstart\u003c/span\u003e\u003c/i\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e) and you do need to ssh using X server! \u003c/span\u003e\u003ca href=\"http://www.cs.uoregon.edu/Research/tau/home.php\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eTAU (Tuning and Analysis Utilities)\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e is a source code instrumentation system to gather profiling information; this system can profile MPI, OpenMP and mixtures, but it has a learning curve. Tau is not installed on Scinet so if you decide to use it you need to run outside of Scinet. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eHints on getting O(n) serial and Shared memory and MPI implementations (\u003c/span\u003e\u003ca href=\"https://drive.google.com/open?id=11vjRefkcRA3a8DlH1t0QoVYw_TMx9RTl\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epdf\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e). Please note that while these slides provide very useful hints on describing the problem and general approaches that you might want to take, they are not necessarily providing you with the most efficient solution. So do not limit your creativity! \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUseful reading: \u003c/span\u003e\u003ca href=\"https://docs.scinet.utoronto.ca/index.php/Introduction_To_Performance#Strong_Scaling_Tests\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://docs.scinet.utoronto.ca/index.php/Introduction_To_Performance#Strong_Scaling_Tests\u003c/span\u003e\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e","exportId":"i0d42e6b487e946ec49aaa342a40c439d"},{"id":586408,"title":"Lab 05","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":"2019-02-27T22:00:00-05:00","lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 5 - MPI \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, February 27, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 1.5 \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: You should work with a partner, the deadline for finding a partner is Wednesday, February 27, at  2:10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this lab. You should have already received an email with your Scinet login. In that email you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et  document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e1. Introduction\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with MPI routines, especially with complex collective operations. Please start early to fully take advantage of the lab time to ask questions. You should read sections 5, 9, 10 and 11 of the \u003ca href=\"https://computing.llnl.gov/tutorials/mpi/\"\u003eMPI tutorial\u003c/a\u003e from the Lawrence Livermore National Laboratory before starting this lab.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003cbr\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eMarkUs will only create the appropriate directory in your repository when you log into MarkUs. Please log into MarkUs well before the deadline to take these steps, find your repository and make sure that you can commit and push to it. Do not create a separate directory in your repository, it should already be created for you. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ebefore\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e the exercise deadline to ensure that you know where to commit/push your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e2. Preliminaries\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet under \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/labs/lab5/starter_code.tgz\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e3. Requirements\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour task for this exercise is to work on implementing two short pieces of code using MPI constructs. The goal is for you to get some hands-on experience with MPI and time your parallel code.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart1: Gather/Allgather\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you are to implement code that transposes an N x N matrix using only MPI_Gather (or MPI_Allgather) operations. You may use MPI_Barrier as well, if necessary. You must \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eimplement this version of the program in the file transpose-sg.c.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor simplicity, you may assume that N == P, where P is the number of processes. Under this assumption, each process starts with an array holding one row, and the master (rank 0) must in the end have the transposed matrix. You must initialize the rows with values that allow you to check the correctness of your program (for example, if you use random values it \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003emight be tricky to test the validity of your code). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may use MPI_Allgather, such that all processes will receive the transposed matrix (not only the master), but it's not necessary and will not be tested. Once you get your code working, you are encouraged to try to make your code as general as possible, but this will not be tested.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must make sure that your code produces correct result first. Then, you must time your code, using MPI_Wtime(). You may take the time elapsed on the master node as the time taken by the operations measured (see comments in the starter code). NOTE: execution times must be reported in \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003emilliseconds\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003edouble t1, t2, elapsed;\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003et1 = MPI_Wtime();\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e... \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003et2 = MPI_Wtime();\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eelapsed = t2 - t1;\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003cbr\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart2: All-to-all\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, your task is to implement an N x N matrix transposition, but this time you must use the MPI_Alltoall operation. You must implement this version of the program in the file \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003etranspose-alltoall.c. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHint: in the simple case, transposing the rows using the MPI_Alltoall operation should be trivial. You may have to collect all the transposed rows into the master though (as a separate final operation).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must make sure that your code produces the correct result, and time your code for this part as well. Discuss your approach with your TA if you get stuck.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNOTE: you must keep the same output format as in the starter code. Do not add any new output, otherwise the \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eautotester will fail your submission.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e4. Running the code:\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor running Lab05 on Scinet compute nodes two scripts named run-job-lab05-part1.sh and run-job-lab05-part2.sh are provided in order to run the first and second parts of the lab respectively. You can call any of these scripts by putting “./” behind it. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e5. Submission\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push all the files required to compile and run your code (all the source code and the makefile). You shouldn't need to add any new files to the starter code, but if you do, make sure that you update the makefile accordingly. Make sure your code compiles and runs correctly on the Scinet cluster.\u003c/span\u003e\u003c/p\u003e","exportId":"iff33c2b823d5364fdae06756b85cb5af"},{"id":599481,"title":"Lec13.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec13.pdf"},{"id":602986,"title":"Lec14.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec14.pdf"}]},{"id":125543,"name":"Week 9","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i2605ed34361adcfbd5a4ebeee0535925","items":[{"id":602640,"title":"Lec15.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec15.pdf"},{"id":613554,"title":"Lec16.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec16.pdf"}]},{"id":128211,"name":"Week 10","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i7f1543ebbd6b2fc6a42d3bc2503b908c","items":[{"id":616394,"title":"Lec17\u002618.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec17.pdf"},{"id":617129,"title":"Lab 06","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-12T18:00:00-04:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 6 - GPU intro, device specs\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday March 13, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e: 1\u003c/p\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you understand the GPU architecture and the CUDA environment, by querying the device to determine its properties. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSee the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation for more information. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work in pairs for this exercise, with your A4 partner, since some code will potentially be common with the assignment. MarkUs will only create the appropriate directory in your repository when you log into MarkUs and either create your group, or declare that you will work alone. The groups will get a new shared repository, and the students working solo may also get a new repository. Please log into MarkUs well before the deadline to take these steps. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on wolf (the department’s teach/CDF machines) under\u003c/span\u003e\u003cem\u003e\u003cstrong\u003e /u/csc367h/winter/pub/labs/lab6/starter_code.tgz \u003c/strong\u003e\u003c/em\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eBackground\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn order to leverage the immense power of the GPUs, one must understand how devices operate, and how memory is organized. Before getting to allocating memory, launch computations, and all the fun things that come with programming in the CUDA environment though, it would be useful to know how to retrieve some information about the GPU, such as how much memory and what type of capabilities it has.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePhysical GPUs are called devices. When the CUDA environment is initialized, the driver creates a global data structure that contains the names and capabilities of the available devices (e.g., amount of device memory, clock rate, etc.). Applications can query these device properties either by invoking the driver directly, or by using the CUDA runtime. We will only focus on the latter, since it is easier to use by CUDA novices.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eThe number of CUDA capable devices can be retrieved by using \u003ccode\u003ecudaGetDeviceCount()\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ecudaError_t cudaGetDeviceCount(int* deviceCount);\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eOn success, this returns \u003ccode\u003ecudaSuccess\u003c/code\u003e. The number of CUDA capable devices may be 0, 1, or more, as indicated by dereferencing deviceCount. On error, the CUDA error message can be extracted from the \u003ccode\u003ecudaError\u003c/code\u003e code by using:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003echar* cudaGetErrorString(cudaError_t)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe CUDA runtime exposes the \u003ccode\u003ecudaDeviceGetProperties()\u003c/code\u003e function, which will fill a \u003ccode\u003ecudaDeviceProp\u003c/code\u003estructure, for the device number passed in as the second argument:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003evoid cudaGetDeviceProperties(cudaDeviceProp* deviceProp, int deviceNumber)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eHere are just a few of the properties stored in the \u003ccode\u003ecudaDeviceProp\u003c/code\u003e structure. These properties are fairly intuitive, but some will only be clear once we learn more about how to structure computations in grids, blocks, and thread warps.\u003c/p\u003e\r\n\u003cp\u003eDevice property Description\u003c/p\u003e\r\n\u003ctable\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003echar\u003c/span\u003e name[256]\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eA string identifying the device. On the teaching labs, you will find \"GeForce GTX 1050 Ti\" discrete NVIDIA cards.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e major\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eThe major revision number of the device's compute capability.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e minor\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eThe minor revision number of the device's compute capability.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e multiProcessorCount;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eThe number of multiprocessors on the device. The total number of CUDA cores can be calculated from the compute capability number. The _ConvertSMVer2Cores utility function \"decodes\" the number of cores per multiprocessor, from the compute capability major and minor numbers.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e clockRate;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eGPU clock frequency, in kHz.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e memoryClockRate;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMemory clock rate, in kHz.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e memoryBusWidth;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eGlobal memory bus width, in bits.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003esize_t\u003c/span\u003e totalGlobalMem\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eTotal global memory on the device, in bytes.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003esize_t\u003c/span\u003e sharedMemPerBlock;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eTotal amount of shared memory in each block, in bytes.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003esize_t\u003c/span\u003e l2CacheSize\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eL2 cache size, in bytes.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e regsPerBlock;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eNumber of 32-bit registers per block.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e maxGridSize[3];\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMaximum number of blocks allowed on each dimension of a grid.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e maxThreadsDim[3];\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMaximum number of threads allowed on each dimension of a block.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e maxThreadsPerBlock;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMaximum number of threads allowed per block.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e warpSize;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eNumber of threads in a warp.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eKeep in mind that this structure has many more fields. Feel free to consult the CUDA documentation for further details. Some these properties will make a lot more sense a bit later, but for now this should give you a good sense of what your GPU can do.\u003c/p\u003e\r\n\u003ch2\u003eYour task\u003c/h2\u003e\r\n\u003cp\u003eYour task for this exercise is simple. Your program must output each of the device properties described in the table above. We have provided some code to get you started, and a Makefile. The starter code contains all the printf function calls you need, with the appropriate strings, so your job consists of replacing the \u003ccode\u003eREPLACE ME\u003c/code\u003e macro with the appropriate variables.\u003c/p\u003e\r\n\u003cp\u003eThe expected output on the lab machines that have discrete NVIDIA cards, is the following:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\r\n    Found 1 CUDA Capable device(s)\r\n\r\n    Device 0: \"GeForce GTX 1050 Ti\"\r\n      CUDA Capability Major/Minor version number:    6.1\r\n      ( 6) Multiprocessors x (128) CUDA Cores/MP: 768 CUDA Cores\r\n      GPU Clock Rate:                                1.39 GHz\r\n      Memory Clock Rate:                             3.50 GHz\r\n      Memory Bus Width:                              128-bit\r\n\r\n      Total amount of global memory:4040 MBytes (4235919360 bytes)\r\n      Shared Memory per Block:                       49152\r\n      L2 Cache Size:                                 1048576\r\n      Registers per Block:                           65536\r\n\r\n      Max grid size:                                 (2147483647, 65535,65535)\r\n      Max thread dimensions:                         (1024, 1024,64)\r\n      Max threads per block:                         1024\r\n      Warp size:                                     32\r\n\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eYou should not hardcode the answers in the code. For instance, you should not have a printf statement like \u003ccode\u003eprintf(\"Warp size: %d\", 32);\u003c/code\u003e in your solution.\u003c/p\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints the required items in the right format. All your code should be included in a single cpp file, named \u003ccode\u003elab6.cpp\u003c/code\u003e. Make sure your code compiles and runs on the teaching lab machines.\u003c/p\u003e","exportId":"i841881a934f3c568a5180f78fa948889"}]},{"id":129612,"name":"Week 11","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i67bdfdf0bbb91892d5b546b22eebb077","items":[{"id":627313,"title":"Assignment Four","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-18T18:00:00-04:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAssignment 4 - GPUs and CUDA\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Friday, April 5, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eOverview\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, you will work with CUDA to design efficient code that leverages the parallel processing power of GPUs to do some image processing. In order to efficiently solve a problem and fully leverage the potential of GPUs, you have to consider everything we discussed in lectures and labs, to design a solution in the GPU model. See the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation guide for more information. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work with a partner on this assignment. We recommend that you work with your A2 partner. Please log into MarkUs as soon as possible to find your repository and invite your partner (should you choose to have one), and make sure that you can commit and push to your repo. For all assignments and labs you will be given your repo URL on MarkUs. Make sure to use this repository (which should already be created for you), otherwise, MarkUs won't know about it and we won't be able to see your work.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available on wolf (the department’s teach/CDF machines) under\u003cstrong\u003e /u/csc367h/winter/pub/assignments/a4/starter_code.tgz\u003c/strong\u003e so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eKeep in mind that most courses have assignments due in the last week of classes, so make sure to start early on this assignment!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003eYour task\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this assignment, you will implement a discrete Laplacian filter kernel on the GPU, using CUDA. You may choose any of the filters described in A2, but the filter dimension should be at least 3x3 (suggestion: try different filter sizes, what do you observe?). Your code must efficiently process the image in parallel, and take advantage of the GPU's massive parallelism and memory bandwidth. Additionally, if you have not already in a previous assignment, you must implement a CPU version which also processes the image in parallel, using POSIX threads. You should use the fastest CPU implementation for a fair comparison. Make sure you tweak your A2 implementation if needed. Remember that CDF machines have 4 cores.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour code will be assessed based on efficiency/performance, so you must make sure to take advantage of all the things we discussed in class. You are welcome to perform additional optimizations, as long as they are supported by the capabilities of the cards from the GPU cluster. \u003c/span\u003e For the following examples, assume we have a 4x4 pixel matrix and threads T0, T1, ... Your code should contain at least 5 GPU implementations:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 1\u003c/strong\u003e - One pixel per thread, column major. In this case, the work is distributed as follows:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0]\r\n    T1: pixel[1][0]\r\n    T2: pixel[2][0]\r\n    T3: pixel[3][0]\r\n    T4: pixel[0][1]\r\n    T5: pixel[1][1], etc.\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 2 \u003c/strong\u003e- One pixel per thread, row major. In this case, the work is distributed as follows:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0]\r\n    T1: pixel[0][1]\r\n    T2: pixel[0][2]\r\n    T3: pixel[0][3]\r\n    T4: pixel[1][0]\r\n    T5: pixel[1][1], etc.\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 3 \u003c/strong\u003e- Multiple pixels per thread, consecutive rows, row major. Assuming you have, for example, 2 threads:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0] pixel[0][1] pixel[0][2] pixel[0][3] pixel[1][0] pixel[1][1] ... pixel[1][3].\r\n    T1: pixel[2][0] ... pixel[3][3]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 4 \u003c/strong\u003e- Multiple pixels per thread, sequential access with a stride equal to the number of threads. Assuming you have 3 threads, then:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0], pixel[0][3], pixel[1][2], pixel[2][1], pixel[3][0], pixel[3][3]\r\n    T1: pixel[0][1], pixel[1][0], pixel[1][3], pixel[2][2], pixel[3][1]\r\n    T2: pixel[0][2], pixel[1][1], pixel[2][0], pixel[2][3], pixel[3][2]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe way you choose how many threads and blocks to run might be different from kernel to kernel.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 5:\u003c/strong\u003e \u003cspan style=\"font-weight: 400;\"\u003eYour fifth implementation should be consistently faster than all of the 4 above by at least 20%. That is, for example, if the best implementation among {1,2,3,4} takes 1s to run, your fifth implementation should take no more than 0.8s on most runs. To do that, you can either find a better partitioning scheme or take one of the partitioning schemes above and add another optimization on top of it. Feel free to try a combination of both, or something entirely different, but explain your rationale.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should first implement a version of this problem without normalization. Once you have that thoroughly tested, you should implement the normalization step. The reasoning for this is that a technique called reduction might be necessary for that step, which might only be covered on lectures that proceed the assignment release date.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eRecall that CUDA can only synchronize threads in the same block; to achieve synchronization across blocks, your kernel must be split into two. Thus, computing the max/min value of the image probably can't be done with a single kernel, and it is your job to find a way to do it. For instance, you could have all blocks write two values (one for max and one for min) into global arrays and then perform a reduction on the global array to compute the global max/min. Notice that this will also involve some reduction within each block, as discussed in the lectures. Alternatively, you could perform the reduction in CPU, which involves copying the global array from device memory to host memory. In this case, you should include both the CPU time to compute min/max and the memory transfer time in the appropriate variables. How the max/min values are computed is up to you, but the normalization should follow the same memory access patterns outlined above (1-4).\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eThe PGM format\u003c/h2\u003e\r\n\u003cp\u003eYou may read more about the PGM specification \u003ca href=\"http://netpbm.sourceforge.net/doc/pgm.html\"\u003ehere\u003c/a\u003e. You may use an image processing program of your choice to create such PGM images for testing. We're also providing you with code that is capable of reading pgm images from files, saving pgm images to files and generating pgm images.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eWe are providing two images in the \u003c/strong\u003e\u003cstrong\u003e\u003ci\u003eimages\u003c/i\u003e\u003c/strong\u003e\u003cstrong\u003e folder in the starter code. Your report should only include results for those two images.  \u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003eMeasuring the performance of your code\u003c/h2\u003e\r\n\u003cp\u003eYou must measure the performance of your kernel and transfer times. Your measurements should include separate timings for the transfer times to/from the GPU, and calculate the speedup of pure GPU computation against the CPU version: \u003ccode\u003eCPU_time/GPU_time\u003c/code\u003e, and the speedup of total time taken to compute on the GPU (including transfers in and out!) against the CPU implementation: \u003ccode\u003eCPU_time / (GPU_time + TransferIn + TransferOut)\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eYour output should be in the following format:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tCPU_time(ms) Kernel  GPU_time(ms) TransferIn(ms) TransferOut(ms) Speedup_noTrf Speedup\r\n\t       2.00       1        0.50           0.25            0.25         4.0      2.0\r\n\t... \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe timings and speedups above are solely for illustration purposes of the output formatting.\u003c/p\u003e\r\n\u003cp\u003eThe provided starter code already satisfies this requirement.\u003c/p\u003e\r\n\u003cp\u003eYour program must not print anything other than what the starter code prints.\u003c/p\u003e\r\n\u003cp\u003eRunning \u003ccode\u003emake\u003c/code\u003e on your directory should produce your solution as an executable called \"solution.out\".\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003eIMPORTANT\u003c/strong\u003e: Your tables and report should be only for the two provided images in the \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eimages\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e folder in the stater code. You should tabulate your data to be more readable and clear.  \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eProgram input\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour program should receive two strings as arguments: \"-i input_image_filename -o output_image_filename\". Other than printing the timings above, your program should also output 1 file per kernel, using the following naming convention: \"kernel_number\"+\"output_image_filename\". So if your program is invoked with \"./solution.out -i input.pgm -o output.pgm\", the following files should be output: \"1output.pgm\", \"2output.pgm\", \"3output.pgm\", \"4output.pgm\" and \"5output.pgm\". Your program should also output the file generated by the cpu implementation, with the name passed as the \"output_image_filename\" argument. Each of your kernels should be in a separate .cu file. We have provided a suggested header and .cu files in the starter code. You do not have to use them, but each kernel should be in its own appropriately named file. When compiling kernels separately, you might need to use the \"--device-c\" flag. We have provided an illustrative Makefile.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eGPU Environment\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can run command ‘nvidia-smi’ to check whether the machine has an Nvidia GPU card.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ein the lab workstations you need to set up the CUDA environment by modifying the PATH and LD_LIBRARY_PATH in .bashrc in your home directory. You can use nano: “nano .bashrc” to open the file and add these lines to it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport PATH=/usr/local/cuda-8.0/bin/:$PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/:$LD_LIBRARY_PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThen run the command: source ~/.bashrc to reload the enviroment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eUse nvcc -V to check whether you have setup the CUDA environment.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eTesting\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the workstations in the labs. Do avoid peak load times (keep an eye on the machine utilization and check if others are logged in and running computations).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should consider running your code in isolation, to avoid any interference from other users. Unlike the Scinet sever, the lab machines are not guaranteed to be quite because others might be using the machine at the same time. Also, when you open a browser or any other file on the machine, the timing results might no longer be correct. Before testing your code on a workstation, please make sure that others are not logged in remotely and potentially running intensive tasks (you can check this using command line tools like ps, who, etc.). Also close all of your browsers and extra files before measuring timings. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must check the specs of the lab machines where you test your code (use the lscpu command and look into /proc/cpuinfo for more information). The lab machines have 4 cores. So modify your optimized CPU code from HW2 to work for \u003cstrong\u003e4 cores. \u003c/strong\u003e\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor each experiment, you must take the average of 5 runs and report this average in the report.  \u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003eYou will submit the code files which contain your implementation, along with the files required to build your program. \u003cbr\u003e\u003cspan style=\"color: red; font-family: bold;\"\u003eDo not submit executables, object files, or image files!\u003cbr\u003eDo not submit any other subdirectories in your A4 repository, as these may prevent the autotester from running correctly and you will lose marks.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit the report documenting your implementation, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003epresenting the results, and discussing your findings. Your report should include a discussion on how you chose the number of threads and blocks on each implementation, an explanation of how you computed the min/max values and a description of your most optimized kernel. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eAdditionally, you must submit an \u003ccode\u003eINFO.txt\u003c/code\u003e file, which contains as the first 2 lines the following:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eyour name(s)\u003c/li\u003e\r\n\u003cli\u003eyour UtorID(s)\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIf you want us to grade an earlier revision of your assignment for whatever reason (for example, for saving some grace tokens if you had a stable submission before the deadline, tried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want to be marked. \u003cbr\u003eAs a general rule, by default we will always take the last revision before the deadline (or last one after the deadline, up to your remaining unused grace tokens), so you should \u003cstrong\u003enot\u003c/strong\u003e be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens if you submit late) is the one you want to be graded.\u003c/p\u003e\r\n\u003cp\u003eFinally, whether you work individually or in pairs with a partner, you \u003cstrong\u003emust\u003c/strong\u003e submit a \u003ccode\u003eplagiarism.txt\u003c/code\u003e file, with the following statement:\u003cbr\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/p\u003e\r\n\u003cp\u003eA missing INFO.txt file will result in a 10% deduction (on top of an inherent penalty if we do not end up grading the revision you expect). \u003cstrong\u003eAny missing code files or Makefile will result in a 0 on this assignment\u003c/strong\u003e! Please reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/p\u003e\r\n\u003cp\u003eAgain, make sure your code compiles without any errors or warnings.\u003cbr\u003e\u003cstrong\u003eCode that does not compile will receive zero marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003eMarking scheme\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be marking based on correctness, coding style, fulfilling the speedup requirements and use of features from the GPU architecture in kernel 5 (don't try to use artificial tricks to make your kernel 5 look better). As with A2, \u003c/span\u003e\u003cstrong\u003ewe will be checking your code for many corner cases, \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eand your code is expected to work with different images. Remember that your handout has to only report numbers for the two provided images, however, your code should work for others. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eMake sure to write legible code, properly indented, and to include comments where appropriate (excessive comments are just as bad as not providing enough comments). Code structure and clarity will be marked strictly!\u003cbr\u003e\u003cstrong\u003eOnce again: code that does not compile will receive 0 marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eMore details on the marking scheme:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e10% for the correctness of each kernel (50% total)\u003c/li\u003e\r\n\u003cli\u003e10% for achieving the desired speedup with kernel 5\u003c/li\u003e\r\n\u003cli\u003e10% for ideas used in implementing kernel 5\u003c/li\u003e\r\n\u003cli\u003e20% for the report\u003c/li\u003e\r\n\u003cli\u003e5% for the correctness of the CPU implementation\u003c/li\u003e\r\n\u003cli\u003eCode style and organization: 5% - code design/organization (modularity, code readability, reasonable variable names, avoid code duplication, appropriate comments where necessary, proper indentation and spacing, etc.)\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003e\u003cspan style=\"color: red;\"\u003eNegative deductions (please be careful about these!):\u003c/span\u003e\u003c/strong\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eCode does not compile: -100%\u003c/strong\u003e for *any* mistake, for example: missing source file necessary for building your code (including Makefile, header files, etc.), typos, any compilation error, etc\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eNo \u003ccode\u003eplagiarism.txt\u003c/code\u003e file: -100%\u003c/strong\u003e (we will assume that your code is plagiarised and that you wish to withdraw your submission, if this file is missing)\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eMissing or incorrect \u003ccode\u003eINFO.txt\u003c/code\u003e: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eWarnings: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eExtra output: -20%\u003c/strong\u003e (for any output other than what is required in the handout)\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eCode placed in other subdirectories than indicated: -20%\u003c/strong\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e","exportId":"i28f240cae8d37985cbc42a52faea218c"},{"id":628880,"title":"Lab 07","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-19T18:00:00-04:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 7 - Working with CUDA threads and blocks\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eDue: Wedensday, March 20, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get a bit of practice with some GPU programming basics, by helping you understand how to launch a kernel that performs simple operations and to analyze the performance. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSee the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation for more information. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work in pairs for this exercise, with your A4 partner, since some code will potentially be common with the assignment. MarkUs will only create the appropriate directory in your repository when you log into MarkUs and either create your group, or declare that you will work alone. The groups will get a new shared repository, and the students working solo may also get a new repository. Please log into MarkUs well before the deadline to take these steps. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on wolf under\u003c/span\u003e\u003cstrong\u003e /u/csc367h/winter/pub/labs/lab7/starter_code.tgz \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eRequirements\u003c/h2\u003e\r\n\u003cp\u003eYour task for this exercise is simple. You will write a CUDA kernel, named \"array_add\", which adds two one-dimensional arrays A and B of the same length, by adding their pairwise elements from same indices, and storing the result back into the corresponding elements of \u003ccode\u003eA\u003c/code\u003e (i.e., \u003ccode\u003eA[i] = A[i] + B[i]\u003c/code\u003e). The elements of \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eB\u003c/code\u003e should be initialized to randomized single precision floating-point values under 100.00.\u003c/p\u003e\r\n\u003cp\u003eYour program must increase the input size (the lengths of A and B) from 1M elements to at least 32M. Your must increase the input size in powers of two (1M, 2M, 4M, etc.)\u003c/p\u003e\r\n\u003ch4\u003eStep 1\u003c/h4\u003e\r\n\u003cp\u003eImplement a kernel called \u003ccode\u003earray_add_simple\u003c/code\u003e, which adds the elements of array \u003ccode\u003eB\u003c/code\u003e into those of array \u003ccode\u003eA\u003c/code\u003e. Your program must output, for each array size, the time it takes to copy the arrays from the CPU to the GPU, the time taken by the kernel to perform the computations on the GPU, and the time it takes to copy the resulting array back from the GPU to the CPU. Check the NVIDIA documentation for a description of CUDA events. In a nutshell, your timing measurements should be using the following pattern:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    cudaEvent_t start, stop;\r\n    float time;\r\n    cudaEventCreate(\u0026amp;start);\r\n    cudaEventCreate(\u0026amp;stop);\r\n    cudaEventRecord(start);\r\n    \u0026lt;code to be timed here\u0026gt;\r\n    cudaEventRecord(stop);\r\n    cudaEventSynchronize(stop);\r\n    cudaEventElapsedTime(\u0026amp;time, start, stop);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe call \u003ccode\u003ecudaEventElapsedTime(\u0026amp;time, start, stop)\u003c/code\u003e stores the elapsed time (in milliseconds) into a single-precision floating-point variable \u003ccode\u003etime\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eFor this initial step, you may only use 1 block and 1 thread. Your code will be very simple - all that the kernel needs to do is iterate through all the elements in the array to add the elements of a and b.\u003c/p\u003e\r\n\u003cp\u003eYour program output should include the size of the arrays, followed by the three time measurements, all separated by spaces. All of these will be preceded by a column called Times, which will be 1 for all measurements. This \u003ccode\u003etimes\u003c/code\u003e value will make more sense in part 4 of this lab. Each measurement result (for a different array size) should be on a separate line:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tTimes Size(M) TransferIn(ms) Computation(ms) TransferOut(ms) \r\n\t    1      1           1.23            2.34            3.45\r\n\t    1      2           1.23            2.34            3.45\r\n\t  ...\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe timings above are just for illustration purposes, to clarify how your output format should look like. To match our output format, please use the printf format specifiers: %5d for the Times and Size columns, and %15.2f for all the others.\u003c/p\u003e\r\n\u003ch4\u003eStep 2\u003c/h4\u003e\r\n\u003cp\u003eImplement a kernel called \u003ccode\u003earray_add_threads_only\u003c/code\u003e, which is invoked using 1 block and 512 threads. You must adjust your kernel to ensure that each thread calculates an equal number of elements. You must try first to give each thread a chunk of Len/512 *consecutive* elements to process, where Len is the number of elements in an array. Next, you must implement a new version of this function, which uses instead strided accesses, in order to allow for memory coalescing. You must compare the results and draw conclusions.\u003c/p\u003e\r\n\u003cp\u003eThe format of the timing measurements should be identical to the one from step 1. Please take the time to look over these measurements and draw conclusions for yourselves. What do you notice? What do the computation times look like and what is the speedup? To get the most out of this lab, you should discuss your findings with your TA.\u003c/p\u003e\r\n\u003ch4\u003eStep 3\u003c/h4\u003e\r\n\u003cp\u003eImplement a kernel called \u003ccode\u003earray_add_threads_blocks\u003c/code\u003e, which is invoked using a number of \u003ccode\u003enum_blocks\u003c/code\u003e blocks and 512 threads. You must calculate \u003ccode\u003enum_blocks\u003c/code\u003e, such that each array element is processed by a single thread. You must adjust your kernel accordingly as well.\u003c/p\u003e\r\n\u003cp\u003eThe format of the timing measurements should be identical to the one from step 1. Please take the time to look over these measurements and draw conclusions for yourselves. What do you notice? What do the computation times look like and what is the speedup? Once again, to get the most out of this lab, you are encouraged to discuss your findings with your TA.\u003c/p\u003e\r\n\u003ch4\u003eStep 4\u003c/h4\u003e\r\n\u003cp\u003eThe next step is to create a new kernel \u003ccode\u003earray_add_times\u003c/code\u003e, which does the same thing as \u003ccode\u003earray_add_threads_blocks\u003c/code\u003e, except it takes an extra arguments \u003ccode\u003etimes\u003c/code\u003e, which indicates how many times the elements in \u003ccode\u003eB\u003c/code\u003e should be added to the counterpart elements from \u003ccode\u003eA\u003c/code\u003e. Basically, each resulting (updated) element \u003ccode\u003eAi\u003c/code\u003e will be computed as:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003eAi = Ai + times * Bi \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eHowever, \u003cstrong\u003eyou must not use multiplication\u003c/strong\u003e in calculating the elements of the result. You must instead create a loop which adds each \u003ccode\u003eB\u003c/code\u003e element \u003ccode\u003e'times'\u003c/code\u003e times.\u003c/p\u003e\r\n\u003cp\u003eFor the array sizes, use only one data point: 32M. Similarly to the previous steps of this lab, your program must output the three time measurements, as described above, but this time as a function of the number of times that the elements in B are added. You must increase \"times\" between 1 and 512 in powers of two steps. Your program output should follow this format:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tTimes Size(M) TransferIn(ms) Computation(ms) TransferOut(ms)\t\r\n\t    1     32           1.23            2.34            3.45\r\n\t    2     32           1.23            2.34            3.45\r\n\t  ...\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eOnce again, the timings above (as well as the Size value) are just for illustration purposes, to clarify how your output format should look like. Once again, to match our output format, please use the printf format specifiers: %5d for the Times and Size columns, and %15.2f for all the others.\u003c/p\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints both measurements (i.e., time as a function of element count and time as a function of the number of additions). All your code (including the main program that you used to produce the results), should be included in a single CUDA C file, named \u003ccode\u003elab7.cu\u003c/code\u003e. Make sure your code compiles and runs on the teaching lab machines.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eGPU Environment \u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can run command ‘nvidia-smi’ to check whether the machine has an Nvidia GPU card.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ein the lab workstations, you need to set up the CUDA environment by modifying the PATH and LD_LIBRARY_PATH in .bashrc in your home directory. You can use nano: “nano .bashrc” to open the file and add these lines to it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport PATH=/usr/local/cuda-8.0/bin/:$PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/:$LD_LIBRARY_PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThen run the command: source ~/.bashrc to reload the environment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eUse nvcc -V to check whether you have setup the CUDA environment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eRunning the code on GPU\u003c/span\u003e\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the workstations in the labs. Do avoid peak load times (keep an eye on the machine utilization and check if others are logged in and running computations).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should consider running your code in isolation, to avoid any interference from other users. Unlike the Scinet sever, the lab machines are not guaranteed to be quite because others might be using the machine at the same time. Also, when you open a browser or any other file on the machine, the timing results might no longer be correct. Before testing your code on a workstation, please make sure that others are not logged in remotely and potentially running intensive tasks (you can check this using command line tools like ps, who, etc.). Also, close all of your browsers and extra files before measuring timings.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"iff2c6495c8cb01ee7a1edcc9940ec309"},{"id":629330,"title":"Lec19.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec19.pdf"},{"id":635968,"title":"Lec20\u002621.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec20.pdf"}]},{"id":131051,"name":"Week 12","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"i52739b2646d28a6ee0832186c2567d53","items":[{"id":635969,"title":"Lab 08","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-25T18:00:00-04:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 8 - GPU memory, reductions\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eDue: Wednesday, March 27, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003eBefore you start\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eBefore you start this lab, you need to read all the slides in Lecture 20, as well as read and understand the code posted in \u003cstrong\u003e/u/csc367h/winter/pub/labs/examples/GPUExamples.tgz\u003c/strong\u003e and read relevant parts of the following link to learn how kernels 8-10 are implemented in the example provided:  \u003c/span\u003e\u003ca href=\"https://devblogs.nvidia.com/faster-parallel-reductions-kepler/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://devblogs.nvidia.com/faster-parallel-reductions-kepler/\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with more advanced GPU programming, like thread cooperation within thread blocks, and using shared memory. In order to efficiently solve a problem and fully leverage the potential of GPUs, you have to think about such aspects and tailor your solution to the GPU model. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSee the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation for more information. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work in pairs for this exercise, with your A4 partner, since some code design may potentially be common with the assignment. MarkUs will only create the appropriate directory in your repository when you log into MarkUs and either create your group, or declare that you will work alone. The groups will get a new shared repository, and the students working solo may also get a new repository. Please log into MarkUs well before the deadline to take these steps. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on wolf under \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003e/u/csc367h/winter/pub/labs/lab8/starter_code.tgz\u003c/strong\u003e \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eRequirements\u003c/h2\u003e\r\n\u003cp\u003eYour task for this exercise is to work on implementing a reduction algorithm, similar to the one discussed in class, and analyze the performance of various optimization steps. Your end goal is to write an efficient CUDA code that calculates the dot product of two arrays.\u003c/p\u003e\r\n\u003cp\u003eYour task is to implement a kernel called \"dot_product\", which multiplies two one-dimensional arrays A and B of the same length, by multiplying their pairwise elements from same indices, then adds all the resulted elements into the final dot product. The elements of A and B have been initialized to random single precision floating-point values in the set {-1, 0, 1}. You will have a chance to toy with this choice afterward, and you'll understand why we chose those values to begin with.\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe recommend that you start with one block only, and keep the size of the array below the blocksize. You may start with the naive dot product approach where each thread calculates the sum of two consecutive elements, as discussed in class. Then consider using multiple blocks and increasing the size of the arrays. You must take steps to optimize your code for the GPU. You will think about how threads access elements, how to use shared memory efficiently, etc. You will optimize your code using the ideas discussed in class, and you will consider comparing the performance between various approaches. We gave you the main execution harness to test the kernels, for convenience. You must implement gradually optimized kernels into dot_kernel1.cu through dot_kernel7.cu. Please review the code samples from class (uploaded in /u/csc367h/winter/pub/labs/examples/GPUExamples.tgz), including sum and max reductions, in order to replicate the same levels of optimizations and code restructuring. You should number the kernel versions the same way as in the code samples, with respect to the optimizations being made in each kernel.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce you have compared your implementations with gradual optimizations, you will implement a reduction using the __shfl_down (shuffle down) instruction. You should implement the versions with and without atomics, similar to the ones discussed in the code sample given and in the link \u003c/span\u003e\u003ca href=\"https://devblogs.nvidia.com/faster-parallel-reductions-kepler/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://devblogs.nvidia.com/faster-parallel-reductions-kepler/\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e, then compare the performance of each version. Please place these implementations in the dot_kernel8-10.cu file (again, consult the provided code samples from lectures, to number the kernel version you're implementing in the same way). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eYou must implement an equivalent dot product function on the CPU. You must time how long it takes to run the code on a single CPU, and on the GPU with various optimizations. As input sizes, use 2M, 8M, and 32M. Each execution time (on the CPU and on the GPU, for each input size) should be averaged over 100 runs. \u003cstrong\u003eDo not run your program 100 times\u003c/strong\u003e, your code should internally run each measurement 100 times and take the average. \u003cbr\u003eYou might want to run your code with and without -O3, to see if you notice any difference for the CPU implementation.\u003c/p\u003e\r\n\u003cp\u003eYour measurements should include separate timings for the transfer times to/from the GPU, and calculate the speedup of pure GPU computation against the CPU: \u003ccode\u003eCPU_time/GPU_time\u003c/code\u003e, and the speedup of total time taken to compute on the GPU (including transfers in and out!) against the CPU implementation: \u003ccode\u003eCPU_time / (GPU_time + TransferIn + TransferOut)\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eFor each reduction implementation, your evaluation output should be in the following format:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tSize(M) GPU_dotp CPU_dotp CPU_time(ms) GPU_time(ms) TransferIn(ms) TransferOut(ms) Speedup_noTrf Speedup\r\n\t     1     12345    12345        2.00         0.50           0.25            0.25         4.0      2.0\r\n\t     2     98765    98765        4.00         0.50           0.50            0.50         8.0      2.7\r\n\t     4    345987   345987        8.00         0.50           1.00            1.00        16.0      3.2\r\n\t...\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe value of the dot product calculated on the CPU and GPU should match, otherwise, your code is incorrect. You must fix such bugs otherwise the timings are likely meaningless. The timings, dotproduct values, and speedups above are solely for illustration purposes of the output formatting.\u003c/p\u003e\r\n\u003cp\u003eOnce you have your code correctly working, change the line where the arrays are initialized to contain a random number between 0 and 1. You can achieve that by assigning each array value to \u003ccode\u003e((float)(rand()%100))/100.0\u003c/code\u003e. What happens to the result? Why? Do not submit the code with this change.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eGPU Environment \u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can run command ‘nvidia-smi’ to check whether the machine has an Nvidia GPU card.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ein the lab workstations, you need to set up the CUDA environment by modifying the PATH and LD_LIBRARY_PATH in .bashrc in your home directory. You can use nano: “nano .bashrc” to open the file and add these lines to it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport PATH=/usr/local/cuda-8.0/bin/:$PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/:$LD_LIBRARY_PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThen run the command: source ~/.bashrc to reload the environment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eUse nvcc -V to check whether you have setup the CUDA environment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eRunning the code on GPU\u003c/span\u003e\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the workstations in the labs. Do avoid peak load times (keep an eye on the machine utilization and check if others are logged in and running computations).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should consider running your code in isolation, to avoid any interference from other users. Unlike the Scinet sever, the lab machines are not guaranteed to be quite because others might be using the machine at the same time. Also, when you open a browser or any other file on the machine, the timing results might no longer be correct. Before testing your code on a workstation, please make sure that others are not logged in remotely and potentially running intensive tasks (you can check this using command line tools like ps, who, etc.). Also, close all of your browsers and extra files before measuring timings.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints both measurements (i.e., time as a function of element count and time as a function of the number of additions). Make sure your code compiles and runs on the teaching lab machines.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","exportId":"ie04c79aeb9473063d12142cd323aac4c"},{"id":642977,"title":"Lec22.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/Lec21.pdf"},{"id":652163,"title":"LastLecture.pdf","type":"Attachment","indent":0,"locked":false,"requirement":null,"completed":false,"content":"viewer/files/LastLecture.pdf"}]}],"pages":[],"assignments":[{"exportId":"i28f240cae8d37985cbc42a52faea218c","title":"Assignment Four","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAssignment 4 - GPUs and CUDA\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Friday, April 5, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eOverview\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, you will work with CUDA to design efficient code that leverages the parallel processing power of GPUs to do some image processing. In order to efficiently solve a problem and fully leverage the potential of GPUs, you have to consider everything we discussed in lectures and labs, to design a solution in the GPU model. See the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation guide for more information. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work with a partner on this assignment. We recommend that you work with your A2 partner. Please log into MarkUs as soon as possible to find your repository and invite your partner (should you choose to have one), and make sure that you can commit and push to your repo. For all assignments and labs you will be given your repo URL on MarkUs. Make sure to use this repository (which should already be created for you), otherwise, MarkUs won't know about it and we won't be able to see your work.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available on wolf (the department’s teach/CDF machines) under\u003cstrong\u003e /u/csc367h/winter/pub/assignments/a4/starter_code.tgz\u003c/strong\u003e so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eKeep in mind that most courses have assignments due in the last week of classes, so make sure to start early on this assignment!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003eYour task\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this assignment, you will implement a discrete Laplacian filter kernel on the GPU, using CUDA. You may choose any of the filters described in A2, but the filter dimension should be at least 3x3 (suggestion: try different filter sizes, what do you observe?). Your code must efficiently process the image in parallel, and take advantage of the GPU's massive parallelism and memory bandwidth. Additionally, if you have not already in a previous assignment, you must implement a CPU version which also processes the image in parallel, using POSIX threads. You should use the fastest CPU implementation for a fair comparison. Make sure you tweak your A2 implementation if needed. Remember that CDF machines have 4 cores.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour code will be assessed based on efficiency/performance, so you must make sure to take advantage of all the things we discussed in class. You are welcome to perform additional optimizations, as long as they are supported by the capabilities of the cards from the GPU cluster. \u003c/span\u003e For the following examples, assume we have a 4x4 pixel matrix and threads T0, T1, ... Your code should contain at least 5 GPU implementations:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 1\u003c/strong\u003e - One pixel per thread, column major. In this case, the work is distributed as follows:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0]\r\n    T1: pixel[1][0]\r\n    T2: pixel[2][0]\r\n    T3: pixel[3][0]\r\n    T4: pixel[0][1]\r\n    T5: pixel[1][1], etc.\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 2 \u003c/strong\u003e- One pixel per thread, row major. In this case, the work is distributed as follows:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0]\r\n    T1: pixel[0][1]\r\n    T2: pixel[0][2]\r\n    T3: pixel[0][3]\r\n    T4: pixel[1][0]\r\n    T5: pixel[1][1], etc.\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 3 \u003c/strong\u003e- Multiple pixels per thread, consecutive rows, row major. Assuming you have, for example, 2 threads:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0] pixel[0][1] pixel[0][2] pixel[0][3] pixel[1][0] pixel[1][1] ... pixel[1][3].\r\n    T1: pixel[2][0] ... pixel[3][3]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 4 \u003c/strong\u003e- Multiple pixels per thread, sequential access with a stride equal to the number of threads. Assuming you have 3 threads, then:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    T0: pixel[0][0], pixel[0][3], pixel[1][2], pixel[2][1], pixel[3][0], pixel[3][3]\r\n    T1: pixel[0][1], pixel[1][0], pixel[1][3], pixel[2][2], pixel[3][1]\r\n    T2: pixel[0][2], pixel[1][1], pixel[2][0], pixel[2][3], pixel[3][2]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe way you choose how many threads and blocks to run might be different from kernel to kernel.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eKernel 5:\u003c/strong\u003e \u003cspan style=\"font-weight: 400;\"\u003eYour fifth implementation should be consistently faster than all of the 4 above by at least 20%. That is, for example, if the best implementation among {1,2,3,4} takes 1s to run, your fifth implementation should take no more than 0.8s on most runs. To do that, you can either find a better partitioning scheme or take one of the partitioning schemes above and add another optimization on top of it. Feel free to try a combination of both, or something entirely different, but explain your rationale.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should first implement a version of this problem without normalization. Once you have that thoroughly tested, you should implement the normalization step. The reasoning for this is that a technique called reduction might be necessary for that step, which might only be covered on lectures that proceed the assignment release date.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eRecall that CUDA can only synchronize threads in the same block; to achieve synchronization across blocks, your kernel must be split into two. Thus, computing the max/min value of the image probably can't be done with a single kernel, and it is your job to find a way to do it. For instance, you could have all blocks write two values (one for max and one for min) into global arrays and then perform a reduction on the global array to compute the global max/min. Notice that this will also involve some reduction within each block, as discussed in the lectures. Alternatively, you could perform the reduction in CPU, which involves copying the global array from device memory to host memory. In this case, you should include both the CPU time to compute min/max and the memory transfer time in the appropriate variables. How the max/min values are computed is up to you, but the normalization should follow the same memory access patterns outlined above (1-4).\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eThe PGM format\u003c/h2\u003e\r\n\u003cp\u003eYou may read more about the PGM specification \u003ca href=\"http://netpbm.sourceforge.net/doc/pgm.html\"\u003ehere\u003c/a\u003e. You may use an image processing program of your choice to create such PGM images for testing. We're also providing you with code that is capable of reading pgm images from files, saving pgm images to files and generating pgm images.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eWe are providing two images in the \u003c/strong\u003e\u003cstrong\u003e\u003ci\u003eimages\u003c/i\u003e\u003c/strong\u003e\u003cstrong\u003e folder in the starter code. Your report should only include results for those two images.  \u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003eMeasuring the performance of your code\u003c/h2\u003e\r\n\u003cp\u003eYou must measure the performance of your kernel and transfer times. Your measurements should include separate timings for the transfer times to/from the GPU, and calculate the speedup of pure GPU computation against the CPU version: \u003ccode\u003eCPU_time/GPU_time\u003c/code\u003e, and the speedup of total time taken to compute on the GPU (including transfers in and out!) against the CPU implementation: \u003ccode\u003eCPU_time / (GPU_time + TransferIn + TransferOut)\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eYour output should be in the following format:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tCPU_time(ms) Kernel  GPU_time(ms) TransferIn(ms) TransferOut(ms) Speedup_noTrf Speedup\r\n\t       2.00       1        0.50           0.25            0.25         4.0      2.0\r\n\t... \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe timings and speedups above are solely for illustration purposes of the output formatting.\u003c/p\u003e\r\n\u003cp\u003eThe provided starter code already satisfies this requirement.\u003c/p\u003e\r\n\u003cp\u003eYour program must not print anything other than what the starter code prints.\u003c/p\u003e\r\n\u003cp\u003eRunning \u003ccode\u003emake\u003c/code\u003e on your directory should produce your solution as an executable called \"solution.out\".\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003eIMPORTANT\u003c/strong\u003e: Your tables and report should be only for the two provided images in the \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eimages\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e folder in the stater code. You should tabulate your data to be more readable and clear.  \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eProgram input\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour program should receive two strings as arguments: \"-i input_image_filename -o output_image_filename\". Other than printing the timings above, your program should also output 1 file per kernel, using the following naming convention: \"kernel_number\"+\"output_image_filename\". So if your program is invoked with \"./solution.out -i input.pgm -o output.pgm\", the following files should be output: \"1output.pgm\", \"2output.pgm\", \"3output.pgm\", \"4output.pgm\" and \"5output.pgm\". Your program should also output the file generated by the cpu implementation, with the name passed as the \"output_image_filename\" argument. Each of your kernels should be in a separate .cu file. We have provided a suggested header and .cu files in the starter code. You do not have to use them, but each kernel should be in its own appropriately named file. When compiling kernels separately, you might need to use the \"--device-c\" flag. We have provided an illustrative Makefile.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eGPU Environment\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can run command ‘nvidia-smi’ to check whether the machine has an Nvidia GPU card.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ein the lab workstations you need to set up the CUDA environment by modifying the PATH and LD_LIBRARY_PATH in .bashrc in your home directory. You can use nano: “nano .bashrc” to open the file and add these lines to it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport PATH=/usr/local/cuda-8.0/bin/:$PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/:$LD_LIBRARY_PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThen run the command: source ~/.bashrc to reload the enviroment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eUse nvcc -V to check whether you have setup the CUDA environment.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eTesting\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the workstations in the labs. Do avoid peak load times (keep an eye on the machine utilization and check if others are logged in and running computations).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should consider running your code in isolation, to avoid any interference from other users. Unlike the Scinet sever, the lab machines are not guaranteed to be quite because others might be using the machine at the same time. Also, when you open a browser or any other file on the machine, the timing results might no longer be correct. Before testing your code on a workstation, please make sure that others are not logged in remotely and potentially running intensive tasks (you can check this using command line tools like ps, who, etc.). Also close all of your browsers and extra files before measuring timings. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must check the specs of the lab machines where you test your code (use the lscpu command and look into /proc/cpuinfo for more information). The lab machines have 4 cores. So modify your optimized CPU code from HW2 to work for \u003cstrong\u003e4 cores. \u003c/strong\u003e\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor each experiment, you must take the average of 5 runs and report this average in the report.  \u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003eYou will submit the code files which contain your implementation, along with the files required to build your program. \u003cbr\u003e\u003cspan style=\"color: red; font-family: bold;\"\u003eDo not submit executables, object files, or image files!\u003cbr\u003eDo not submit any other subdirectories in your A4 repository, as these may prevent the autotester from running correctly and you will lose marks.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit the report documenting your implementation, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003epresenting the results, and discussing your findings. Your report should include a discussion on how you chose the number of threads and blocks on each implementation, an explanation of how you computed the min/max values and a description of your most optimized kernel. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eAdditionally, you must submit an \u003ccode\u003eINFO.txt\u003c/code\u003e file, which contains as the first 2 lines the following:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eyour name(s)\u003c/li\u003e\r\n\u003cli\u003eyour UtorID(s)\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIf you want us to grade an earlier revision of your assignment for whatever reason (for example, for saving some grace tokens if you had a stable submission before the deadline, tried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want to be marked. \u003cbr\u003eAs a general rule, by default we will always take the last revision before the deadline (or last one after the deadline, up to your remaining unused grace tokens), so you should \u003cstrong\u003enot\u003c/strong\u003e be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens if you submit late) is the one you want to be graded.\u003c/p\u003e\r\n\u003cp\u003eFinally, whether you work individually or in pairs with a partner, you \u003cstrong\u003emust\u003c/strong\u003e submit a \u003ccode\u003eplagiarism.txt\u003c/code\u003e file, with the following statement:\u003cbr\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/p\u003e\r\n\u003cp\u003eA missing INFO.txt file will result in a 10% deduction (on top of an inherent penalty if we do not end up grading the revision you expect). \u003cstrong\u003eAny missing code files or Makefile will result in a 0 on this assignment\u003c/strong\u003e! Please reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/p\u003e\r\n\u003cp\u003eAgain, make sure your code compiles without any errors or warnings.\u003cbr\u003e\u003cstrong\u003eCode that does not compile will receive zero marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003eMarking scheme\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be marking based on correctness, coding style, fulfilling the speedup requirements and use of features from the GPU architecture in kernel 5 (don't try to use artificial tricks to make your kernel 5 look better). As with A2, \u003c/span\u003e\u003cstrong\u003ewe will be checking your code for many corner cases, \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eand your code is expected to work with different images. Remember that your handout has to only report numbers for the two provided images, however, your code should work for others. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eMake sure to write legible code, properly indented, and to include comments where appropriate (excessive comments are just as bad as not providing enough comments). Code structure and clarity will be marked strictly!\u003cbr\u003e\u003cstrong\u003eOnce again: code that does not compile will receive 0 marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eMore details on the marking scheme:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e10% for the correctness of each kernel (50% total)\u003c/li\u003e\r\n\u003cli\u003e10% for achieving the desired speedup with kernel 5\u003c/li\u003e\r\n\u003cli\u003e10% for ideas used in implementing kernel 5\u003c/li\u003e\r\n\u003cli\u003e20% for the report\u003c/li\u003e\r\n\u003cli\u003e5% for the correctness of the CPU implementation\u003c/li\u003e\r\n\u003cli\u003eCode style and organization: 5% - code design/organization (modularity, code readability, reasonable variable names, avoid code duplication, appropriate comments where necessary, proper indentation and spacing, etc.)\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003e\u003cspan style=\"color: red;\"\u003eNegative deductions (please be careful about these!):\u003c/span\u003e\u003c/strong\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eCode does not compile: -100%\u003c/strong\u003e for *any* mistake, for example: missing source file necessary for building your code (including Makefile, header files, etc.), typos, any compilation error, etc\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eNo \u003ccode\u003eplagiarism.txt\u003c/code\u003e file: -100%\u003c/strong\u003e (we will assume that your code is plagiarised and that you wish to withdraw your submission, if this file is missing)\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eMissing or incorrect \u003ccode\u003eINFO.txt\u003c/code\u003e: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eWarnings: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli\u003e\n\u003cstrong\u003eExtra output: -20%\u003c/strong\u003e (for any output other than what is required in the handout)\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eCode placed in other subdirectories than indicated: -20%\u003c/strong\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e","submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-18T18:00:00-04:00"},{"exportId":"i0fd6573bf2128c4f5deadae5daaf811b","title":"Assignment one","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAssignment 1 - System Performance \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Monday January 28, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 10 \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 16th at 10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this assignment!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eIntro to Scinet:\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this assignment. You should have already received an email with your Scinet login. In that email, you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eOverview\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work on groups of two. For this assignment, you will work on learning about the limitations of system memory performance. You will study some of the concepts discussed in lecture in a practical context, by performing performance measurements, profiling, and designing code meant to expose your system's boundaries. Additionally, you will experience first hand the impact of programming efficiently with your system's memory performance in mind.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work with a partner on this assignment. Please log into MarkUs as soon as possible to find your repository and invite your partner, and make sure that you can commit and push to your repo. For all assignments and labs, you will be given your repo URL on MarkUs. Make sure to use this repository (which should already be created for you), otherwise, MarkUs won't know about it and we won't be able to see your work.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available on \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet under \u003cem\u003e\u003cspan\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003c/em\u003e\u003cspan\u003e\u003cem\u003e/assignments/assignment1/\u003c/em\u003e\u003c/span\u003e\u003cem\u003estarter_code.tgz\u003c/em\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 1 - Know the Scinet machine's memory system!\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you will test the memory bandwidth and cache size of the Scinet machine.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003eA) \u003c/strong\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eDesign an experiment to measure the memory bandwidth in the Scinet machines. In particular,\u003c/span\u003e you will measure the write\u003cspan style=\"font-weight: 400;\"\u003e bandwidth, by creating a program that accesses memory in a specific way, designed to test the limits of the memory bus. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cem\u003eHint:\u003c/em\u003e\u003c/span\u003e You will want to write to memory as fast as possible; a naive approach like writing to memory byte by byte using a for-loop might not give you a reasonable estimate of memory bandwidth.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cem\u003eNote:\u003c/em\u003e\u003c/span\u003e This will help you reason about Scinet system's performance limitations and scaling issues. This will be particularly useful later in the course in understanding the benefits and limitations of GPU devices.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003eB)\u003c/strong\u003e Design an experiment to determine the number of levels in the CPU cache hierarchy, and to measure cache sizes and cache (write) latencies for each level, as well as the write latency of main memory. You must create a program that accesses memory in a particular manner, such that it allows you to calculate these parameters. Keep in mind how memory accesses are serviced within the memory hierarchy and design your code to expose this behaviour.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eTo measure the elapsed time of a piece of code, you can use the \u003cem\u003eclock_gettime()\u003c/em\u003e function (with the CLOCK_MONOTONIC clock) to capture the time before and after, then subtract them using the \u003cem\u003edifftimespec()\u003c/em\u003e helper function defined in \u003cem\u003etime_util.h\u003c/em\u003e in the starter code, and convert the difference to time units of your choice using the helper functions in \u003cem\u003etime_util.h\u003c/em\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce your design your experiment, you must represent your results visually (with graphs) and analyze them in a short report (called \u003cem\u003ereport.pdf\u003c/em\u003e). You should describe your approach, analyze the findings and draw conclusions. More on \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethis in a later section.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must automate running the experiments, collecting the data and generating the graphs. You need to write a script \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(e.g. Bash or Python) that invokes your C program (\u003cem\u003epart1.c\u003c/em\u003e) to performs all measurements, and produces all the graphs and other necessary data that you use to draw conclusions that your describe in your report. Invoke the script in the 'run' target of the part 1 makefile (see \u003cem\u003epart1/Makefile\u003c/em\u003e in the starter code). You must also describe your data collection programs and scripts in your report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eNote:\u003c/span\u003e\u003c/em\u003e In your experiments, you can assume that the cache line size is known (usually 64 bytes, check file \u003cem\u003e/proc/cpuinfo\u003c/em\u003e on the machine you're using for experiments). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eBONUS (10%):\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e Design an experiment to measure the cache line size.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eHint:\u003c/span\u003e\u003c/em\u003e measuring memory write bandwidth is all about hitting the memory with heavy requests and measuring the performance of your code, while measuring cache sizes and latencies is all about hitting the memory with accesses that are increasingly unlikely to hit in the cache, until you see significant drops in performance. Particularly for cache measurements, you are encouraged to draw graphs to support your analysis.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eHint:\u003c/span\u003e\u003c/em\u003e when your program accesses a memory region for the first time after it is dynamically allocated using \u003cem\u003emalloc()\u003c/em\u003e, or when it accesses a static global array for the first time, it might incur some overhead (you don't need to worry about what these are, but if you're taking CSC369 or just curious, this involves setting up the virtual to physical address translation - populating the page tables and the TLB). These are called cold accesses. To avoid the negative impact of the initial (cold) access overheads on the accuracy of your measurements, you can \"warm up\" the data by touching (e.g. writing to) the respective memory before starting the measurements.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eNote:\u003c/span\u003e\u003c/em\u003e Since memory and cache latency are typically very small, you want to avoid as much as possible time-consuming operations within the code being timed. For example, avoid division or modulo operations inside the timed code, if possible. You can also use bit shift operations if the denominator is a power of 2, instead of a division, etc. You might have to play a bit with such tweaks if your measurements do not seem right.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 2 - Performance and profiling\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you will implement a piece of simple parallel code, and profile its performance. \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eThe profiling should guide you into how to optimize your code further.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou'll start with a program (part2.c in the part2/ subdirectory in the starter code) that computes the historic average grades for a set of courses. Profile your code (e.g., using the kcachegrind tool of valgrind or gprof), and then parallelize (in part2/part2-parallel.c) the piece(s) of code which take a considerable amount of execution time, and which are also parallelizable.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe provide you with a data generator (datagen.c) that is automatically invoked with default parameters by 'make' when you build the code (see comments in the makefile). This default dataset should be enough, but you can generate more data if you wish (please do not commit any data files!). Refer to the starter code for more details on the data generator. You can run the programs (part2*.c) on generated data by specifying the path to the data (the one that you gave to the generator) as an argument.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eTo profile your code, you have several options:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse gprof. For full documentation, see\u003c/span\u003e\u003ca href=\"https://sourceware.org/binutils/docs/gprof/\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e. \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e The most basic usage involves simply adding the \"-pg\" flag to the compilation and linking of your program, and then running your code. After you run your code, a \"gmon.out\" file will be generated. To inspect the gprof details, simply use: \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003cspan style=\"font-weight: 400;\"\u003e$ gprof ./myprogram gmon.out \u0026gt; gprof_analysis.txt\u003c/span\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can then inspect the \u003cem\u003egprof_analysis.txt\u003c/em\u003e file for details on how much time is spent in each function. \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse valgrind's\u003c/span\u003e\u003ca href=\"http://valgrind.org/docs/manual/cl-manual.html\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ecallgrind\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e tool and kcachegrind for a more visual representation. For example: \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003cspan style=\"font-weight: 400;\"\u003e$ valgrind --tool=callgrind ./myprogram \u003c/span\u003e\u003c/pre\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis will generate a trace file that starts with \"callgrind\". You can view this with a text editor, but this won't be very helpful since the trace can be quite cryptic. You can analyze visually the trace results using a tool like kcachegrind. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse a tool like oprofile. For more documentation, see\u003c/span\u003e\u003ca href=\"http://oprofile.sourceforge.net/docs/\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce you have parallelized your code, you must use the perf tools to capture architectural performance counters that might help you optimize your code. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e\u003cspan style=\"text-decoration: underline;\"\u003eHint:\u003c/span\u003e\u003c/em\u003e look at your cache misses in particular! You must then optimize your code accordingly and measure the improvements. Document your findings and discuss them in the report. You will implement the optimized version in part2/part2-parallel-opt.c.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you have trouble getting stable measurements from perf, you can try building the code as follows: \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEMBED_DATA=1 make (instead of a simple make invocation) This will embed the data in the compiled executable file (instead of loading it from a file explicitly by default; see the source code for details), and might help to make perf readings less \"noisy\". Please do not commit the generated .c files with embedded data (\u003cem\u003epart2_data.c\u003c/em\u003e for example)!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cstrong\u003eNote:\u003c/strong\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e you \u003cstrong\u003e\u003cem\u003emust not\u003c/em\u003e\u003c/strong\u003e add any gcc optimization options in your part2 makefile. This is important for the particular performance effects we want you to explore in this assignment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eBONUS (5%):\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e study the effect of the gcc optimization level (-O0, -O1, -O2, -O3) on the performance issues that you encounter in your initial parallel implementation. Describe your findings in the report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTesting\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFirst read the \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003erun-job-**.sh \u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003efiles in the code folders.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e1- Running Part 1: \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eAfter you have logged in to Scinet and copied the code into your \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003e$SCRATCH\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e folder, you can start working on the assignment. A script called \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003erun-job-part1.sh\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e is provided that builds and runs your code on a Scinet compute node\u003c/span\u003e\u003cstrong\u003e.\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e2- Running Part 2: \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eThree scripts are provided called \u003cem\u003erun-job-serial.sh\u003c/em\u003e, \u003cem\u003erun-job-parallel.sh\u003c/em\u003e and \u003cem\u003erun-job-parallel-opt.sh\u003c/em\u003e that build, generate data, and run in order the \u003cem\u003epart2.c\u003c/em\u003e, \u003cem\u003epart2-parallel.c\u003c/em\u003e, and \u003cem\u003epart2-parallel-opt.c\u003c/em\u003e codes on a compute node. Also, script \u003cem\u003erun-gprof.sh\u003c/em\u003e is provided to profile code on a compute node. If you want to use Valgrind write your own script similar to \u003cem\u003erun-gprof.sh\u003c/em\u003e and remember to load the Valgrind module. You can change any of these scripts to test for different data based on the comments inside the scripts. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eReport\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must write a report documenting your implementation, displaying your results in a meaningful way, and analyzing your findings, for each part of the assignment. In your report, you should present your ideas, the experimental setup and results. You should discuss what you noticed, draw conclusions and explain any optimization decisions, if any. The report should be written in a scientific manner (clear structure, clear description of your approach, results, findings, etc., and should use technical writing instead of colloquial terminology or phrases). Keep in mind that presenting your experimental findings and observations to a technical audience is an important skill to develop as a computer scientist.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eSubmission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must keep the same structure as the starter code: part1 code under the \"part1/\" directory, part2 code under the \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\"part2/\" directory. You must submit all the files required to build and run all your programs (including any header files and the makefiles, etc.). Make sure your code compiles and runs correctly on the teaching lab machines.\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor part1, you may keep all your C code in\u003cem\u003e part1.c\u003c/em\u003e, but if you add any other source files, make sure that you update the makefile accordingly. You must also submit the scripts for collecting data and generating graphs, and\u003cspan style=\"text-decoration: underline;\"\u003e create a target called \"run\"\u003c/span\u003e in the part1 makefile that invokes the script(s) to collect all the necessary data and generate all the graphs that you use in your report. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor part2, you shouldn't need to add any new files to the starter code, but if you do, make sure that you update the makefile accordingly.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eBe sure to make it clear how to run your code with various configurations, in your report! \u003cspan style=\"text-decoration: underline;\"\u003eDo not submit any executables or object files!\u003c/span\u003e (do a \"make clean\" before making your final commit)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit the report (named \u003cem\u003ereport.pdf\u003c/em\u003e, in the top directory of the assignment) documenting your approach, presenting the results, and discussing your findings. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAdditionally, you must submit an \u003cem\u003eINFO.txt\u003c/em\u003e file, which contains as the first 2 lines the following: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour name(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour UtorID(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you want us to grade an earlier revision of your assignment for whatever reason \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(for example, for saving some grace tokens if you had a stable submission before the deadline, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003etried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want marked. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAs a general rule, by default we will always take the last revision before the deadline \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(or last one after the deadline, up to your remaining unused grace tokens), so you should \u003c/span\u003e\u003cstrong\u003enot\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens if you submit late) is the one you want graded.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFinally, whether you work individually or in pairs with a partner, you \u003c/span\u003e\u003cstrong\u003emust\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e submit a \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003eplagiarism.txt\u003c/em\u003e file (in the top directory of the assignment), with the following statement: \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cem\u003e\u003cspan style=\"font-weight: 400;\"\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/span\u003e\u003c/em\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA missing \u003cem\u003eINFO.txt\u003c/em\u003e file will result in a 10% deduction (on top of an inherent penalty if we do not end upgrading the revision you expect). \u003c/span\u003e\u003cstrong\u003eAny missing code files or makefile will result in a 0 on this assignment\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e! \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ePlease reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAgain, make sure your code compiles without any errors or warnings.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eCode that does not compile will receive zero marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eMarking scheme\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be marking based on correctness (90%), and coding style (10%). Make sure to write legible code, properly \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eindented, and to include comments where appropriate (excessive comments are just as bad as not providing enough comments). Code structure and clarity will be marked strictly!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eOnce again: code that does not compile will receive 0 marks!\u003c/strong\u003e \u003cspan style=\"font-weight: 400;\"\u003eMore details on the marking scheme: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 1: 40%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 2: 30%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eReport: 20% (12% for Part 1 + 8% for Part 2)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e(BONUS) Cache line size measurement: 10% (5% for the implementation, 5% for explaining the rationale clearly in the report, justifying your approach)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e(BONUS) Studying the effect of compiler optimizations for Part2: 5%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode style and organization: 10% - code design/organization (modularity (if applicable), code readability, reasonable variable names, avoid code duplication, appropriate comments where necessary, proper indentation and spacing, etc.)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eNegative deductions (please be careful about these!):\u003c/strong\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eCode does not compile: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e for *any* mistake, for example missing source file necessary for building your code (including makefile, header files, etc.), typos, any compilation error, etc\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eNo plagiarism.txt file: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (we will assume that your code is plagiarised and wish to withdraw your submission if this file is missing)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eMissing or incorrect INFO.txt: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eWarnings: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eExtra output: -20%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (for any output other than what is required in the handout)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eCode placed in other subdirectories than indicated: -20%\u003c/strong\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":"2019-01-28T22:00:00-05:00","lockAt":null,"unlockAt":"2019-01-14T10:00:00-05:00"},{"exportId":"iddb96613ce5edd328efd7037b8c58fe5","title":"Assignment two","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAssignment 2 - Parallel Data and Task Management\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Monday February 11, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 10 \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday January 30, at 10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this assignment!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eIntro to Scinet:\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this assignment. You should have already received an email with your Scinet login. In that email you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et  document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eOverview\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work in groups of two for this assignment. Before you start, you must read section 7 from this \u003c/span\u003e\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epthreads tutorial\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e from the Lawrence Livermore National labs.  Your task is to implement a series of image processing methods, then parallelize them using data decomposition (partitioning) and the following parallel models: the data parallel model, and the work pool model.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease log into MarkUs as soon as possible to find your repository and invite your partner, and make sure that you can commit and push to your repo. For all assignments and labs you will be given your repo URL on MarkUs. Make sure to use this repository (which should already be created for you), otherwise MarkUs won't know about it and we won't be able to see your work.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eon\u003c/span\u003e \u003cem\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter/assignments/assignment2/starter_code.tgz\u003c/span\u003e\u003c/em\u003e \u003cspan style=\"font-weight: 400;\"\u003e \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments. \u003c/span\u003e\u003cstrong\u003eTo encourage you to avoid versioning things that you won't need to submit, we've included a \".gitignore\" file for you in the starter code. Feel free to adjust it for your needs.\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease note that this assignment is once again, meant to be practical and encourage your critical thinking ability. Therefore, the implementation component is not incredibly time consuming (although you do have to reserve reasonable time for it), but you will likely spend quite a bit of time in analyzing your findings and reasoning about your results.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eImage representation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be working with images in the pgm format. Feel free to go over the image specification\u003c/span\u003e\u003ca href=\"http://netpbm.sourceforge.net/doc/pgm.html\"\u003e \u003cspan style=\"font-weight: 400;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e (don't read the \"Plain PGM\" section). You don't have to worry too much about the format, as we provide you with code that reads a pgm image and transforms it into an array of pixels in grayscale, and all of your work will be done with this array. If you are curious, this code is in the files \u003cem\u003epgm.h\u003c/em\u003e and \u003cem\u003epgm.c\u003c/em\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will notice that images are represented as a 1-dimensional array in the code, even though intuitively they are 2-dimensional (why do we do this?). It is your job to calculate the corresponding offsets in the 1 dimensional array of pixels in the 2-dimensional image.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eImage processing\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eImage processing techniques are exciting and useful in many situations: to obtain various artistic effects, sharpen blurry photos, perform edge detection, etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, you will be working with monochrome (greyscale) images. Monochrome images are represented as a two-dimensional array of pixels. Each pixel is stored as a byte and encodes a greyscale color as a value between 0 and 255.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA discrete Laplace operator is used to compute the second derivatives of an image, which can emphasize edges within an image. This is useful in image processing for performing edge detection and various other related applications. The discrete Laplacian filter is a 3 x 3 array, which typically contains a high negative value at the center, surrounded by small positive values. Some variations include opposite signs, to achieve a similar effect.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHere are some examples of two Laplacian filters:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\left(\r\n\\begin{matrix}\r\n1 \u0026amp; 1 \u0026amp; 1 \\\\\r\n1 \u0026amp; -8 \u0026amp; 1 \\\\\r\n1 \u0026amp; 1 \u0026amp; 1\r\n\\end{matrix}\r\n\\right)\" src=\"https://q.utoronto.ca/equation_images/%255Cleft(%250A%255Cbegin%257Bmatrix%257D%250A1%2520%2526%25201%2520%2526%25201%2520%255C%255C%250A1%2520%2526%2520-8%2520%2526%25201%2520%255C%255C%250A1%2520%2526%25201%2520%2526%25201%250A%255Cend%257Bmatrix%257D%250A%255Cright)\" alt=\"LaTeX: \\left(\r\n\\begin{matrix}\r\n1 \u0026amp; 1 \u0026amp; 1 \\\\\r\n1 \u0026amp; -8 \u0026amp; 1 \\\\\r\n1 \u0026amp; 1 \u0026amp; 1\r\n\\end{matrix}\r\n\\right)\" data-equation-content=\"\\left(\r\n\\begin{matrix}\r\n1 \u0026amp; 1 \u0026amp; 1 \\\\\r\n1 \u0026amp; -8 \u0026amp; 1 \\\\\r\n1 \u0026amp; 1 \u0026amp; 1\r\n\\end{matrix}\r\n\\right)\" data-mathml='\u0026lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"\u0026gt;\r\n  \u0026lt;mrow\u0026gt;\r\n    \u0026lt;mo\u0026gt;(\u0026lt;/mo\u0026gt;\r\n    \u0026lt;mtable rowspacing=\"4pt\" columnspacing=\"1em\"\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mo\u0026gt;\u0026amp;#x2212;\u003c!-- − --\u003e\u0026lt;/mo\u0026gt;\r\n          \u0026lt;mn\u0026gt;8\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n    \u0026lt;/mtable\u0026gt;\r\n    \u0026lt;mo\u0026gt;)\u0026lt;/mo\u0026gt;\r\n  \u0026lt;/mrow\u0026gt;\r\n\u0026lt;/math\u0026gt;'\u003e or \u003cimg class=\"equation_image\" title=\"\\left(\r\n\\begin{matrix}\r\n0 \u0026amp; 1 \u0026amp; 0 \\\\\r\n1 \u0026amp; -4 \u0026amp; 1 \\\\\r\n0 \u0026amp; 1 \u0026amp; 0\r\n\\end{matrix}\r\n\\right)\" src=\"https://q.utoronto.ca/equation_images/%255Cleft(%250A%255Cbegin%257Bmatrix%257D%250A0%2520%2526%25201%2520%2526%25200%2520%255C%255C%250A1%2520%2526%2520-4%2520%2526%25201%2520%255C%255C%250A0%2520%2526%25201%2520%2526%25200%250A%255Cend%257Bmatrix%257D%250A%255Cright)\" alt=\"LaTeX: \\left(\r\n\\begin{matrix}\r\n0 \u0026amp; 1 \u0026amp; 0 \\\\\r\n1 \u0026amp; -4 \u0026amp; 1 \\\\\r\n0 \u0026amp; 1 \u0026amp; 0\r\n\\end{matrix}\r\n\\right)\" data-equation-content=\"\\left(\r\n\\begin{matrix}\r\n0 \u0026amp; 1 \u0026amp; 0 \\\\\r\n1 \u0026amp; -4 \u0026amp; 1 \\\\\r\n0 \u0026amp; 1 \u0026amp; 0\r\n\\end{matrix}\r\n\\right)\" data-mathml='\u0026lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"\u0026gt;\r\n  \u0026lt;mrow\u0026gt;\r\n    \u0026lt;mo\u0026gt;(\u0026lt;/mo\u0026gt;\r\n    \u0026lt;mtable rowspacing=\"4pt\" columnspacing=\"1em\"\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mo\u0026gt;\u0026amp;#x2212;\u003c!-- − --\u003e\u0026lt;/mo\u0026gt;\r\n          \u0026lt;mn\u0026gt;4\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n      \u0026lt;mtr\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;1\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n        \u0026lt;mtd\u0026gt;\r\n          \u0026lt;mn\u0026gt;0\u0026lt;/mn\u0026gt;\r\n        \u0026lt;/mtd\u0026gt;\r\n      \u0026lt;/mtr\u0026gt;\r\n    \u0026lt;/mtable\u0026gt;\r\n    \u0026lt;mo\u0026gt;)\u0026lt;/mo\u0026gt;\r\n  \u0026lt;/mrow\u0026gt;\r\n\u0026lt;/math\u0026gt;'\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA Laplacian filter can be applied to an existing image, by considering each pixel and its surrounding 8 neighbors and multiplying the 9-pixel values with the corresponding values in the Laplacian filter. The sum of the pairwise multiplications is used as the new value of that pixel.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePixels on the edges and corners of the image are dealt with a bit differently since they do not have all 8 neighbors. Only the valid neighbors and the corresponding filter weights are factored into computing the new value of such a \"marginal\" pixel.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIntuitively, the Laplacian filter emphasizes sudden changes in pixel values. The weights in the Laplacian filter end up setting a darker tone for areas with low pixel changes, and contrasting white tones for sharp changes which represent edges.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce a pixel value is updated, you might notice that the new pixel values may end up outside the [0,255] range. When processing an image, the new pixel values must be brought back to the original range by a process called \u003cstrong\u003enormalization\u003c/strong\u003e. This involves finding the minimum (Min) and maximum (Max), from the new (out-of-bounds) pixel values, then using these to normalize the pixel values back into the [0,255] range. For example, assume that the new pixel values are in the range [-100, 190]. In this case, you must add 100 to all pixels to bring all pixels in the range [0, 290]. Then, you must scale all pixels multiplying with 255/290, to bring all pixels in the [0,255] range.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eYour program\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will implement a program which, given an image, it applies a discrete Laplacian filter to produce a new image. You will work with 4 different filters listed below; their respective matrices are already in the starter code provided (\u003cem\u003efilters.c\u003c/em\u003e).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe program takes the following command line arguments:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe input image: \"-i input.pgm\". This is an optional argument and can be ignored if the built-in parameter is used (see below).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe built-in parameter: \"-b image_number\". This argument indicates that your program will be run with one of the hardcoded images we provided. The reason for using these images and how to generate them will be explained later, in the testing tips section. Use 1 for a big square image or 2 for a very tall (one column) image. Either -b or -i must be specified.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe output image: \"-o output.pgm\". This is the resulting image after applying \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethe filter to the input image (or the built-in image selected). This is an optional argument. If the output image is not specified, then no output image is produced. That is, the program still computes the resulting image in memory but does not write it to a file on disk and its contents will be lost once the program exits. The reason for this will be clear in the testing tips section.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe number of threads: \"-n num_threads\". You must vary the number of \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethreads between 1 and the number of cores available on the test machine.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eTiming enabled: \"-t toggle_timing\". Timing is enabled if toggle_timing is set to 1, and disabled if set to 0. As described later, you will need to time the execution time of your \u003c/span\u003e\u003cstrong\u003eimage processing code\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe filter: \"-f filter_number\"\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe execution method: -m method_number\". If the method is SEQUENTIAL, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ethe num_threads parameter can either not be provided or simply ignored.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe work chunk: \"-c chunksize\". This argument is optional and is only used when the execution method is WORK_QUEUE. This is described further in Part 3.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe are providing in the starter code a set of filters and run method macros which should be self-explanatory. The filter is one of a set of predefined filters (you will find the relevant macros in the starter code):\u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 3x3 Laplacian\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 5x5 Laplacian\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 9x9 Laplacian of Gaussian\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e 1x1 Identity\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe method is the mode of execution, either sequential or one of several parallel strategies (described in Part 2 \u0026amp; 3):\u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSEQUENTIAL\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSHARDED_ROWS\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSHARDED_COLUMNS_COLUMN_MAJOR\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSHARDED_COLUMNS_ROW_MAJOR\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWORK_QUEUE\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will find an enumeration defining those methods in \u003cem\u003efilters.h\u003c/em\u003e. We have given you code that handles the parsing of the command line arguments in the \u003cem\u003emain.c\u003c/em\u003e file, so you don't have to change it.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 1 - Sequential implementation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this part, you will be using the SEQUENTIAL method and the predefined filters. This task is as simple as implementing the function\u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003e apply_filter2d\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e in the file \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003efilters.c\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNOTE:\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e you must especially test your sequential implementation \u003c/span\u003e\u003cstrong\u003ethoroughly\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e, with lots of corner cases and check against your own manual calculations on paper, to make sure that your code produces the correct image. Correctness is \u003c/span\u003e\u003cstrong\u003ecrucial\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e here, especially if you re-use the sequential code for filtering pieces of the image in your parallel implementations!\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 2 - Data Parallel implementation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will now write a Data Parallel implementation using pthreads. Each thread is statically assigned a chunk of the data to process. You must partition the data in three ways: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003ehorizontal sharding (or row partitioning):\u003c/span\u003e each thread processes a set of \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003econsecutive rows, such that each thread gets a roughly equal number of rows. If the total number of rows is not divisible by the number of threads, then each thread will be assigned nrows\u003cem\u003e/\u003c/em\u003enthreads rows, except possibly for the last thread, which may get assigned more rows.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan style=\"text-decoration: underline;\"\u003evertical sharding (or column partitioning):\u003c/span\u003e similar to horizontal sharding, but instead, each thread processes a (roughly) equal number of consecutive columns. For this partitioning, there are two processing methods: column major and row major. In column-major, a thread processes all the pixels in a column before moving on to its next assigned column. In row major, a thread processes first all the pixels from the first row of every column in its subset of columns, then moves on to the pixels from the second row of its columns, and so on.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis part consists of implementing part of the function \u003cem\u003eapply_filter2d_threaded\u003c/em\u003e in \u003cem\u003efilters.c\u003c/em\u003e. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor now, only handle the cases where the method parameter is one of: \u003c/span\u003e\u003cspan style=\"font-size: 1rem;\"\u003eSHARDED_ROWS, SHARDED_COLUMNS_COLUMN_MAJOR, SHARDED_COLUMNS_ROW_MAJOR.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eYou must now profile your code and determine where most of the execution time is spent.\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e If you have modularized your code well, it should be easy to prove that the code which does the image processing is where most of the computation time is spent.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 3 - Work Pool implementation\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will now write a Work Pool implementation using pthreads. This is specified as the WORK_QUEUE method number. In the WORK_QUEUE method, the image is divided in square tiles of size chunk x chunk (where chunk is the command line argument described as the work chunk earlier). All the tiles (work chunks) are statically placed in a queue at the start of the program. A task has the granularity of one tile. That is, each thread will take one tile at a time from the queue and process it before proceeding to grab another tile. You must implement this abstraction \u003c/span\u003e\u003cstrong\u003eefficiently\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNote: Your implementation must ensure that accesses to shared resources are synchronized. Keep in mind that although your program may be run in sequential mode (that is, using a work pool with 1 thread), you should still use locking where necessary.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis part consists of implementing the remaining part of the function \u003cem\u003eapply_filter2d_threaded\u003c/em\u003e in \u003cem\u003efilters.c\u003c/em\u003e, in other words, you should handle the case where method is WORK_QUEUE.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eGeneral parallel guidelines\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn the parallel implementations, you have to consider the fact that normalization cannot be done until all threads know the Min and Max pixel values. We suggest structuring your computation into the following steps:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e- In the first stage, while applying the filters on a data partition, threads must also calculate a partial Min and Max pixel value from their assigned data partition. Consider having each of the threads store their partial Min and Max values into separate elements of a shared global array.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e- Once the filter is applied by all threads and each thread has calculated their local Min and Max values, all threads must synchronize to ensure that everyone has finished this step. This can be achieved by using a \u003cem\u003epthread_barrier\u003c/em\u003e construct (check out the documentation for further details).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e- Next, all threads calculate the global Min and global Max values using the other threads' local Min and Max. Once the threads all have the global Min and Max, the next step involves all threads performing the normalization on their assigned data partitions.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003ePart 4 - Data collection and analysis\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce you have implemented all the parts of the assignment and verified the correctness \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eof the output, you must measure the time taken in each of the previous parts, and collect all the necessary data points. We have already provided time measurements in the starter code, inside main.c. It's up to you to design meaningful experiments using this timing functionality.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should also collect other data using perf tools.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must plot your results visually (graphs!) and analyze your results.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must automate running the experiments, collecting the data and generating the graphs. You need to write a script (e.g. Python) that invokes your C program, performs all measurements, and produces all the graphs and other necessary data that you use to draw conclusions that you describe in your report. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe have provided a sample script perf_student.py to get you started. You must also describe your data collection programs and scripts in your report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003ci\u003e(Please note that the python scripts that help with generating the graphs is only made \u003cstrong\u003eavailable in the starter code after 6pm of Tuesday Jan 29th\u003c/strong\u003e to not overlap with the grace period of Assignment 1)\u003c/i\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn a report (you must name this file Report.pdf, see the following section), you must describe your implementation, your experiments and include the graphs, then analyze your results, draw conclusions and report your findings. It is important to show insight into what you are measuring and explain the performance of various strategies under certain conditions and inputs, explain why different methods perform in a certain way, etc. For example, you should discuss how well your algorithms scale and how various considerations discussed in class play a factor into the results. You should keep your report reasonably concise (e.g., 5-10 pages is ok, 40 pages is rather excessive), assuming a reasonable font size and readable figures.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eTo help guide your observations, we are recommending the following experiments and plotting the corresponding data points. You are welcome to run extra experiments and investigate further, but your report should at least describe your results and analyze your findings for the following experiments. \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eRun the sequential algorithm as well as the parallel methods for a given image. For each run, vary the number of threads from 1 to the total number of cores by doubling the number of threads (i.e.,., 1, 2, 4, 8.). We want the experiments to be on up to 8 threads which is the number of physical cores. Consider checking the L1 cache misses and explaining why and how these factor into your results. \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor the work queue implementation, the length of the tile is set to be equal to the number of threads used. That is, the chunk will be N x N, where N is the number of threads. Remember that your implementation uses synchronization regardless of N. In fact, observing the locking overhead when N=1 is an interesting aspect to consider. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eTest the work pool method for a variety of chunk sizes. For example, using N threads, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eyou could measure the time depending on chunk size, by changing the chunk size: 1x1, 2x2, 4x4, 8x8, 16x16, 32x32, etc. Plot a separate line for each N between 1 and the number of cores on the same graph. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eNow vary the filter size for each of the methods (including the sequential one). Keep the number of threads constant to an N = 8, i.e. the number of physical cores, and (for work pool) use a chunk size of N x N. You may additionally vary these if you wish, or if you plan to gain further insights. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eVary the images used for testing using the built-in ones, and any additional images \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eyou may wish to create yourself. Consider special cases that might help you gain certain insights into the differences between various methods (e.g., when would some of them likely perform better than others). Keep in mind that you must analyze your results in the report and discuss your findings. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch2\u003e\u003cstrong\u003eReport\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must write a report documenting your implementation, displaying your results in a meaningful way, and analyzing your findings. Name it \"Report.pdf\". In your report, you should present your implementation, the experimental setup and results. You should discuss what you noticed, draw conclusions and analyze the tradeoffs, if any. The report should be written in a scientific manner (clear structure, clear description of your approach, results, findings, etc., and should use technical writing instead of colloquial terminology or phrases). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eKeep in mind that presenting your experimental findings and observations to a technical audience is an important skill to develop as a computer scientist.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eTesting tips\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, here are a few tips to help you get a better experimentation \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eenvironment:\u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the Scinet server to run your experiments.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eA job file named with \u003cem\u003erun-job-a2.sh\u003c/em\u003e is provided that you can use for running the \u003cem\u003eperf_student.py\u003c/em\u003e on the Scinet compute node. You can execute \u003cem\u003erun-job-a2.sh\u003c/em\u003e by typing:\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e ./run-job-a2.sh.sh\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should be able to see some graphs by running the scripts but the graphs will be correct once you finish the TODOs properly.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eMeasuring architectural events using perf tools cannot be done accurately for the part you intend to measure, if your program is also writing the output image to a file, or doing \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eany serious IO (including printing timing measurements). This is why it is possible to disable writing the output to a file and collecting the timing. In other words, when using perf tools don't use -o and use -t 0. Consider carefully what you are measuring and how your program's execution parameters can impact your tests.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSince reading an image from disk might affect your architectural counter measurements too, you should consider using the hardcoded images we provide as part of the starter code, or generate your own in a similar fashion. Read the \u003cem\u003erun-job-a2.sh\u003c/em\u003e script in order to learn how to generate those images.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor each experiment, you must take the average of 10 runs. Measure the standard deviation of your timing results across the 10 runs, and (this takes a lot of work to code, so it is just a suggestion) consider adding error bars on your measurements, for clarifying if the difference between two test results is significant or whether your results are very noisy.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUse small scale experiments or contrived examples, if you must test a specific behaviour. Check the correctness of your code though (including when making substantial code changes), because an incorrect result will render any performance measurement meaningless. For instance, you can create a small image by hand, apply one filter by hand (it's just basic arithmetic operations, after all), and compare the result with what your code produces. \u003c/span\u003e\u003cstrong\u003eAgain, you \u003c/strong\u003e\u003cstrong\u003e\u003ci\u003emust\u003c/i\u003e\u003c/strong\u003e\u003cstrong\u003e check on paper on a small example that your sequential algorithm works correctly.\u003c/strong\u003e\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003ch2\u003e\u003cstrong\u003eSubmission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will submit your code on MarkUs under your\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cem\u003e Assignment2\u003c/em\u003e director\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ey (do not create this manually, it should be created for you when you log into your MarkUs web interface). Be sure to make it clear how to run your code with various configurations, in your report! You must also submit any files required to build your program (including any header files (optional), a \u003cem\u003eMakefile\u003c/em\u003e (mandatory!), etc.). \u003cspan style=\"text-decoration: underline;\"\u003eDo not submit executables or object files!\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOur autotesting script will invoke \u003cem\u003emake main\u003c/em\u003e to test the correctness of your code, that is, if it produces the correct output image. In other words, \u003cem\u003emake main\u003c/em\u003e MUST generate your binary file (the starter code already does that for you). Furthermore, you must provide a \u003cem\u003emake run\u003c/em\u003e target (see the provided Makefile), which will generate ALL graphs included in your report. It is ok if \u003cem\u003emake run\u003c/em\u003e takes roughly one hour to run.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may NOT modify the \u003cem\u003emain.c\u003c/em\u003e file, nor the\u003cem\u003e make main\u003c/em\u003e or \u003cem\u003emake pgm_creator\u003c/em\u003e targets in the Makefile. You must include at least the files\u003cem\u003e filters.c,\u003c/em\u003e \u003cem\u003efilters.h,\u003c/em\u003e \u003cem\u003emain.c, Makefile, pgm.c,\u003c/em\u003e \u003cem\u003epgm_creator.c,\u003c/em\u003e \u003cem\u003epgm.h\u003c/em\u003e. An ideal submission would only modify \u003cem\u003efilters.c\u003c/em\u003e and add the scripts for graph generation. Do NOT include the files related to the hardcoded images (\u003cem\u003every_{big,tall}_sample.{c,h}\u003c/em\u003e).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit the report documenting your implementation, \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003epresenting the results, and discussing your findings. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAdditionally, you must submit an \u003cem\u003eINFO.txt\u003c/em\u003e file, which contains as the first 2 lines the following: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour name(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour UtorID(s)\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you want us to grade an earlier revision of your assignment for whatever reason \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(for example, for saving some grace tokens if you had a stable submission before the deadline, tried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want marked. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAs a general rule, by default we will always take the last revision before the deadline \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e(or last one after the deadline, up to your remaining unused grace tokens), so you should \u003c/span\u003e\u003cstrong\u003enot\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eif you submit late) is the one you want graded.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFinally, whether you work individually or in pairs with a partner, you \u003c/span\u003e\u003cstrong\u003emust\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e submit a \u003cem\u003eplagiarism.txt\u003c/em\u003e file, with the following statement:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA missing INFO.txt file will result in a 10% deduction (on top of an inherent penalty if we do not end up grading the revision you expect). \u003c/span\u003e\u003cstrong\u003eAny missing code files or Makefile will result in a 0 on this assignment\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e! \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ePlease reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAgain, make sure your code compiles without any errors or warnings.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eCode that does not compile will receive zero marks!\u003c/strong\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003eChecklist\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eMake sure you have: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eImplemented the sequential version of the code and checked with a small \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eexample on paper to see if it produces the correct output pixel values.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eImplemented the parallel versions of the code:\u003c/span\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded rows\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded columns, column major\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded columns, row major\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWork queue\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWritten your make run target, which will invoke scripts that generate the graphs in your report.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eNOT modified make main and make pgm_creator.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eNOT modified main.c.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eCommited your: \u003c/span\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003esource code files (including headers)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003escripts for the graphs\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eMakefile\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eINFO.txt file\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eplagiarism.txt file\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eReport.pdf file\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003ch2\u003e\u003cstrong\u003eMarking scheme\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will be marking based on correctness (90%), and coding style (10%). Make sure to write legible code, properly indented, and to include comments where appropriate (excessive comments are just as bad as not providing enough comments). Code structure and clarity will be marked strictly!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eOnce again: code that does not compile will receive 0 marks!\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e More details on the marking scheme: \u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSequential implementation: 5%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded parallel implementation: 30% (10% each)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWork-queue implementation: 15%\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eReport: 40% (including testing scripts)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode style and organization: 10% (code organization and modularity (if applicable), code readability, reasonable variable names, avoid code duplication, appropriate comments where necessary, proper indentation and spacing, etc.)\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eNegative deductions (please be careful about these!):\u003c/strong\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eCode does not compile: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e for *any* mistake, for example: missing source file necessary for building your code (including Makefile, header files, etc.), typos, any compilation error, etc\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eNo plagiarism.txt file: -100%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (we will assume that your code is plagiarised and you wish to you withdraw your submission, if this file is missing)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eMissing or incorrect INFO.txt: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eWarnings: -10%\u003c/strong\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cstrong\u003eExtra output: -20%\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e (for any output other than what is required in the handout)\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cstrong\u003eCode placed in other subdirectories than indicated: -20%\u003c/strong\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":10.0,"dueAt":"2019-02-11T22:00:00-05:00","lockAt":null,"unlockAt":null},{"exportId":"id33b9075ac365305b2f60e75d4c28bec","title":"Lab 02","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 2 - POSIX Threads\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 23, at 10pm\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 1\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 23th at 2:10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this lab!\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e \u003c/h2\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this lab. You should have already received an email with your Scinet login. In that email, you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e1. Introduction\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with POSIX threads. Please start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou will work with a partner for this lab, but you may also discuss your results with your classmates. Please log into MarkUs well before the deadline to find your repository and make sure that you can commit to it. Do not create a separate directory in your repository, it should already be created for you. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ebefore\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e2. Requirements\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e Scinet from \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/labs/lab2/starter_code.tgz so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour task for this exercise is to work on implementing a basic algorithm both sequentially and in parallel, using pthreads. The goal is to get some insight into the decisions involved in parallelizing an algorithm.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003ePart1: Sequential algorithm\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you are to implement a basic algorithm for scaling down a set of measurements by a set of weights. The measurements are stored in an array of floating-point numbers M, of size N, and the weights are stored in an array \u003cimg class=\"equation_image\" title=\"R\" src=\"https://q.utoronto.ca/equation_images/R\" alt=\"LaTeX: R\" data-equation-content=\"R\"\u003e, of the same size. The result \u003cimg class=\"equation_image\" title=\"R\" src=\"https://q.utoronto.ca/equation_images/R\" alt=\"LaTeX: R\" data-equation-content=\"R\"\u003e is generated by scaling down the items of \u003cimg class=\"equation_image\" title=\"M\" src=\"https://q.utoronto.ca/equation_images/M\" alt=\"LaTeX: M\" data-equation-content=\"M\"\u003e by the weights \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003ein \u003cimg class=\"equation_image\" title=\"W\" src=\"https://q.utoronto.ca/equation_images/W\" alt=\"LaTeX: W\" data-equation-content=\"W\"\u003e, as follows:\u003cimg class=\"equation_image\" title=\"R_i\\:=\\:M_i\\:\\times W_i\" src=\"https://q.utoronto.ca/equation_images/R_i%255C%253A%253D%255C%253AM_i%255C%253A%255Ctimes%2520W_i\" alt=\"LaTeX: R_i\\:=\\:M_i\\:\\times W_i\" data-equation-content=\"R_i\\:=\\:M_i\\:\\times W_i\"\u003e  for \u003cimg class=\"equation_image\" title=\"0\\:\\le i\\:\u0026lt;\\:n\" src=\"https://q.utoronto.ca/equation_images/0%255C%253A%255Cle%2520i%255C%253A%253C%255C%253An\" alt=\"LaTeX: 0\\:\\le i\\:\u0026lt;\\:n\" data-equation-content=\"0\\:\\le i\\:\u0026lt;\\:n\"\u003e. Both \u003cimg class=\"equation_image\" title=\"M\" src=\"https://q.utoronto.ca/equation_images/M\" alt=\"LaTeX: M\" data-equation-content=\"M\"\u003e and \u003cimg class=\"equation_image\" title=\"W\" src=\"https://q.utoronto.ca/equation_images/W\" alt=\"LaTeX: W\" data-equation-content=\"W\"\u003e are generated internally in the starter code.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must time the computation part involving the scaling algorithm (do not include other items like reading from a file or printing output). You must use the \u003cem\u003eclock_gettime()\u003c/em\u003e function for this purpose. For further documentation on this, please consult the manual pages. For testing purposes, the array R must be saved to a file \"sequential_output.txt\" (this is done by the starter code).\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003ePart2: Parallel algorithm\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePOSIX threads or pthreads offer a standardized API for writing multithreaded programs. To implement a multithreaded program you will need to create a set of threads, and wait for them to finish. Before you start, you must read sections 1 through 5.3 from this \u003c/span\u003e\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epthreads tutorial\u003c/span\u003e\u003c/a\u003e \u003cspan style=\"font-weight: 400;\"\u003efrom the Lawrence Livermore National labs. The sections indicated contain a basic introduction to pthreads, which you will need to complete this lab.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you must parallelize the algorithm from part1 using pthreads. Each thread computes a set of items from the result R, independently of all other threads. Your code must take a command line argument: the number of threads, T. This is already implemented in the starter code.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour parallel algorithm must contain two versions corresponding to the following approaches: \u003c/span\u003e\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eSharded: Each thread processes an equal amount of consecutive elements from R (using the corresponding elements from M and W). For example, if N = 8 and T = 2, then thread 0 is assigned elements R0, R1, R2, and R3 from the result, while thread 1 computes elements R4, R5, R6, and R7. N is selected to be power of two so, an even number of elements get assigned to each thread. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eStrided: Each thread processes every T-th item. For example, if T = 4, then thread 0 will process items R0, R4, R8, etc., thread 1 will process items R1, R5, R9, etc.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this part, you must also time your code, and compare the two parallel versions between each other, as well as against the sequential version. For testing purposes, the array R must be saved to the files \"sharded_output.txt\" and \"strided_output.txt\". This is already implemented in the starter code. You can increase N  to see significant differences. If N does not divide exactly by T, then the last thread gets assigned a few elements more or less than all other threads. Remember to set N back to the original number in the starter code since we autograde using that value. What do you notice? Discuss your findings with your TA. One easy sanity check is to run the diff command on your output files. For instance, diff sequential_output.txt sharded_output.txt should produce no output, i.e., the files are identical.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003e3. Running the code:\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor running Lab02 on Scinet compute nodes a script named with run-job-lab02.sh is provided. You can call this script by calling ./run-job-lab02.sh \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e4. Submission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints the execution time for the sequential and parallel code. All your code should be included in a single C file, named lab2pthreads.c. Your output should consist of 4 lines, two lines for the sequential implementation, one for each parallel implementation. Each line must contain the name of the implementation, followed by a single space, followed by the equals sign, followed by a single space, followed by a floating point number representing the time taken (in seconds) for the respective algorithm. For example:\u003c/span\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003cspan style=\"font-weight: 400;\"\u003esequential = 0.0123123123\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003esequential = 0.0123123123\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eparallel strided = 0.01231231\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eparallel sharded = 0.01231231\u003c/span\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe order in which the implementations are reported should be exactly as above, that is, sequential, then parallel strided, then parallel sharded. Make sure to commit the Makefile as well. \u003c/span\u003e\u003cstrong\u003eDo not commit any of the .txt files\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e. Make sure your code compiles and runs on the Scinet cluster. \u003c/span\u003e\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":"2019-01-23T22:00:00-05:00","lockAt":null,"unlockAt":"2019-01-23T10:00:00-05:00"},{"exportId":"i9064ec2df15c199a7449fbf111e04753","title":"Lab03","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 3 - \u003cstrong\u003e\u003cspan style=\"text-decoration: underline;\"\u003ePOSIX Threads and Synchronization\u003c/span\u003e\u003c/strong\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday January 30, at 10pm\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 1.5\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, January 30th at 2:10pm. If you do not have a partner in MarkUs by this deadline, you will not be able to submit this lab!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this lab. You should have already received an email with your Scinet login. In that email, you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e1. Introduction\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with pthreads and basic synchronization using mutexes. Please start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work with a partner for this lab, but you may also discuss your results with your classmates. Please log into MarkUs well before the deadline to find your repository and make sure that you can commit and push to it. Do not create a separate directory in your repository, it should already be created for you. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit/push your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e2. Requirements\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on Scinet under \u003c/span\u003e\u003cem\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/labs/lab3/starter_code.tgz\u003c/span\u003e\u003c/em\u003e \u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour task for this exercise is to work on implementing a basic hashtable, both a single-threaded version and a concurrent version, using pthreads. The goal is to get some exposure to synchronizing accesses to shared data, in a practical context.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 1: Non-concurrent hashtable\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you are to implement a basic hashtable which does not support concurrent accesses. We are providing a skeleton of the hash table implementation (\u003cem\u003ehash.h\u003c/em\u003e, \u003cem\u003ehash-nolock.c\u003c/em\u003e) as well as a basic program (\u003cem\u003etest-simple.c\u003c/em\u003e) that uses the hashtable to add items and retrieve them. You must not modify the \u003cem\u003ehash.h\u003c/em\u003e file, and must implement the exact interface specified in \u003cem\u003ehash.h\u003c/em\u003e, using the \"skeleton\" provided in \u003cem\u003ehash-nolock.c\u003c/em\u003e. You must time your hashtable using the stress test program (\u003cem\u003etest-perf.c\u003c/em\u003e) we provided. Important: your program shouldn't print anything on stdout/stderr except the execution time (see \u003cem\u003emain()\u003c/em\u003e function in \u003cem\u003etest-perf.c\u003c/em\u003e) if no errors occur; otherwise our autotester will fail your submission. Please remove all debugging output in your final submission.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 2: Concurrent hashtable\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eBefore you start, you must read section 7 from this pthreads\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/#Mutexes\"\u003e tutorial\u003c/a\u003e from the Lawrence Livermore National labs. The section contain a basic introduction to mutex locks, which you will need to complete this lab.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part you must implement a concurrent version of your hash table (in \u003cem\u003ehash-mutex.c\u003c/em\u003e), respecting the same interface in the \u003cem\u003ehash.h\u003c/em\u003e file. You must ensure that concurrent accesses (get or put items) to the same hashtable bucket are protected using mutexes, avoiding race conditions. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should also implement a parallel version of the stress test program we gave you in part1 (in \u003cem\u003etest-perf-parallel.c\u003c/em\u003e), using pthreads. Each thread must be assigned an equal number of operations to the hashtable (the one specified as a command line argument; see comments in \u003cem\u003etest-perf-parallel.c\u003c/em\u003e in the starter code).\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this part, you must also time your code, and compare the concurrent hashtable version against the single-threaded version. Discuss your findings with your TA.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cstrong\u003e3. Running the code:\u003c/strong\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor running Lab03 on Scinet compute nodes two scripts called with \u003cem\u003erun-job-lab03-seq.sh\u003c/em\u003e and \u003cem\u003erun-job-lab03-parallel.sh\u003c/em\u003e  are provided in order to run the sequential and parallel implementation. You can call any of these scripts by putting “./” before it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cstrong\u003e4. Submission\u003c/strong\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push all the files required to compile and run your code (all the source code and the makefile). \u003cstrong\u003eYou shouldn't need to add any new files to the starter code\u003c/strong\u003e, but if you do, make sure that you update the makefile accordingly. Make sure your code compiles and runs correctly on the Scinet teach cluster machines.\u003c/span\u003e\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":"2019-01-30T22:00:00-05:00","lockAt":null,"unlockAt":"2019-01-29T18:00:00-05:00"},{"exportId":"iff33c2b823d5364fdae06756b85cb5af","title":"Lab 05","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 5 - MPI \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday, February 27, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: 1.5 \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: You should work with a partner, the deadline for finding a partner is Wednesday, February 27, at  2:10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this lab. You should have already received an email with your Scinet login. In that email you see a link to \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe short intro to Scine\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003et  document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e1. Introduction\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with MPI routines, especially with complex collective operations. Please start early to fully take advantage of the lab time to ask questions. You should read sections 5, 9, 10 and 11 of the \u003ca href=\"https://computing.llnl.gov/tutorials/mpi/\"\u003eMPI tutorial\u003c/a\u003e from the Lawrence Livermore National Laboratory before starting this lab.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003cbr\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eMarkUs will only create the appropriate directory in your repository when you log into MarkUs. Please log into MarkUs well before the deadline to take these steps, find your repository and make sure that you can commit and push to it. Do not create a separate directory in your repository, it should already be created for you. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ebefore\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e the exercise deadline to ensure that you know where to commit/push your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e2. Preliminaries\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet under \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e/labs/lab5/starter_code.tgz\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e so copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e3. Requirements\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour task for this exercise is to work on implementing two short pieces of code using MPI constructs. The goal is for you to get some hands-on experience with MPI and time your parallel code.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart1: Gather/Allgather\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you are to implement code that transposes an N x N matrix using only MPI_Gather (or MPI_Allgather) operations. You may use MPI_Barrier as well, if necessary. You must \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eimplement this version of the program in the file transpose-sg.c.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor simplicity, you may assume that N == P, where P is the number of processes. Under this assumption, each process starts with an array holding one row, and the master (rank 0) must in the end have the transposed matrix. You must initialize the rows with values that allow you to check the correctness of your program (for example, if you use random values it \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003emight be tricky to test the validity of your code). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may use MPI_Allgather, such that all processes will receive the transposed matrix (not only the master), but it's not necessary and will not be tested. Once you get your code working, you are encouraged to try to make your code as general as possible, but this will not be tested.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must make sure that your code produces correct result first. Then, you must time your code, using MPI_Wtime(). You may take the time elapsed on the master node as the time taken by the operations measured (see comments in the starter code). NOTE: execution times must be reported in \u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003emilliseconds\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003edouble t1, t2, elapsed;\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003et1 = MPI_Wtime();\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003e... \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003et2 = MPI_Wtime();\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eelapsed = t2 - t1;\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003cbr\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart2: All-to-all\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, your task is to implement an N x N matrix transposition, but this time you must use the MPI_Alltoall operation. You must implement this version of the program in the file \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003etranspose-alltoall.c. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHint: in the simple case, transposing the rows using the MPI_Alltoall operation should be trivial. You may have to collect all the transposed rows into the master though (as a separate final operation).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must make sure that your code produces the correct result, and time your code for this part as well. Discuss your approach with your TA if you get stuck.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNOTE: you must keep the same output format as in the starter code. Do not add any new output, otherwise the \u003c/span\u003e \u003cspan style=\"font-weight: 400;\"\u003eautotester will fail your submission.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e4. Running the code:\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor running Lab05 on Scinet compute nodes two scripts named run-job-lab05-part1.sh and run-job-lab05-part2.sh are provided in order to run the first and second parts of the lab respectively. You can call any of these scripts by putting “./” behind it. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e5. Submission\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push all the files required to compile and run your code (all the source code and the makefile). You shouldn't need to add any new files to the starter code, but if you do, make sure that you update the makefile accordingly. Make sure your code compiles and runs correctly on the Scinet cluster.\u003c/span\u003e\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":"2019-02-27T22:00:00-05:00","lockAt":null,"unlockAt":null},{"exportId":"i841881a934f3c568a5180f78fa948889","title":"Lab 06","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 6 - GPU intro, device specs\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday March 13, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003ePoints\u003c/strong\u003e: 1\u003c/p\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you understand the GPU architecture and the CUDA environment, by querying the device to determine its properties. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSee the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation for more information. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work in pairs for this exercise, with your A4 partner, since some code will potentially be common with the assignment. MarkUs will only create the appropriate directory in your repository when you log into MarkUs and either create your group, or declare that you will work alone. The groups will get a new shared repository, and the students working solo may also get a new repository. Please log into MarkUs well before the deadline to take these steps. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on wolf (the department’s teach/CDF machines) under\u003c/span\u003e\u003cem\u003e\u003cstrong\u003e /u/csc367h/winter/pub/labs/lab6/starter_code.tgz \u003c/strong\u003e\u003c/em\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eBackground\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn order to leverage the immense power of the GPUs, one must understand how devices operate, and how memory is organized. Before getting to allocating memory, launch computations, and all the fun things that come with programming in the CUDA environment though, it would be useful to know how to retrieve some information about the GPU, such as how much memory and what type of capabilities it has.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePhysical GPUs are called devices. When the CUDA environment is initialized, the driver creates a global data structure that contains the names and capabilities of the available devices (e.g., amount of device memory, clock rate, etc.). Applications can query these device properties either by invoking the driver directly, or by using the CUDA runtime. We will only focus on the latter, since it is easier to use by CUDA novices.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eThe number of CUDA capable devices can be retrieved by using \u003ccode\u003ecudaGetDeviceCount()\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ecudaError_t cudaGetDeviceCount(int* deviceCount);\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eOn success, this returns \u003ccode\u003ecudaSuccess\u003c/code\u003e. The number of CUDA capable devices may be 0, 1, or more, as indicated by dereferencing deviceCount. On error, the CUDA error message can be extracted from the \u003ccode\u003ecudaError\u003c/code\u003e code by using:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003echar* cudaGetErrorString(cudaError_t)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe CUDA runtime exposes the \u003ccode\u003ecudaDeviceGetProperties()\u003c/code\u003e function, which will fill a \u003ccode\u003ecudaDeviceProp\u003c/code\u003estructure, for the device number passed in as the second argument:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003evoid cudaGetDeviceProperties(cudaDeviceProp* deviceProp, int deviceNumber)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eHere are just a few of the properties stored in the \u003ccode\u003ecudaDeviceProp\u003c/code\u003e structure. These properties are fairly intuitive, but some will only be clear once we learn more about how to structure computations in grids, blocks, and thread warps.\u003c/p\u003e\r\n\u003cp\u003eDevice property Description\u003c/p\u003e\r\n\u003ctable\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003echar\u003c/span\u003e name[256]\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eA string identifying the device. On the teaching labs, you will find \"GeForce GTX 1050 Ti\" discrete NVIDIA cards.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e major\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eThe major revision number of the device's compute capability.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e minor\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eThe minor revision number of the device's compute capability.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e multiProcessorCount;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eThe number of multiprocessors on the device. The total number of CUDA cores can be calculated from the compute capability number. The _ConvertSMVer2Cores utility function \"decodes\" the number of cores per multiprocessor, from the compute capability major and minor numbers.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e clockRate;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eGPU clock frequency, in kHz.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e memoryClockRate;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMemory clock rate, in kHz.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e memoryBusWidth;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eGlobal memory bus width, in bits.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003esize_t\u003c/span\u003e totalGlobalMem\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eTotal global memory on the device, in bytes.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003esize_t\u003c/span\u003e sharedMemPerBlock;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eTotal amount of shared memory in each block, in bytes.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003esize_t\u003c/span\u003e l2CacheSize\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eL2 cache size, in bytes.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e regsPerBlock;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eNumber of 32-bit registers per block.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e maxGridSize[3];\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMaximum number of blocks allowed on each dimension of a grid.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e maxThreadsDim[3];\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMaximum number of threads allowed on each dimension of a block.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e maxThreadsPerBlock;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eMaximum number of threads allowed per block.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"width: 264px;\"\u003e\n\u003cspan style=\"color: blue;\"\u003eint\u003c/span\u003e warpSize;\u003c/td\u003e\r\n\u003ctd style=\"width: 833px;\"\u003eNumber of threads in a warp.\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eKeep in mind that this structure has many more fields. Feel free to consult the CUDA documentation for further details. Some these properties will make a lot more sense a bit later, but for now this should give you a good sense of what your GPU can do.\u003c/p\u003e\r\n\u003ch2\u003eYour task\u003c/h2\u003e\r\n\u003cp\u003eYour task for this exercise is simple. Your program must output each of the device properties described in the table above. We have provided some code to get you started, and a Makefile. The starter code contains all the printf function calls you need, with the appropriate strings, so your job consists of replacing the \u003ccode\u003eREPLACE ME\u003c/code\u003e macro with the appropriate variables.\u003c/p\u003e\r\n\u003cp\u003eThe expected output on the lab machines that have discrete NVIDIA cards, is the following:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\r\n    Found 1 CUDA Capable device(s)\r\n\r\n    Device 0: \"GeForce GTX 1050 Ti\"\r\n      CUDA Capability Major/Minor version number:    6.1\r\n      ( 6) Multiprocessors x (128) CUDA Cores/MP: 768 CUDA Cores\r\n      GPU Clock Rate:                                1.39 GHz\r\n      Memory Clock Rate:                             3.50 GHz\r\n      Memory Bus Width:                              128-bit\r\n\r\n      Total amount of global memory:4040 MBytes (4235919360 bytes)\r\n      Shared Memory per Block:                       49152\r\n      L2 Cache Size:                                 1048576\r\n      Registers per Block:                           65536\r\n\r\n      Max grid size:                                 (2147483647, 65535,65535)\r\n      Max thread dimensions:                         (1024, 1024,64)\r\n      Max threads per block:                         1024\r\n      Warp size:                                     32\r\n\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eYou should not hardcode the answers in the code. For instance, you should not have a printf statement like \u003ccode\u003eprintf(\"Warp size: %d\", 32);\u003c/code\u003e in your solution.\u003c/p\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints the required items in the right format. All your code should be included in a single cpp file, named \u003ccode\u003elab6.cpp\u003c/code\u003e. Make sure your code compiles and runs on the teaching lab machines.\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-12T18:00:00-04:00"},{"exportId":"iff2c6495c8cb01ee7a1edcc9940ec309","title":"Lab 07","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 7 - Working with CUDA threads and blocks\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eDue: Wedensday, March 20, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get a bit of practice with some GPU programming basics, by helping you understand how to launch a kernel that performs simple operations and to analyze the performance. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSee the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation for more information. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work in pairs for this exercise, with your A4 partner, since some code will potentially be common with the assignment. MarkUs will only create the appropriate directory in your repository when you log into MarkUs and either create your group, or declare that you will work alone. The groups will get a new shared repository, and the students working solo may also get a new repository. Please log into MarkUs well before the deadline to take these steps. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on wolf under\u003c/span\u003e\u003cstrong\u003e /u/csc367h/winter/pub/labs/lab7/starter_code.tgz \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eRequirements\u003c/h2\u003e\r\n\u003cp\u003eYour task for this exercise is simple. You will write a CUDA kernel, named \"array_add\", which adds two one-dimensional arrays A and B of the same length, by adding their pairwise elements from same indices, and storing the result back into the corresponding elements of \u003ccode\u003eA\u003c/code\u003e (i.e., \u003ccode\u003eA[i] = A[i] + B[i]\u003c/code\u003e). The elements of \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eB\u003c/code\u003e should be initialized to randomized single precision floating-point values under 100.00.\u003c/p\u003e\r\n\u003cp\u003eYour program must increase the input size (the lengths of A and B) from 1M elements to at least 32M. Your must increase the input size in powers of two (1M, 2M, 4M, etc.)\u003c/p\u003e\r\n\u003ch4\u003eStep 1\u003c/h4\u003e\r\n\u003cp\u003eImplement a kernel called \u003ccode\u003earray_add_simple\u003c/code\u003e, which adds the elements of array \u003ccode\u003eB\u003c/code\u003e into those of array \u003ccode\u003eA\u003c/code\u003e. Your program must output, for each array size, the time it takes to copy the arrays from the CPU to the GPU, the time taken by the kernel to perform the computations on the GPU, and the time it takes to copy the resulting array back from the GPU to the CPU. Check the NVIDIA documentation for a description of CUDA events. In a nutshell, your timing measurements should be using the following pattern:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e    cudaEvent_t start, stop;\r\n    float time;\r\n    cudaEventCreate(\u0026amp;start);\r\n    cudaEventCreate(\u0026amp;stop);\r\n    cudaEventRecord(start);\r\n    \u0026lt;code to be timed here\u0026gt;\r\n    cudaEventRecord(stop);\r\n    cudaEventSynchronize(stop);\r\n    cudaEventElapsedTime(\u0026amp;time, start, stop);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe call \u003ccode\u003ecudaEventElapsedTime(\u0026amp;time, start, stop)\u003c/code\u003e stores the elapsed time (in milliseconds) into a single-precision floating-point variable \u003ccode\u003etime\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eFor this initial step, you may only use 1 block and 1 thread. Your code will be very simple - all that the kernel needs to do is iterate through all the elements in the array to add the elements of a and b.\u003c/p\u003e\r\n\u003cp\u003eYour program output should include the size of the arrays, followed by the three time measurements, all separated by spaces. All of these will be preceded by a column called Times, which will be 1 for all measurements. This \u003ccode\u003etimes\u003c/code\u003e value will make more sense in part 4 of this lab. Each measurement result (for a different array size) should be on a separate line:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tTimes Size(M) TransferIn(ms) Computation(ms) TransferOut(ms) \r\n\t    1      1           1.23            2.34            3.45\r\n\t    1      2           1.23            2.34            3.45\r\n\t  ...\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe timings above are just for illustration purposes, to clarify how your output format should look like. To match our output format, please use the printf format specifiers: %5d for the Times and Size columns, and %15.2f for all the others.\u003c/p\u003e\r\n\u003ch4\u003eStep 2\u003c/h4\u003e\r\n\u003cp\u003eImplement a kernel called \u003ccode\u003earray_add_threads_only\u003c/code\u003e, which is invoked using 1 block and 512 threads. You must adjust your kernel to ensure that each thread calculates an equal number of elements. You must try first to give each thread a chunk of Len/512 *consecutive* elements to process, where Len is the number of elements in an array. Next, you must implement a new version of this function, which uses instead strided accesses, in order to allow for memory coalescing. You must compare the results and draw conclusions.\u003c/p\u003e\r\n\u003cp\u003eThe format of the timing measurements should be identical to the one from step 1. Please take the time to look over these measurements and draw conclusions for yourselves. What do you notice? What do the computation times look like and what is the speedup? To get the most out of this lab, you should discuss your findings with your TA.\u003c/p\u003e\r\n\u003ch4\u003eStep 3\u003c/h4\u003e\r\n\u003cp\u003eImplement a kernel called \u003ccode\u003earray_add_threads_blocks\u003c/code\u003e, which is invoked using a number of \u003ccode\u003enum_blocks\u003c/code\u003e blocks and 512 threads. You must calculate \u003ccode\u003enum_blocks\u003c/code\u003e, such that each array element is processed by a single thread. You must adjust your kernel accordingly as well.\u003c/p\u003e\r\n\u003cp\u003eThe format of the timing measurements should be identical to the one from step 1. Please take the time to look over these measurements and draw conclusions for yourselves. What do you notice? What do the computation times look like and what is the speedup? Once again, to get the most out of this lab, you are encouraged to discuss your findings with your TA.\u003c/p\u003e\r\n\u003ch4\u003eStep 4\u003c/h4\u003e\r\n\u003cp\u003eThe next step is to create a new kernel \u003ccode\u003earray_add_times\u003c/code\u003e, which does the same thing as \u003ccode\u003earray_add_threads_blocks\u003c/code\u003e, except it takes an extra arguments \u003ccode\u003etimes\u003c/code\u003e, which indicates how many times the elements in \u003ccode\u003eB\u003c/code\u003e should be added to the counterpart elements from \u003ccode\u003eA\u003c/code\u003e. Basically, each resulting (updated) element \u003ccode\u003eAi\u003c/code\u003e will be computed as:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003eAi = Ai + times * Bi \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eHowever, \u003cstrong\u003eyou must not use multiplication\u003c/strong\u003e in calculating the elements of the result. You must instead create a loop which adds each \u003ccode\u003eB\u003c/code\u003e element \u003ccode\u003e'times'\u003c/code\u003e times.\u003c/p\u003e\r\n\u003cp\u003eFor the array sizes, use only one data point: 32M. Similarly to the previous steps of this lab, your program must output the three time measurements, as described above, but this time as a function of the number of times that the elements in B are added. You must increase \"times\" between 1 and 512 in powers of two steps. Your program output should follow this format:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tTimes Size(M) TransferIn(ms) Computation(ms) TransferOut(ms)\t\r\n\t    1     32           1.23            2.34            3.45\r\n\t    2     32           1.23            2.34            3.45\r\n\t  ...\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eOnce again, the timings above (as well as the Size value) are just for illustration purposes, to clarify how your output format should look like. Once again, to match our output format, please use the printf format specifiers: %5d for the Times and Size columns, and %15.2f for all the others.\u003c/p\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints both measurements (i.e., time as a function of element count and time as a function of the number of additions). All your code (including the main program that you used to produce the results), should be included in a single CUDA C file, named \u003ccode\u003elab7.cu\u003c/code\u003e. Make sure your code compiles and runs on the teaching lab machines.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eGPU Environment \u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can run command ‘nvidia-smi’ to check whether the machine has an Nvidia GPU card.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ein the lab workstations, you need to set up the CUDA environment by modifying the PATH and LD_LIBRARY_PATH in .bashrc in your home directory. You can use nano: “nano .bashrc” to open the file and add these lines to it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport PATH=/usr/local/cuda-8.0/bin/:$PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/:$LD_LIBRARY_PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThen run the command: source ~/.bashrc to reload the environment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eUse nvcc -V to check whether you have setup the CUDA environment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eRunning the code on GPU\u003c/span\u003e\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the workstations in the labs. Do avoid peak load times (keep an eye on the machine utilization and check if others are logged in and running computations).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should consider running your code in isolation, to avoid any interference from other users. Unlike the Scinet sever, the lab machines are not guaranteed to be quite because others might be using the machine at the same time. Also, when you open a browser or any other file on the machine, the timing results might no longer be correct. Before testing your code on a workstation, please make sure that others are not logged in remotely and potentially running intensive tasks (you can check this using command line tools like ps, who, etc.). Also, close all of your browsers and extra files before measuring timings.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e \u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-19T18:00:00-04:00"},{"exportId":"ie04c79aeb9473063d12142cd323aac4c","title":"Lab 08","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eLab 8 - GPU memory, reductions\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eDue: Wednesday, March 27, at 10 p.m.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003eBefore you start\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eBefore you start this lab, you need to read all the slides in Lecture 20, as well as read and understand the code posted in \u003cstrong\u003e/u/csc367h/winter/pub/labs/examples/GPUExamples.tgz\u003c/strong\u003e and read relevant parts of the following link to learn how kernels 8-10 are implemented in the example provided:  \u003c/span\u003e\u003ca href=\"https://devblogs.nvidia.com/faster-parallel-reductions-kepler/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://devblogs.nvidia.com/faster-parallel-reductions-kepler/\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis exercise is intended to help you get some practice with more advanced GPU programming, like thread cooperation within thread blocks, and using shared memory. In order to efficiently solve a problem and fully leverage the potential of GPUs, you have to think about such aspects and tailor your solution to the GPU model. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSee the\u003c/span\u003e\u003ca href=\"https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e CUDA \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003edocumentation for more information. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlease start early to fully take advantage of the lab time to ask questions.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou may work in pairs for this exercise, with your A4 partner, since some code design may potentially be common with the assignment. MarkUs will only create the appropriate directory in your repository when you log into MarkUs and either create your group, or declare that you will work alone. The groups will get a new shared repository, and the students working solo may also get a new repository. Please log into MarkUs well before the deadline to take these steps. (If you create the directory manually, then MarkUs won't know about it and we won't be able to see your work.)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is your responsibility to log into MarkUs before the exercise deadline to ensure that you know where to commit your work, and so that MarkUs can connect your work to the grading system.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can find the starter code on wolf under \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cstrong\u003e/u/csc367h/winter/pub/labs/lab8/starter_code.tgz\u003c/strong\u003e \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eso copy this into your repository and make sure you can do your first commit. Please make sure to read carefully over the code, including the licenses and the instructions from the comments.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003eRequirements\u003c/h2\u003e\r\n\u003cp\u003eYour task for this exercise is to work on implementing a reduction algorithm, similar to the one discussed in class, and analyze the performance of various optimization steps. Your end goal is to write an efficient CUDA code that calculates the dot product of two arrays.\u003c/p\u003e\r\n\u003cp\u003eYour task is to implement a kernel called \"dot_product\", which multiplies two one-dimensional arrays A and B of the same length, by multiplying their pairwise elements from same indices, then adds all the resulted elements into the final dot product. The elements of A and B have been initialized to random single precision floating-point values in the set {-1, 0, 1}. You will have a chance to toy with this choice afterward, and you'll understand why we chose those values to begin with.\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe recommend that you start with one block only, and keep the size of the array below the blocksize. You may start with the naive dot product approach where each thread calculates the sum of two consecutive elements, as discussed in class. Then consider using multiple blocks and increasing the size of the arrays. You must take steps to optimize your code for the GPU. You will think about how threads access elements, how to use shared memory efficiently, etc. You will optimize your code using the ideas discussed in class, and you will consider comparing the performance between various approaches. We gave you the main execution harness to test the kernels, for convenience. You must implement gradually optimized kernels into dot_kernel1.cu through dot_kernel7.cu. Please review the code samples from class (uploaded in /u/csc367h/winter/pub/labs/examples/GPUExamples.tgz), including sum and max reductions, in order to replicate the same levels of optimizations and code restructuring. You should number the kernel versions the same way as in the code samples, with respect to the optimizations being made in each kernel.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eOnce you have compared your implementations with gradual optimizations, you will implement a reduction using the __shfl_down (shuffle down) instruction. You should implement the versions with and without atomics, similar to the ones discussed in the code sample given and in the link \u003c/span\u003e\u003ca href=\"https://devblogs.nvidia.com/faster-parallel-reductions-kepler/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://devblogs.nvidia.com/faster-parallel-reductions-kepler/\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e, then compare the performance of each version. Please place these implementations in the dot_kernel8-10.cu file (again, consult the provided code samples from lectures, to number the kernel version you're implementing in the same way). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003eYou must implement an equivalent dot product function on the CPU. You must time how long it takes to run the code on a single CPU, and on the GPU with various optimizations. As input sizes, use 2M, 8M, and 32M. Each execution time (on the CPU and on the GPU, for each input size) should be averaged over 100 runs. \u003cstrong\u003eDo not run your program 100 times\u003c/strong\u003e, your code should internally run each measurement 100 times and take the average. \u003cbr\u003eYou might want to run your code with and without -O3, to see if you notice any difference for the CPU implementation.\u003c/p\u003e\r\n\u003cp\u003eYour measurements should include separate timings for the transfer times to/from the GPU, and calculate the speedup of pure GPU computation against the CPU: \u003ccode\u003eCPU_time/GPU_time\u003c/code\u003e, and the speedup of total time taken to compute on the GPU (including transfers in and out!) against the CPU implementation: \u003ccode\u003eCPU_time / (GPU_time + TransferIn + TransferOut)\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eFor each reduction implementation, your evaluation output should be in the following format:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e\tSize(M) GPU_dotp CPU_dotp CPU_time(ms) GPU_time(ms) TransferIn(ms) TransferOut(ms) Speedup_noTrf Speedup\r\n\t     1     12345    12345        2.00         0.50           0.25            0.25         4.0      2.0\r\n\t     2     98765    98765        4.00         0.50           0.50            0.50         8.0      2.7\r\n\t     4    345987   345987        8.00         0.50           1.00            1.00        16.0      3.2\r\n\t...\r\n\t\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe value of the dot product calculated on the CPU and GPU should match, otherwise, your code is incorrect. You must fix such bugs otherwise the timings are likely meaningless. The timings, dotproduct values, and speedups above are solely for illustration purposes of the output formatting.\u003c/p\u003e\r\n\u003cp\u003eOnce you have your code correctly working, change the line where the arrays are initialized to contain a random number between 0 and 1. You can achieve that by assigning each array value to \u003ccode\u003e((float)(rand()%100))/100.0\u003c/code\u003e. What happens to the result? Why? Do not submit the code with this change.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eGPU Environment \u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou can run command ‘nvidia-smi’ to check whether the machine has an Nvidia GPU card.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ein the lab workstations, you need to set up the CUDA environment by modifying the PATH and LD_LIBRARY_PATH in .bashrc in your home directory. You can use nano: “nano .bashrc” to open the file and add these lines to it. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport PATH=/usr/local/cuda-8.0/bin/:$PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/:$LD_LIBRARY_PATH\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThen run the command: source ~/.bashrc to reload the environment. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eUse nvcc -V to check whether you have setup the CUDA environment.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eRunning the code on GPU\u003c/span\u003e\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should use the workstations in the labs. Do avoid peak load times (keep an eye on the machine utilization and check if others are logged in and running computations).\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou should consider running your code in isolation, to avoid any interference from other users. Unlike the Scinet sever, the lab machines are not guaranteed to be quite because others might be using the machine at the same time. Also, when you open a browser or any other file on the machine, the timing results might no longer be correct. Before testing your code on a workstation, please make sure that others are not logged in remotely and potentially running intensive tasks (you can check this using command line tools like ps, who, etc.). Also, close all of your browsers and extra files before measuring timings.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003eSubmission\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eEnsure that you have a repository directory created by MarkUs for this exercise. In this directory, add and commit+push your source code which prints both measurements (i.e., time as a function of element count and time as a function of the number of additions). Make sure your code compiles and runs on the teaching lab machines.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":1.5,"dueAt":null,"lockAt":null,"unlockAt":"2019-03-25T18:00:00-04:00"},{"exportId":"i0d42e6b487e946ec49aaa342a40c439d","title":"Project","type":"Assignment","content":"\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eProject - Parallelizing a Particles Simulation \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eTotal Points: 20\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDeadline to find your group partner and create your group on MarkUs\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e: Wednesday  February 27, at noon. Your group partners for part 1 and part 2 remain the same. DO NOT change partners between the two parts or you will be flagged for plagiarism because of shared design between the parts!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue Date for Part 1:\u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003e This part includes the serial and the OpenMP section should be submitted on Monday, March 11th at 10PM. You have to submit the code using the project-part1 MarkUs instance. Grace tokens will be deducted if you submit part 1 after this deadline. You have to submit a report called report-part1.pdf on this deadline along with your complete code for Part 1 of the project. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eDue Date for Part 2: \u003c/strong\u003e\u003cspan style=\"font-weight: 400;\"\u003eThis part includes the MPI section should be submitted on Friday, March 22th at 10PM. You have to submit the code using the project-part2 MarkUs instance. Grace tokens will be deducted if you submit part 2 after this deadline. You have to submit a report called report-part2.pdf on this deadline along with your complete code for Part 2 of the project. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eImportant note for phase 2: \u003c/strong\u003eMPI jobs can run for a very long time if you have created a deadlock. Do not leave your jobs running for long periods of time. Always monitor your jobs submitted to the compute nodes. ALso, do not run large jobs on the login node! You are only allowed to run very short jobs on the login node. Jobs on the login node should only run for a few minutes at max! Always check that you do not have a long-running job on the login node. A code with a deadlock is considered a long job since it will never terminate. We will deduct 30% to 100% of your grade if you run long jobs on the login node. We do have the complete log of all jobs submitted to Scinet.\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eScinet\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will use Scinet for this project. You should have already received an email with your Scinet login. In that email you see a link to The short intro to Scinet  document (the document is also uploaded in Quercus). You have to read that document before starting this lab. While you can use your own machine or a lab machine to debug the code, your final code has to be performance engineered and executed on Scinet. We will do all grading on Scinet. For each part, we do provide scripts to help with running your code on Scinet. \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eBefore you start!\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNote that this is a project not an assignment. You will be evaluated on \u003cspan style=\"text-decoration: underline;\"\u003eyour efforts to \u003c/span\u003e\u003c/span\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eunderstand the problem\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e and \u003cspan style=\"text-decoration: underline;\"\u003eto \u003c/span\u003e\u003c/span\u003e\u003cspan style=\"text-decoration: underline;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cspan\u003ef\u003c/span\u003eind answers to issues that come up\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e as you start implementations. The project code, handout, and resources listed at the end of the handout provide you with all that is needed to understand the problem and even provide hints (read items 6 and 7 before you start the project, they are very helpful!). Being able to understand these and leverage them in your implementation is a part of your grade. To allow for a fair grading and to not give out answers, we might not be able to answer questions in Piazza that relate to questions that want us to explain the problem in detail or ask to resolve issues with your implementation. You are encouraged to ask questions from your classmates in Piazza, we will take note of students that actively help others and answer questions. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003cbr\u003e\u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eOverview\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou have to work with a partner for this project. In this project, we will be parallelizing a toy particle simulation (similar simulations are used in\u003c/span\u003e\u003ca href=\"http://www.thp.uni-duisburg.de/~kai/index_1.html\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e mechanics\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e,\u003c/span\u003e\u003ca href=\"http://www.ks.uiuc.edu/Research/namd/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e biology\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e, and\u003c/span\u003e\u003ca href=\"http://www.mpa-garching.mpg.de/gadget/clusters/index.html\"\u003e\u003cspan style=\"font-weight: 400;\"\u003e astronomy\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e).  In our simulation, particles interact by repelling one another.  A run of our simulation is shown here:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"viewer/files/unnamed-1.gif\" alt=\"unnamed-1.gif\" width=\"200\" height=\"200\" data-api-endpoint=\"https://q.utoronto.ca/api/v1/courses/69683/files/2804499\" data-api-returntype=\"File\"\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe particles repel one another, but only when closer than a cutoff distance highlighted around one particle in grey.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eAsymptotic Complexity\u003c/span\u003e\u003c/h2\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eSerial Solution Time Complexity\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf we were to naively compute the forces on the particles by iterating through every pair of particles, then we would expect the asymptotic complexity of our simulation to be O(n^2).\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHowever, in our simulation, we have chosen a density of particles sufficiently low so that with n particles, we expect only O(n) interactions.  An efficient implementation can reach this time complexity. The first part of your assignment will be to implement this linear time solution in a serial code, given a naive O(n^2) implementation.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eParallel Speedup\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eSuppose we have a code that runs in time T = O(n) on a single processor. Then we'd hope to run close to time T/p when using p processors.  After implementing an efficient serial O(n) solution, you will attempt to reach this speedup using two different programming models.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eStarter Code\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code is available on Scinet under:\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e/home/t/teachcsc367/CSC367Starter/assignments/project/starter.tgz\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe starter code provides correct implementations of the particle simulation problem in serial/OpenMP/MPI, however, these implementations are not optimized for performance. Note that correctness does not mean optimized, it only means that the provided code correctly computes the particles interactions.  \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eRead the below on the source code structure carefully:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ecommon.cpp, common.h ; these files provide an implementation of common functionality, such as I/O, numerics and timing. Do not change these files by any means.  You will alter the physics if you do! We will use the default version (what we provide with the starter code) of these files for grading. You do not need to understand the underlying physics (such as ordinary differential equations and the Euler method) used in the common.cpp and common.h files since the movement of particles and how forces are applied are already correctly implemented for you in these two files.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eautograder.cpp; a code that helps calculate performance for both serial and parallel implementations. Do not change this file. We will use the default version (what we provide with the starter code) of this file for grading. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eMakefile; a makefile that compiles your code on Scinet. Do not create a make run command. Run your code using the sbatch files provided. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eserial.cpp: This file provides a correct serial implementation to the problem, however, the implementation is not optimal and is a naive O(n^2) implementation. Do not try to run this code for large particle sizes. It will not finish on-time and the sbatch files will timeout.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eopenmp.cpp: This file provides a correct parallel implementation of the problem in OpenMP. However, the implementation is not optimized for performance or scalability!\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003empi.cpp: This file provides a correct MPI implementation to the problem. However, the implementation is not optimized for performance or scalability!\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003esetup-project.sh: This file loads the modules and compiles your code. The jobs scripts are not called with this file.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ejob-teach-serial, job-teach-openmp, job-teach-mpi: are sbatch files that run your code with small number of particles and do not include the “-no” flag.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eauto-teach-*: are sbatch files that run your code with different number of particles/cores/processors and call the autograder. These runs are with the “-no” flag.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe recommend that you only change the serial.cpp, openmp.cpp, and mpi.cpp files. However, if you do decide to include other files or modify the Makefile (do not modify common.cpp, common.h, autograder.cpp), spell out the changes in your report. Also, spell out in your report what Makefile targets we are to build for the different parts of your report.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eCorrectness and Performance\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eA simple correctness check which checks the smallest distance between 2 particles during the entire simulation is provided (look inside the provided source code!). A correct simulation will have particles stay at greater than 0.4 (of cutoff) with typical values between 0.7-0.8. A simulation were particles don't interact correctly will have particles closer than 0.4 (of cutoff) with typical values between 0.01-0.05 . More details as well as an average distance are described in the source file.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe'd recommend keeping the correctness checker in your code (for the OpenMP and MPI codes the overhead isn't significant) but depending on performance desires it can be deleted as long as the simulation can still output a correct txt file.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe performance of the code is determined by doing multiple runs of the simulation with increasing particle numbers and comparing the performance with the autograder.cpp provided. This can be done automatically with the auto-* scripts.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThere will be two types of scaling that are tested for your parallel codes:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn strong scaling we keep the problem size constant but increase the number of processors\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn weak scaling we increase the problem size proportionally to the number of processors so the work/processor stays the same \u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor more details on the options provided by each file you can use the -h flag on the compiled executables.\u003c/span\u003e\u003c/p\u003e\r\n\u003ch3\u003e\u003cspan style=\"font-weight: 400;\"\u003eImportant notes for Performance and the Autograder:\u003c/span\u003e\u003c/h3\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe scripts we are providing have small numbers of particles and large number of particles. We will use the same particles sizes to test the performance of your code! We will put great weight on your code running correctly and performing well for the large particles so don't just optimize for the small particles! \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eRemember to use the -no flag to “turn off all correctness checks and particle location outputs” for actual timing runs. Our auto-teach* scripts use the -no flag, but the job-teach-* does not include the -no flag. So use the job-teach-* for debugging and checking for correctness before moving to the job-teach* sbatch files that will help with actual timings and information on scaling and efficiency that the autograder provides. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eMore details on the autograder:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eSerial code performance will be tested via fitting multiple runs of the code to a line on a log/log plot and calculating the slope of that line. This will determine whether your code is attaining the O(n) desired complexity versus the starting O(n^2\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e). \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eOpenMP Memory performance and MPI Performance will be tested via calculating the strong and weak scaling average efficiencies for 1,2,4,8,16 processor/thread runs.\u003c/span\u003e\u003c/li\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eThe strong and weak average efficiencies ( eff\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ess\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e , eff\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003ews\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e) are reported for your reference. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eImportant note about the autograder: The strong and weak scaling numbers reported by the autograder should only be taken seriously when you have optimized the serial code. To clarify, if you run the starter code only, the scaling efficiency and speedups reported by the autograder might not be bad, but don't be fooled! Recall the discussions in class on “how to fool the masses with reporting performance numbers!”  \u003c/span\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003c/span\u003e\u003c/h2\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 1: Serial and OpenMP\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIn this part, you will write two versions of our simulation.  DO NOT change the headers in the provided sbatch scripts. First, you will write an O(n) serial code.  Then, you will write a parallel version of this O(n) code for shared memory architectures using OpenMP.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThere are two source files (serial.cpp and openmp.cpp) you need to modify.  You need to create one serial code (serial.cpp) that runs in O(n) time and one shared memory implementation (openmp.cpp) using OpenMP.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must represent your results visually (graphs!) and analyze them in a short report (you must name this file: report-part1.pdf). You should describe your implementation, plot and analyze your results, draw conclusions and report your findings in a written report. Write a very technically sound report and it is important to show insight into what you are measuring and explain the results you are seeing. Below lists examples of what you can include in your report:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA description of the design choices that you tried and how did they affect the performance.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlots: Serial: (1) A table that shows the running time of your optimized code for different particles sizes as well as the slope estimate for your optimized serial code. (2) A log-log plot of running time vs the number of particles to show that your optimized serial implementation runs in O(n) time.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlots: OpenMP: (1) The strong and weak scaling plots that show the running time of your optimized OpenMP implementation.  (2) The strong scaling plots that show the speedup of your optimized OpenMP implementation. (3) The strong and weak scaling plots that show the efficiency of your optimized OpenMP implementation. (4) Average weak and strong scaling efficiency.  \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eAnalyze the speedup plots to show how closely your OpenMP code approaches the idealized p-times speedup and a discussion on whether it is possible to do better.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWhere does the time go? Discuss the synchronization and locking strategies used in your code and the optimization you have made to make the code more efficient. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA discussion on your serial and OpenMP implementation.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003ePart 2: MPI\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe MPI part of the project is set to be implemented on one Scinet node. DO NOT change the headers in the provided sbatch scripts. Note that you should not make assumptions of the underlying network and do not optimize for a specific topology. We are using a “logical view” of a distributed system in this section so refer to “cores” as “processors” in all your plots. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThere is one source file (mpi.cpp) you need to modify. You need to create one distributed memory implementation (MPI) that runs in O(n) time with as close as possible to O(n/p) scaling.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must represent your results visually (graphs!) and analyze them in a short report (you must name this file: report-part2.pdf. You should describe your implementation, plot and analyze your results, draw conclusions and report your findings in a written report. It is important to show insight into what you are measuring and explain the results you are seeing.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eHere are some items you might add to your report:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ePlots: (1) The strong and weak scaling plots that show the running time of your optimized MPI implementation.  (2) The strong scaling plots that show the speedup of your optimized MPI implementation. (3) The strong and weak scaling plots that show the efficiency of your optimized MPI implementation. \u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA description of the communication you used in the distributed memory implementation.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA description of the design choices that you tried and how they affect performance.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eAnalyze the speedup plots to show how closely your MPI code approaches the idealized p-times speedup and a discussion on whether it is possible to do better.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eWhere does the time go? Consider breaking down the runtime into computation time or communication time. You can plot the distribution or even comeup with a parameterized expression that estimates the amount of data communication vs the computation cost.  How do they scale with p? If you have designed your partitioning to reduce communication costs, explain your strategy and why it works. What else comes into mind to improve your code?\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eA discussion on your MPI implementation.\u003c/span\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eTesting tips\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor this assignment, you are required to use the teach cluster (SciNet) to get accurate performance results. You will be graded on the teach cluster only. You are free to use C or C++. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003ejob-teach* files: These files will run one instance of your serial (or OpenMP, or MPI) implementation for small number of particles (see inside the job-teach-* file for more information)  with the -no flag disabled to print outputs related to particles locations and correctness issues. Run these files (one at a time) using sbatch job-teach-*\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eauto-teach-* files: These files will run your code for different particles sizes and/or a different number of particles and then run the autograder to report scaling and efficient numbers. Note that the -no flag is included to report accurate timings. Also note that these jobs will take longer to run and should not be used for checking code correctness.  The auto-teach-* files have two versions: *-small and *-large. The small files run your code for small particles. Please note that auto-teach-serial-small has a different number of particles compared to auto-teach-openmp-small and auto-teach-mpi small. This is because the unoptimized serial code runs very slow so we provide smaller particle sizes for the serial-small script. DO NOT use auto-teach-serial-large on an unoptimized serial code since it will timeout and never finish. Always optimize your code and test with the *-small scripts first then move to *-large files. Also, if you have not created efficient data structures or allocated memory properly, your code might crash for *-large files or you might get a segmentation fault. So optimize your code properly and remember that the optimizing your code for *-large files will be harder because of the large particle sizes!   Run these files (one at a time) using sbatch auto-teach-*\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400; font-size: 24pt;\"\u003eReport\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYou must write two reports (report-part1.pdf for part 1 and report-part2.pdf for part 2) documenting your implementation, displaying your results in a meaningful way, and analyzing your findings, for each part of the assignment. In your report, you should present your implementation, the experimental setup and results. You should discuss what you noticed, draw conclusions and analyze the tradeoffs, if any. The reports should be written in a scientific manner (clear structure, clear description of your approach, results, findings, etc., and should use technical writing instead of colloquial terminology or phrases). Keep in mind that presenting your experimental findings and observations to a technical audience is an important skill to develop as a computer scientist.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eTwo-Phase Submission\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eIt is critical to read the below to submit your project properly. The project should be submitted in two parts:\u003c/span\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003ePart 1 of the project that includes the serial and the OpenMP section should be submitted on Monday, March 11th at 10PM. You have to submit the code using the project-part1 MarkUs instance. Grace tokens will be deducted if you submit part 1 after this deadline. You have to submit a report called report-part1.pdf on this deadline along with your complete code for Part 1 of the project. Your submission for part 1 will be the only instance that we will use to grade for serial and OpenMP implementations. Please read the below on “\u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ecommon submission rules for both parts”\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003ePart 2 of the project that includes MPI section should be submitted on Friday, March 22th at 10PM. You have to submit the code using the project-part2 MarkUs instance. Grace tokens will be deducted if you submit part 2 after this deadline. You have to submit a report called report-part2.pdf on this deadline along with your complete code for Part 2 of the project. Your submission for part 2 will be the only instance that we will use to grade for MPI implementations. DO NOT assume that the course staff will look at your submission from part 1 to grade this section. Two different course staff might grade parts 1 and part 2. So include anything needed for this part to be fully stand alone. Please read the below on “\u003c/span\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ecommon submission rules for both parts”\u003c/span\u003e\u003c/i\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eCommon submission rules for both parts: You must keep the same structure in your repository as the starter code. You must submit all the files required to build and run all your programs (including any header files and the makefile, etc.). You shouldn't need to add any new files to the starter code, but if you do, make sure that you update the makefile accordingly. Make sure your code compiles and runs correctly on Scinet. Be sure to make it clear in the report how to run your code! Do not submit any executables or object files! (do a \"make clean\" before making your final commit). \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIMPORTANT: make sure to keep the optimization options (-O3) in the makefile in your final submission, otherwise your code will be too slow, even if your algorithms are efficient.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eAside from your code, you must submit two reports (named report-part1.pdf and report-part1.pdf) with the required content as described above. When discussing your approach, feel free to also describe any problems encountered and workarounds, what isn't fully implemented (or doesn't work fully), any special design decisions you've taken or optimizations you made (as long as they conform to the assignment specs!), etc.\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eAdditionally, you must submit an INFO.txt file, which contains as the first 2 lines the following:\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour name(s)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eyour UtorID(s)\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eIf you want us to grade an earlier revision of your project for whatever reason (for example, for saving some grace tokens if you had a stable submission before the deadline, tried to add new functionality after the deadline but broke your submission irreparably), then you may specify the git hash for the earlier revision you want marked. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eAs a general rule, by default we will always take the last revision before the deadline (or last one after the deadline, up to your remaining unused grace tokens), so you should not be including a line with the git commit hash, except in the exceptional circumstances where it makes sense. So in general, please avoid using this option and just make sure that the last revision (either before the deadline if you submit on time, or up to a subset of your remaining grace tokens if you submit late) is the one you want graded.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFinally, you must submit a plagiarism.txt file (in the top directory of the assignment), with the following statement: \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003e\"All members of this group reviewed all the code being submitted and have a good understanding of it. All members of this group declare that no code other than their own has been submitted. We both acknowledge that not understanding our own work will result in a zero on this assignment, and that if the code is detected to be plagiarised, severe academic penalties will be applied when the case is brought forward to the Dean of Arts and Science.\"\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eA missing INFO.txt file will result in a 10% deduction (on top of an inherent penalty if we do not end up grading the revision you expect). Any missing code files or Makefile will result in a 0 on this assignment! Please reserve enough time before the deadline to ensure correct submission of your files. No remark requests will be addressed due to an incomplete or incorrect submission!\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eAgain, make sure your code compiles without any errors or warnings. \u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode that does not compile will receive zero marks!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eMarking Scheme\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eYour grade will depend on the performance and efficiency sustained by your codes on Scinet and will be broken into 3 parts. We will be marking based on performance and efficiency (65%), coding style (5%), and report (30%). This grading criteria will be applied to different parts as follows: Serial - 30%, OpenMP - 30%, MPI - 40%.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode that does not compile or computes the particle interactions incorrectly will receive 0 marks (for the part that applies)! \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eFor grading your performance, we will consider multiple factors such as the running time of the implementation as well the strong and weak scaling performances and efficiency. It is our discretion on how to distribute the performance grade between these metrics. For example, an unoptimized serial code has not merit and it will also invalidate all the weak and strong scaling numbers in the OpenMP and MPI parts!\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eNegative deductions (please be careful about these!):\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode does not compile: -100% for *any* mistake, for example: missing source file necessary for building your code (including Makefile, header files, etc.), typos, any compilation error, etc\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eChanges to common.h, common.c: -100%, you are not allowed to change these two files!\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eNo plagiarism.txt file: -100% (we will assume that your code is plagiarised and that you wish to withdraw your submission, if this file is missing)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eMissing or incorrect INFO.txt: -10%\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eWarnings: -10%\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eExtra output: -20% (for any output other than what is required in the handout)\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eCode placed in other subdirectories than indicated: -20%\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003e\u003cbr\u003e\u003c/span\u003e\u003cspan style=\"font-weight: 400;\"\u003eSubmitted unnecessary files (compiled code, test reports, data files, etc.): -10%\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eWe will deduct 30% to 100% of your grade if you run long jobs on the login node.\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eCopyright\u003c/span\u003e\u003c/h2\u003e\r\n\u003cp\u003e\u003cspan style=\"font-weight: 400;\"\u003eThe project is adapted from the XSEDE online course Applications of Parallel Computing. The copyright belongs to XSEDE and the staff for this online course as well as the University of Toronto CSC367 staff. Similar to all the assignments and labs, distribution of this project and your solutions, during or after the semester, is strictly prohibited and is considered plagiarism. Do not post your solutions online! Searching for solutions online is also considered plagiarism. We will use technology to track plagiarism and violations of any of the above rules. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003ch2\u003e\u003cspan style=\"font-weight: 400;\"\u003eResources\u003c/span\u003e\u003c/h2\u003e\r\n\u003col\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eShared memory implementations may require using locks that are available as \u003c/span\u003e\u003ca href=\"http://msdn.microsoft.com/en-us/library/7d2zxc0s(VS.80).aspx\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eomp_lock_t\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e in OpenMP (requires omp.h).\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eDistributed memory implementation may benefit from overlapping communication and computation that is provided by \u003c/span\u003e\u003ca href=\"http://www.mpi-forum.org/docs/mpi-1.1/mpi-11-html/node46.html\"\u003e\u003cspan style=\"font-weight: 400;\"\u003enonblocking MPI routines\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e such as MPI_Isend and MPI_Irecv.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eOther useful resources: \u003c/span\u003e\u003ca href=\"http://openmp.org/wp/2008/11/sc08-openmp-hands-on-tutorial-available/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eOpenMP tutorial\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e, \u003c/span\u003e\u003ca href=\"http://www.openmp.org/specifications/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eOpenMP specifications\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e and \u003c/span\u003e\u003ca href=\"http://mpi-forum.org/docs/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eMPI specifications\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e.\u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eProgramming in shared and distributed memory models are introduced in Lectures.\u003c/span\u003e\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eIf you want a parallel debugging tool, Scinet has DDT installed, however, if you plan to use DDT on Scinet, remember the ask for a dedicated node (\u003c/span\u003e\u003ca href=\"https://docs.scinet.utoronto.ca/index.php/Niagara_Quickstart\"\u003e\u003ci\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://docs.scinet.utoronto.ca/index.php/Niagara_Quickstart\u003c/span\u003e\u003c/i\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e) and you do need to ssh using X server! \u003c/span\u003e\u003ca href=\"http://www.cs.uoregon.edu/Research/tau/home.php\"\u003e\u003cspan style=\"font-weight: 400;\"\u003eTAU (Tuning and Analysis Utilities)\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e is a source code instrumentation system to gather profiling information; this system can profile MPI, OpenMP and mixtures, but it has a learning curve. Tau is not installed on Scinet so if you decide to use it you need to run outside of Scinet. \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eHints on getting O(n) serial and Shared memory and MPI implementations (\u003c/span\u003e\u003ca href=\"https://drive.google.com/open?id=11vjRefkcRA3a8DlH1t0QoVYw_TMx9RTl\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epdf\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"font-weight: 400;\"\u003e). Please note that while these slides provide very useful hints on describing the problem and general approaches that you might want to take, they are not necessarily providing you with the most efficient solution. So do not limit your creativity! \u003c/span\u003e\n\u003c/li\u003e\r\n\u003cli style=\"font-weight: 400;\"\u003e\n\u003cspan style=\"font-weight: 400;\"\u003eUseful reading: \u003c/span\u003e\u003ca href=\"https://docs.scinet.utoronto.ca/index.php/Introduction_To_Performance#Strong_Scaling_Tests\"\u003e\u003cspan style=\"font-weight: 400;\"\u003ehttps://docs.scinet.utoronto.ca/index.php/Introduction_To_Performance#Strong_Scaling_Tests\u003c/span\u003e\u003c/a\u003e\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":20.0,"dueAt":null,"lockAt":null,"unlockAt":null}],"discussion_topics":[{"exportId":"i0874e8c0e4f3e5fce98e7f273a719a3d","title":"Take Home Task on Wed Jan 16th and Assignment One","type":"DiscussionTopic","content":"\u003cp\u003eHi everyone,\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eWe will not have a lab on Wed Jan 16th because of Scinet downtime. Instead, \u003cspan style=\"font-weight: 400;\"\u003eyou must read sections 1 through 5.3 from this \u003c/span\u003e\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003e\u003cspan style=\"font-weight: 400;\"\u003epthreads tutorial\u003c/span\u003e\u003c/a\u003e  (\u003ca href=\"https://computing.llnl.gov/tutorials/pthreads/\"\u003ehttps://computing.llnl.gov/tutorials/pthreads/\u003c/a\u003e) \u003cspan style=\"font-weight: 400;\"\u003efrom the Lawrence Livermore National labs. This is a mandatory take-home task and should be done on Wed Jan 16th. \u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eRemember that you can not submit Assignment1 jobs to Scient during the Scinet downtime dates (Jan 15th and Jan 16th), you should do tests and debug the assignment on a local or a lab machine and when Scinet is up again you will be able to continue the assignment there. Your assignment will only be graded on Scinet so do not use any other platform for fine-tuning your code, obtaining final results, and writing your report!\u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003eAssignment one will be posted sometime today. \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e\r\n\u003cp\u003e \u003c/p\u003e","lockAt":null,"unlockAt":null,"graded":false}],"quizzes":[],"files":[{"type":"file","name":"Lec17.pdf","size":2460080,"files":null},{"type":"file","name":"Lec20.pdf","size":4072776,"files":null},{"type":"file","name":"Lec14.pdf","size":1480212,"files":null},{"type":"file","name":"Lec16.pdf","size":1561986,"files":null},{"type":"file","name":"Lec7.pdf","size":456965,"files":null},{"type":"file","name":"Lec8.pdf","size":1738742,"files":null},{"type":"file","name":"Lec21.pdf","size":363599,"files":null},{"type":"file","name":"Lec19.pdf","size":959019,"files":null},{"type":"file","name":"LastLecture.pdf","size":8986010,"files":null},{"type":"file","name":"Lec11.pdf","size":4904647,"files":null},{"type":"file","name":"unnamed-1.gif","size":124298,"files":null},{"type":"file","name":"Lec01P.pdf","size":9053190,"files":null},{"type":"file","name":"Lec6P.pdf","size":1676895,"files":null},{"type":"file","name":"CSC367 Syllabus (1).pdf","size":110806,"files":null},{"type":"file","name":"Lec02P.pdf","size":3529812,"files":null},{"type":"file","name":"A short intro to Scinet.pdf","size":141552,"files":null},{"type":"file","name":"Lec9.pdf","size":2298408,"files":null},{"type":"file","name":"Lec12.pdf","size":1534361,"files":null},{"type":"file","name":"Lec03P.pdf","size":894247,"files":null},{"type":"file","name":"Lec10.pdf","size":2013958,"files":null},{"type":"file","name":"Lec13.pdf","size":354454,"files":null},{"type":"file","name":"Lec15.pdf","size":1230505,"files":null},{"type":"file","name":"Lec03P_E.pdf","size":913079,"files":null}]}